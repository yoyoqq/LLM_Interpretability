{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6051cbee-dd05-431c-9d21-e624bb1d0347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 29 15:26:05 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  | 00000000:31:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              51W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beaa6ab7-a120-4098-b4b9-53d408e47059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import csv\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a6341b-67c5-44c3-b001-1d4c0aa9a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAMES = [\n",
    "                # \"emotion\", \n",
    "                # \"math\", \n",
    "                \"mmlu\", \n",
    "                # \"programming\"\n",
    "]\n",
    "DATASET_PATHS = [f\"./datasets/{name}_processed.csv\" for name in DATASET_NAMES]\n",
    "# Load and concatenate all datasets\n",
    "df = pd.concat([pd.read_csv(path, encoding=\"utf-8-sig\") for path in DATASET_PATHS], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e61e84-a1af-4be8-9a73-e76a2fe061c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>category</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_2/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_2/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_2/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_3/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_3/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_3/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_4/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_4/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_4/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_5/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_5/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_5/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_6/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_6/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_6/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_7/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_7/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_7/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_8/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_8/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_8/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_9/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_9/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_9/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_10/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_10/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_10/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_11/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_11/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_11/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_12/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_12/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_12/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_13/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_13/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_13/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_14/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_14/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_14/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_15/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_15/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_15/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_16/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_16/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_16/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_17/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_17/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_17/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_18/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_18/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_18/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_19/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_19/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_19/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_20/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_20/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_20/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_21/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_21/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_21/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_22/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_22/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_22/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_23/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_23/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_23/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_24/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_24/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_24/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_25/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_25/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_25/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_0/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_0/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_0/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_1/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_1/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_1/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_2/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_2/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_2/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_3/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_3/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_3/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_4/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_4/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_4/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_5/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_5/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_5/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_6/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_6/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_6/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_7/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_7/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_7/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_8/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_8/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_8/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_9/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_9/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_9/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_10/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_10/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_10/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_11/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_11/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_11/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_12/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_12/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_12/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_13/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_13/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_13/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_14/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_14/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_14/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_15/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_15/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_15/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_16/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_16/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_16/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_17/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_17/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_17/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_18/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_18/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_18/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_19/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_19/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_19/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_20/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_20/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_20/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_21/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_21/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_21/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_22/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_22/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_22/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_23/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_23/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_23/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_24/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_24/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_24/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_25/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_25/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-att-canonical-layer_25/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_0/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_0/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_0/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_1/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_1/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_1/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_2/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_2/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_2/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_3/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_3/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_3/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_4/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_4/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_4/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_5/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_5/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_5/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_6/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_6/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_6/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_7/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_7/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_7/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_8/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_8/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_8/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_9/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_9/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_9/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_10/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_10/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_10/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_11/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_11/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_11/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_12/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_12/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_12/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_13/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_13/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_13/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_14/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_14/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_14/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_15/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_15/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_15/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_16/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_16/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_16/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_17/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_17/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_17/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_18/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_18/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_18/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_19/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_19/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_19/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_20/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_20/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_20/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_21/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_21/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_21/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_22/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_22/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_22/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-token_feature_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>Statement 1 | If a group has an element of ord...</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 11864, 4698, 3798, 6186, ...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 10183, 3848, 8835, 8994, 1...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>[[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....</td>\n",
       "      <td>[15089, 14059, 7132, 9407, 1650, 4592, 1401, 1...</td>\n",
       "      <td>[[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...</td>\n",
       "      <td>[[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...</td>\n",
       "      <td>[9134, 6486, 14238, 7173, 5806, 4303, 5371, 21...</td>\n",
       "      <td>[[12690, 11570, 6680, 14155, 13325, 5575, 1118...</td>\n",
       "      <td>[[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...</td>\n",
       "      <td>[12690, 11570, 6680, 11333, 6717, 6680, 6232, ...</td>\n",
       "      <td>[[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...</td>\n",
       "      <td>[[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...</td>\n",
       "      <td>[1059, 8392, 5148, 6131, 3235, 1059, 15280, 19...</td>\n",
       "      <td>[[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...</td>\n",
       "      <td>[[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...</td>\n",
       "      <td>[9743, 6201, 14077, 2686, 15854, 12531, 15012,...</td>\n",
       "      <td>[[12287, 14119, 14537, 516, 13236, 13027, 6142...</td>\n",
       "      <td>[[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...</td>\n",
       "      <td>[12287, 14119, 14537, 9664, 8039, 2523, 3660, ...</td>\n",
       "      <td>[[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...</td>\n",
       "      <td>[[868.33, 240.19, 224.46, 217.45, 134.61, 127....</td>\n",
       "      <td>[9213, 4399, 6069, 6291, 6966, 2024, 13041, 16...</td>\n",
       "      <td>[[12102, 5877, 3736, 9892, 10966, 12253, 4212,...</td>\n",
       "      <td>[[1050.34, 380.12, 201.91, 168.05, 167.84, 135...</td>\n",
       "      <td>[12102, 5877, 3736, 12102, 381, 7266, 15789, 9...</td>\n",
       "      <td>[[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...</td>\n",
       "      <td>[[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...</td>\n",
       "      <td>[4392, 2843, 3736, 4392, 3736, 14372, 4444, 67...</td>\n",
       "      <td>[[12945, 13423, 10772, 7228, 6222, 8238, 7675,...</td>\n",
       "      <td>[[1365.86, 254.11, 229.52, 216.75, 200.8, 160....</td>\n",
       "      <td>[12945, 13423, 10772, 12945, 13423, 10772, 695...</td>\n",
       "      <td>[[1041, 7507, 11087, 3220, 11767, 11752, 14669...</td>\n",
       "      <td>[[1436.4, 288.32, 274.44, 177.82, 175.78, 169....</td>\n",
       "      <td>[1041, 7507, 11087, 4667, 11087, 1178, 6810, 8...</td>\n",
       "      <td>[[11248, 13423, 15319, 12322, 15392, 12879, 15...</td>\n",
       "      <td>[[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...</td>\n",
       "      <td>[11248, 13423, 15319, 13423, 11248, 6665, 3149...</td>\n",
       "      <td>[[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...</td>\n",
       "      <td>[[1326.71, 937.5, 207.55, 193.66, 179.61, 165....</td>\n",
       "      <td>[15567, 7214, 6812, 16123, 12313, 15567, 15887...</td>\n",
       "      <td>[[10716, 8610, 13870, 14717, 6266, 10404, 7546...</td>\n",
       "      <td>[[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...</td>\n",
       "      <td>[10716, 8610, 13870, 10716, 14717, 8610, 2234,...</td>\n",
       "      <td>[[16028, 10480, 14919, 4500, 2717, 4631, 4005,...</td>\n",
       "      <td>[[1902.23, 718.23, 386.15, 328.9, 205.48, 198....</td>\n",
       "      <td>[16028, 10480, 14919, 4500, 16028, 10480, 1295...</td>\n",
       "      <td>[[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...</td>\n",
       "      <td>[[1963.47, 777.35, 402.1, 298.72, 265.57, 229....</td>\n",
       "      <td>[7127, 7921, 9095, 1935, 11527, 1003, 6492, 50...</td>\n",
       "      <td>[[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...</td>\n",
       "      <td>[[2052.88, 763.03, 348.91, 271.26, 259.58, 222...</td>\n",
       "      <td>[3851, 15394, 12685, 10793, 7373, 15897, 7373,...</td>\n",
       "      <td>[[12025, 11046, 3543, 14445, 6075, 7417, 11438...</td>\n",
       "      <td>[[2130.78, 634.11, 405.05, 283.16, 279.33, 242...</td>\n",
       "      <td>[12025, 11046, 3543, 8475, 10441, 5111, 6655, ...</td>\n",
       "      <td>[[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...</td>\n",
       "      <td>[[2028.8, 781.4, 534.86, 264.19, 252.53, 251.0...</td>\n",
       "      <td>[6631, 743, 5052, 292, 11527, 13785, 2045, 292...</td>\n",
       "      <td>[[4138, 13557, 15170, 2788, 4967, 15463, 5910,...</td>\n",
       "      <td>[[2020.27, 856.65, 758.72, 290.22, 261.91, 250...</td>\n",
       "      <td>[4138, 13557, 15170, 14723, 1003, 5111, 4366, ...</td>\n",
       "      <td>[[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...</td>\n",
       "      <td>[[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....</td>\n",
       "      <td>[15056, 2037, 630, 10752, 8962, 16143, 5112, 1...</td>\n",
       "      <td>[[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...</td>\n",
       "      <td>[[2067.19, 1388.15, 290.23, 256.19, 256.17, 24...</td>\n",
       "      <td>[3956, 6961, 8321, 932, 5286, 8797, 2385, 9382...</td>\n",
       "      <td>[[1802, 14391, 14836, 4182, 15109, 14832, 395,...</td>\n",
       "      <td>[[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...</td>\n",
       "      <td>[1802, 14391, 14836, 12205, 3848, 501, 3650, 1...</td>\n",
       "      <td>[[7479, 5149, 14186, 14325, 15861, 15298, 1734...</td>\n",
       "      <td>[[2302.48, 919.27, 913.31, 362.69, 330.19, 330...</td>\n",
       "      <td>[7479, 5149, 14186, 14325, 3627, 484, 13749, 1...</td>\n",
       "      <td>[[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...</td>\n",
       "      <td>[[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...</td>\n",
       "      <td>[3880, 1421, 1608, 3880, 1608, 9944, 8636, 142...</td>\n",
       "      <td>[[15873, 7914, 11003, 7428, 15345, 5816, 14312...</td>\n",
       "      <td>[[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...</td>\n",
       "      <td>[15873, 7914, 11003, 15873, 11003, 7914, 15157...</td>\n",
       "      <td>[[13234, 888, 11147, 8912, 14708, 3818, 9138, ...</td>\n",
       "      <td>[[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....</td>\n",
       "      <td>[13234, 888, 11147, 13644, 12037, 8012, 12169,...</td>\n",
       "      <td>[[6576, 4257, 10471, 12044, 14532, 7826, 1451,...</td>\n",
       "      <td>[[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....</td>\n",
       "      <td>[6576, 4257, 10471, 6576, 15575, 3030, 4226, 9...</td>\n",
       "      <td>[[5518, 4210, 10188, 8146, 14202, 12331, 884, ...</td>\n",
       "      <td>[[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...</td>\n",
       "      <td>[5518, 4210, 10188, 5518, 4742, 4210, 5518, 47...</td>\n",
       "      <td>[[5252, 11557, 11619, 4107, 14508, 3087, 12114...</td>\n",
       "      <td>[[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...</td>\n",
       "      <td>[5252, 11557, 11619, 5252, 11557, 11619, 5252,...</td>\n",
       "      <td>[[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...</td>\n",
       "      <td>[[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....</td>\n",
       "      <td>[1231, 9366, 15754, 4171, 1231, 12948, 1231, 5...</td>\n",
       "      <td>[[5514, 2461, 12467, 10364, 7156, 14085, 14823...</td>\n",
       "      <td>[[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...</td>\n",
       "      <td>[5514, 2461, 12467, 10258, 10364, 5514, 10364,...</td>\n",
       "      <td>[[4923, 11894, 10982, 11028, 9940, 2403, 5138,...</td>\n",
       "      <td>[[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...</td>\n",
       "      <td>[4923, 11894, 10982, 11382, 4923, 11894, 11894...</td>\n",
       "      <td>[[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...</td>\n",
       "      <td>[[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...</td>\n",
       "      <td>[4526, 1054, 15802, 4526, 10930, 1054, 4526, 1...</td>\n",
       "      <td>[[3101, 11995, 13952, 3748, 11799, 7547, 14552...</td>\n",
       "      <td>[[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...</td>\n",
       "      <td>[3101, 11995, 13952, 7876, 3101, 7844, 3101, 1...</td>\n",
       "      <td>[[8683, 2311, 1110, 11075, 11763, 10633, 10905...</td>\n",
       "      <td>[[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....</td>\n",
       "      <td>[8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...</td>\n",
       "      <td>[[6884, 10255, 14886, 486, 12861, 9087, 10703,...</td>\n",
       "      <td>[[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....</td>\n",
       "      <td>[6884, 10255, 14886, 13166, 10703, 6884, 14886...</td>\n",
       "      <td>[[6025, 1654, 15853, 8632, 15290, 14175, 8202,...</td>\n",
       "      <td>[[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....</td>\n",
       "      <td>[6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...</td>\n",
       "      <td>[[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...</td>\n",
       "      <td>[[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...</td>\n",
       "      <td>[3356, 2036, 1508, 12301, 261, 15018, 9843, 33...</td>\n",
       "      <td>[[4542, 14855, 11886, 3064, 12706, 69, 13693, ...</td>\n",
       "      <td>[[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...</td>\n",
       "      <td>[4542, 14855, 11886, 4542, 12706, 8038, 4447, ...</td>\n",
       "      <td>[[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...</td>\n",
       "      <td>[[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...</td>\n",
       "      <td>[11259, 4776, 3719, 11390, 16350, 15727, 16350...</td>\n",
       "      <td>[[14463, 11256, 1901, 11739, 15874, 7041, 1212...</td>\n",
       "      <td>[[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....</td>\n",
       "      <td>[14463, 11256, 1901, 13628, 14463, 11305, 1446...</td>\n",
       "      <td>[[7096, 7462, 12750, 15159, 14710, 14336, 8274...</td>\n",
       "      <td>[[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....</td>\n",
       "      <td>[7096, 7462, 12750, 7096, 5053, 14984, 14984, ...</td>\n",
       "      <td>[[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...</td>\n",
       "      <td>[[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....</td>\n",
       "      <td>[12896, 7538, 1889, 12796, 12896, 7896, 16316,...</td>\n",
       "      <td>[[9566, 12583, 4881, 12769, 11388, 2808, 5912,...</td>\n",
       "      <td>[[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...</td>\n",
       "      <td>[9566, 12583, 4881, 9566, 12583, 4766, 9566, 4...</td>\n",
       "      <td>[[11959, 16293, 1028, 6700, 783, 12140, 4377, ...</td>\n",
       "      <td>[[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....</td>\n",
       "      <td>[11959, 16293, 1028, 3858, 16293, 11959, 11959...</td>\n",
       "      <td>[[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...</td>\n",
       "      <td>[[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[14953, 12042, 11637, 14953, 697, 5889, 14953,...</td>\n",
       "      <td>[[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...</td>\n",
       "      <td>[[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....</td>\n",
       "      <td>[5279, 11288, 13838, 5279, 8424, 3820, 5279, 6...</td>\n",
       "      <td>[[12402, 3678, 10405, 7012, 7290, 12500, 5465,...</td>\n",
       "      <td>[[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...</td>\n",
       "      <td>[12402, 3678, 10405, 13983, 12402, 14623, 1398...</td>\n",
       "      <td>[[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...</td>\n",
       "      <td>[[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....</td>\n",
       "      <td>[5364, 11788, 9449, 15678, 4382, 9024, 13675, ...</td>\n",
       "      <td>[[15745, 2628, 10077, 8629, 9147, 3088, 10698,...</td>\n",
       "      <td>[[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...</td>\n",
       "      <td>[15745, 2628, 10077, 9038, 10698, 6214, 13955,...</td>\n",
       "      <td>[[7101, 890, 11950, 11426, 9709, 15133, 3060, ...</td>\n",
       "      <td>[[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....</td>\n",
       "      <td>[7101, 890, 11950, 12057, 322, 9790, 12057, 11...</td>\n",
       "      <td>[[5817, 4198, 2493, 4736, 962, 266, 12247, 953...</td>\n",
       "      <td>[[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...</td>\n",
       "      <td>[5817, 4198, 2493, 13276, 15637, 14206, 4736, ...</td>\n",
       "      <td>[[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...</td>\n",
       "      <td>[[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...</td>\n",
       "      <td>[4730, 6258, 5254, 4185, 3710, 3680, 1427, 79,...</td>\n",
       "      <td>[[12597, 10159, 14164, 11873, 14566, 12669, 74...</td>\n",
       "      <td>[[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...</td>\n",
       "      <td>[12597, 10159, 14164, 2793, 12597, 6186, 12597...</td>\n",
       "      <td>[[15592, 12904, 4700, 13680, 2955, 9554, 15209...</td>\n",
       "      <td>[[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....</td>\n",
       "      <td>[15592, 12904, 4700, 686, 15592, 5758, 15592, ...</td>\n",
       "      <td>[[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...</td>\n",
       "      <td>[[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...</td>\n",
       "      <td>[7589, 6941, 7590, 9583, 5371, 7730, 4143, 958...</td>\n",
       "      <td>[[12096, 11676, 7040, 4053, 9060, 11423, 13517...</td>\n",
       "      <td>[[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...</td>\n",
       "      <td>[12096, 11676, 7040, 12096, 9778, 6117, 12096,...</td>\n",
       "      <td>[[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...</td>\n",
       "      <td>[[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...</td>\n",
       "      <td>[1367, 10938, 5451, 10312, 13, 7282, 6279, 136...</td>\n",
       "      <td>[[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...</td>\n",
       "      <td>[[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...</td>\n",
       "      <td>[11525, 11530, 2788, 11525, 2788, 7622, 13788,...</td>\n",
       "      <td>[[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...</td>\n",
       "      <td>[[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...</td>\n",
       "      <td>[7495, 3117, 6381, 7495, 8202, 5376, 7495, 860...</td>\n",
       "      <td>[[6316, 3458, 15102, 4397, 10966, 6806, 10388,...</td>\n",
       "      <td>[[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...</td>\n",
       "      <td>[6316, 3458, 15102, 6316, 3318, 3458, 5421, 13...</td>\n",
       "      <td>[[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...</td>\n",
       "      <td>[[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...</td>\n",
       "      <td>[9338, 2350, 11394, 2636, 8191, 10598, 9819, 1...</td>\n",
       "      <td>[[13617, 4166, 16213, 12064, 10652, 7512, 1589...</td>\n",
       "      <td>[[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...</td>\n",
       "      <td>[13617, 4166, 16213, 249, 3869, 4290, 13617, 1...</td>\n",
       "      <td>[[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...</td>\n",
       "      <td>[[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...</td>\n",
       "      <td>[14672, 2673, 3001, 8681, 2564, 7488, 8681, 12...</td>\n",
       "      <td>[[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...</td>\n",
       "      <td>[[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...</td>\n",
       "      <td>[75, 12355, 8833, 75, 14877, 8833, 75, 14261, ...</td>\n",
       "      <td>[[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...</td>\n",
       "      <td>[[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...</td>\n",
       "      <td>[9218, 7586, 6883, 11167, 2604, 593, 9218, 155...</td>\n",
       "      <td>[[5845, 11167, 1359, 15100, 5745, 10491, 12367...</td>\n",
       "      <td>[[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...</td>\n",
       "      <td>[5845, 11167, 1359, 2506, 1600, 14844, 9380, 4...</td>\n",
       "      <td>[[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...</td>\n",
       "      <td>[[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...</td>\n",
       "      <td>[77, 7228, 16359, 9584, 8081, 5949, 9584, 1179...</td>\n",
       "      <td>[[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...</td>\n",
       "      <td>[[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...</td>\n",
       "      <td>[9071, 3170, 11447, 11447, 670, 1828, 1125, 11...</td>\n",
       "      <td>[[8468, 14729, 12522, 13882, 7302, 15247, 1488...</td>\n",
       "      <td>[[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....</td>\n",
       "      <td>[8468, 14729, 12522, 13882, 13143, 5910, 13882...</td>\n",
       "      <td>[[10730, 13775, 6168, 13924, 1222, 14050, 1107...</td>\n",
       "      <td>[[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...</td>\n",
       "      <td>[10730, 13775, 6168, 13966, 15701, 13509, 1247...</td>\n",
       "      <td>[[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...</td>\n",
       "      <td>[[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...</td>\n",
       "      <td>[4723, 2531, 12567, 11983, 8563, 9228, 2232, 6...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 8390, 10184, 15497, 8390, 101...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 282, 9329, 6134, 9243, 4368,...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 8171, 8262, 8420, 6608, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>Statement 1 | If G, H and K are groups of orde...</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 11864, 4698, 3798, 6186, ...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 10183, 3848, 8835, 8994, 1...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>[[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....</td>\n",
       "      <td>[15089, 14059, 7132, 9407, 1650, 4592, 1401, 1...</td>\n",
       "      <td>[[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...</td>\n",
       "      <td>[[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...</td>\n",
       "      <td>[9134, 6486, 14238, 7173, 5806, 4303, 5371, 21...</td>\n",
       "      <td>[[12690, 11570, 6680, 14155, 13325, 5575, 1118...</td>\n",
       "      <td>[[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...</td>\n",
       "      <td>[12690, 11570, 6680, 11333, 6717, 6680, 6232, ...</td>\n",
       "      <td>[[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...</td>\n",
       "      <td>[[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...</td>\n",
       "      <td>[1059, 8392, 5148, 6131, 3235, 1059, 15280, 19...</td>\n",
       "      <td>[[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...</td>\n",
       "      <td>[[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...</td>\n",
       "      <td>[9743, 6201, 14077, 2686, 15854, 12531, 15012,...</td>\n",
       "      <td>[[12287, 14119, 14537, 516, 13236, 13027, 6142...</td>\n",
       "      <td>[[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...</td>\n",
       "      <td>[12287, 14119, 14537, 9664, 8039, 2523, 3660, ...</td>\n",
       "      <td>[[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...</td>\n",
       "      <td>[[868.33, 240.19, 224.46, 217.45, 134.61, 127....</td>\n",
       "      <td>[9213, 4399, 6069, 6291, 6966, 2024, 13041, 16...</td>\n",
       "      <td>[[12102, 5877, 3736, 9892, 10966, 12253, 4212,...</td>\n",
       "      <td>[[1050.34, 380.12, 201.91, 168.05, 167.84, 135...</td>\n",
       "      <td>[12102, 5877, 3736, 12102, 381, 7266, 15789, 9...</td>\n",
       "      <td>[[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...</td>\n",
       "      <td>[[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...</td>\n",
       "      <td>[4392, 2843, 3736, 4392, 3736, 14372, 4444, 67...</td>\n",
       "      <td>[[12945, 13423, 10772, 7228, 6222, 8238, 7675,...</td>\n",
       "      <td>[[1365.86, 254.11, 229.52, 216.75, 200.8, 160....</td>\n",
       "      <td>[12945, 13423, 10772, 12945, 13423, 10772, 695...</td>\n",
       "      <td>[[1041, 7507, 11087, 3220, 11767, 11752, 14669...</td>\n",
       "      <td>[[1436.4, 288.32, 274.44, 177.82, 175.78, 169....</td>\n",
       "      <td>[1041, 7507, 11087, 4667, 11087, 1178, 6810, 8...</td>\n",
       "      <td>[[11248, 13423, 15319, 12322, 15392, 12879, 15...</td>\n",
       "      <td>[[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...</td>\n",
       "      <td>[11248, 13423, 15319, 13423, 11248, 6665, 3149...</td>\n",
       "      <td>[[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...</td>\n",
       "      <td>[[1326.71, 937.5, 207.55, 193.66, 179.61, 165....</td>\n",
       "      <td>[15567, 7214, 6812, 16123, 12313, 15567, 15887...</td>\n",
       "      <td>[[10716, 8610, 13870, 14717, 6266, 10404, 7546...</td>\n",
       "      <td>[[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...</td>\n",
       "      <td>[10716, 8610, 13870, 10716, 14717, 8610, 2234,...</td>\n",
       "      <td>[[16028, 10480, 14919, 4500, 2717, 4631, 4005,...</td>\n",
       "      <td>[[1902.24, 718.23, 386.15, 328.9, 205.48, 198....</td>\n",
       "      <td>[16028, 10480, 14919, 4500, 16028, 10480, 1295...</td>\n",
       "      <td>[[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...</td>\n",
       "      <td>[[1963.47, 777.35, 402.1, 298.72, 265.57, 229....</td>\n",
       "      <td>[7127, 7921, 9095, 1935, 11527, 1003, 6492, 50...</td>\n",
       "      <td>[[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...</td>\n",
       "      <td>[[2052.88, 763.03, 348.91, 271.26, 259.58, 222...</td>\n",
       "      <td>[3851, 15394, 12685, 10793, 7373, 15897, 7373,...</td>\n",
       "      <td>[[12025, 11046, 3543, 14445, 6075, 7417, 11438...</td>\n",
       "      <td>[[2130.77, 634.11, 405.05, 283.16, 279.33, 242...</td>\n",
       "      <td>[12025, 11046, 3543, 8475, 10441, 5111, 6655, ...</td>\n",
       "      <td>[[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...</td>\n",
       "      <td>[[2028.8, 781.4, 534.86, 264.19, 252.53, 251.0...</td>\n",
       "      <td>[6631, 743, 5052, 292, 11527, 13785, 2045, 292...</td>\n",
       "      <td>[[4138, 13557, 15170, 2788, 4967, 15463, 5910,...</td>\n",
       "      <td>[[2020.26, 856.65, 758.71, 290.22, 261.91, 250...</td>\n",
       "      <td>[4138, 13557, 15170, 14723, 1003, 5111, 4366, ...</td>\n",
       "      <td>[[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...</td>\n",
       "      <td>[[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....</td>\n",
       "      <td>[15056, 2037, 630, 10752, 8962, 16143, 5112, 1...</td>\n",
       "      <td>[[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...</td>\n",
       "      <td>[[2067.19, 1388.15, 290.23, 256.19, 256.17, 24...</td>\n",
       "      <td>[3956, 6961, 8321, 932, 5286, 8797, 2385, 9382...</td>\n",
       "      <td>[[1802, 14391, 14836, 4182, 15109, 14832, 395,...</td>\n",
       "      <td>[[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...</td>\n",
       "      <td>[1802, 14391, 14836, 12205, 3848, 501, 3650, 1...</td>\n",
       "      <td>[[7479, 5149, 14186, 14325, 15861, 15298, 1734...</td>\n",
       "      <td>[[2302.48, 919.27, 913.31, 362.69, 330.19, 330...</td>\n",
       "      <td>[7479, 5149, 14186, 14325, 3627, 484, 13749, 1...</td>\n",
       "      <td>[[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...</td>\n",
       "      <td>[[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...</td>\n",
       "      <td>[3880, 1421, 1608, 3880, 1608, 9944, 8636, 142...</td>\n",
       "      <td>[[15873, 7914, 11003, 7428, 15345, 5816, 14312...</td>\n",
       "      <td>[[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...</td>\n",
       "      <td>[15873, 7914, 11003, 15873, 11003, 7914, 15157...</td>\n",
       "      <td>[[13234, 888, 11147, 8912, 14708, 3818, 9138, ...</td>\n",
       "      <td>[[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....</td>\n",
       "      <td>[13234, 888, 11147, 13644, 12037, 8012, 12169,...</td>\n",
       "      <td>[[6576, 4257, 10471, 12044, 14532, 7826, 1451,...</td>\n",
       "      <td>[[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....</td>\n",
       "      <td>[6576, 4257, 10471, 6576, 15575, 3030, 4226, 9...</td>\n",
       "      <td>[[5518, 4210, 10188, 8146, 14202, 12331, 884, ...</td>\n",
       "      <td>[[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...</td>\n",
       "      <td>[5518, 4210, 10188, 5518, 4742, 4210, 5518, 47...</td>\n",
       "      <td>[[5252, 11557, 11619, 4107, 14508, 3087, 12114...</td>\n",
       "      <td>[[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...</td>\n",
       "      <td>[5252, 11557, 11619, 5252, 11557, 11619, 5252,...</td>\n",
       "      <td>[[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...</td>\n",
       "      <td>[[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....</td>\n",
       "      <td>[1231, 9366, 15754, 4171, 1231, 12948, 1231, 5...</td>\n",
       "      <td>[[5514, 2461, 12467, 10364, 7156, 14085, 14823...</td>\n",
       "      <td>[[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...</td>\n",
       "      <td>[5514, 2461, 12467, 10258, 10364, 5514, 10364,...</td>\n",
       "      <td>[[4923, 11894, 10982, 11028, 9940, 2403, 5138,...</td>\n",
       "      <td>[[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...</td>\n",
       "      <td>[4923, 11894, 10982, 11382, 4923, 11894, 11894...</td>\n",
       "      <td>[[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...</td>\n",
       "      <td>[[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...</td>\n",
       "      <td>[4526, 1054, 15802, 4526, 10930, 1054, 4526, 1...</td>\n",
       "      <td>[[3101, 11995, 13952, 3748, 11799, 7547, 14552...</td>\n",
       "      <td>[[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...</td>\n",
       "      <td>[3101, 11995, 13952, 7876, 3101, 7844, 3101, 1...</td>\n",
       "      <td>[[8683, 2311, 1110, 11075, 11763, 10633, 10905...</td>\n",
       "      <td>[[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....</td>\n",
       "      <td>[8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...</td>\n",
       "      <td>[[6884, 10255, 14886, 486, 12861, 9087, 10703,...</td>\n",
       "      <td>[[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....</td>\n",
       "      <td>[6884, 10255, 14886, 13166, 10703, 6884, 14886...</td>\n",
       "      <td>[[6025, 1654, 15853, 8632, 15290, 14175, 8202,...</td>\n",
       "      <td>[[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....</td>\n",
       "      <td>[6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...</td>\n",
       "      <td>[[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...</td>\n",
       "      <td>[[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...</td>\n",
       "      <td>[3356, 2036, 1508, 12301, 261, 15018, 9843, 33...</td>\n",
       "      <td>[[4542, 14855, 11886, 3064, 12706, 69, 13693, ...</td>\n",
       "      <td>[[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...</td>\n",
       "      <td>[4542, 14855, 11886, 4542, 12706, 8038, 4447, ...</td>\n",
       "      <td>[[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...</td>\n",
       "      <td>[[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...</td>\n",
       "      <td>[11259, 4776, 3719, 11390, 16350, 15727, 16350...</td>\n",
       "      <td>[[14463, 11256, 1901, 11739, 15874, 7041, 1212...</td>\n",
       "      <td>[[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....</td>\n",
       "      <td>[14463, 11256, 1901, 13628, 14463, 11305, 1446...</td>\n",
       "      <td>[[7096, 7462, 12750, 15159, 14710, 14336, 8274...</td>\n",
       "      <td>[[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....</td>\n",
       "      <td>[7096, 7462, 12750, 7096, 5053, 14984, 14984, ...</td>\n",
       "      <td>[[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...</td>\n",
       "      <td>[[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....</td>\n",
       "      <td>[12896, 7538, 1889, 12796, 12896, 7896, 16316,...</td>\n",
       "      <td>[[9566, 12583, 4881, 12769, 11388, 2808, 5912,...</td>\n",
       "      <td>[[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...</td>\n",
       "      <td>[9566, 12583, 4881, 9566, 12583, 4766, 9566, 4...</td>\n",
       "      <td>[[11959, 16293, 1028, 6700, 783, 12140, 4377, ...</td>\n",
       "      <td>[[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....</td>\n",
       "      <td>[11959, 16293, 1028, 3858, 16293, 11959, 11959...</td>\n",
       "      <td>[[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...</td>\n",
       "      <td>[[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[14953, 12042, 11637, 14953, 697, 5889, 14953,...</td>\n",
       "      <td>[[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...</td>\n",
       "      <td>[[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....</td>\n",
       "      <td>[5279, 11288, 13838, 5279, 8424, 3820, 5279, 6...</td>\n",
       "      <td>[[12402, 3678, 10405, 7012, 7290, 12500, 5465,...</td>\n",
       "      <td>[[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...</td>\n",
       "      <td>[12402, 3678, 10405, 13983, 12402, 14623, 1398...</td>\n",
       "      <td>[[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...</td>\n",
       "      <td>[[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....</td>\n",
       "      <td>[5364, 11788, 9449, 15678, 4382, 9024, 13675, ...</td>\n",
       "      <td>[[15745, 2628, 10077, 8629, 9147, 3088, 10698,...</td>\n",
       "      <td>[[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...</td>\n",
       "      <td>[15745, 2628, 10077, 9038, 10698, 6214, 13955,...</td>\n",
       "      <td>[[7101, 890, 11950, 11426, 9709, 15133, 3060, ...</td>\n",
       "      <td>[[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....</td>\n",
       "      <td>[7101, 890, 11950, 12057, 322, 9790, 12057, 11...</td>\n",
       "      <td>[[5817, 4198, 2493, 4736, 962, 266, 12247, 953...</td>\n",
       "      <td>[[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...</td>\n",
       "      <td>[5817, 4198, 2493, 13276, 15637, 14206, 4736, ...</td>\n",
       "      <td>[[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...</td>\n",
       "      <td>[[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...</td>\n",
       "      <td>[4730, 6258, 5254, 4185, 3710, 3680, 1427, 79,...</td>\n",
       "      <td>[[12597, 10159, 14164, 11873, 14566, 12669, 74...</td>\n",
       "      <td>[[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...</td>\n",
       "      <td>[12597, 10159, 14164, 2793, 12597, 6186, 12597...</td>\n",
       "      <td>[[15592, 12904, 4700, 13680, 2955, 9554, 15209...</td>\n",
       "      <td>[[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....</td>\n",
       "      <td>[15592, 12904, 4700, 686, 15592, 5758, 15592, ...</td>\n",
       "      <td>[[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...</td>\n",
       "      <td>[[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...</td>\n",
       "      <td>[7589, 6941, 7590, 9583, 5371, 7730, 4143, 958...</td>\n",
       "      <td>[[12096, 11676, 7040, 4053, 9060, 11423, 13517...</td>\n",
       "      <td>[[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...</td>\n",
       "      <td>[12096, 11676, 7040, 12096, 9778, 6117, 12096,...</td>\n",
       "      <td>[[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...</td>\n",
       "      <td>[[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...</td>\n",
       "      <td>[1367, 10938, 5451, 10312, 13, 7282, 6279, 136...</td>\n",
       "      <td>[[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...</td>\n",
       "      <td>[[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...</td>\n",
       "      <td>[11525, 11530, 2788, 11525, 2788, 7622, 13788,...</td>\n",
       "      <td>[[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...</td>\n",
       "      <td>[[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...</td>\n",
       "      <td>[7495, 3117, 6381, 7495, 8202, 5376, 7495, 860...</td>\n",
       "      <td>[[6316, 3458, 15102, 4397, 10966, 6806, 10388,...</td>\n",
       "      <td>[[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...</td>\n",
       "      <td>[6316, 3458, 15102, 6316, 3318, 3458, 5421, 13...</td>\n",
       "      <td>[[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...</td>\n",
       "      <td>[[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...</td>\n",
       "      <td>[9338, 2350, 11394, 2636, 8191, 10598, 9819, 1...</td>\n",
       "      <td>[[13617, 4166, 16213, 12064, 10652, 7512, 1589...</td>\n",
       "      <td>[[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...</td>\n",
       "      <td>[13617, 4166, 16213, 249, 3869, 4290, 13617, 1...</td>\n",
       "      <td>[[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...</td>\n",
       "      <td>[[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...</td>\n",
       "      <td>[14672, 2673, 3001, 8681, 2564, 7488, 8681, 12...</td>\n",
       "      <td>[[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...</td>\n",
       "      <td>[[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...</td>\n",
       "      <td>[75, 12355, 8833, 75, 14877, 8833, 75, 14261, ...</td>\n",
       "      <td>[[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...</td>\n",
       "      <td>[[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...</td>\n",
       "      <td>[9218, 7586, 6883, 11167, 2604, 593, 9218, 155...</td>\n",
       "      <td>[[5845, 11167, 1359, 15100, 5745, 10491, 12367...</td>\n",
       "      <td>[[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...</td>\n",
       "      <td>[5845, 11167, 1359, 2506, 1600, 14844, 9380, 4...</td>\n",
       "      <td>[[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...</td>\n",
       "      <td>[[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...</td>\n",
       "      <td>[77, 7228, 16359, 9584, 8081, 5949, 9584, 1179...</td>\n",
       "      <td>[[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...</td>\n",
       "      <td>[[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...</td>\n",
       "      <td>[9071, 3170, 11447, 11447, 670, 1828, 1125, 11...</td>\n",
       "      <td>[[8468, 14729, 12522, 13882, 7302, 15247, 1488...</td>\n",
       "      <td>[[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....</td>\n",
       "      <td>[8468, 14729, 12522, 13882, 13143, 5910, 13882...</td>\n",
       "      <td>[[10730, 13775, 6168, 13924, 1222, 14050, 1107...</td>\n",
       "      <td>[[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...</td>\n",
       "      <td>[10730, 13775, 6168, 13966, 15701, 13509, 1247...</td>\n",
       "      <td>[[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...</td>\n",
       "      <td>[[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...</td>\n",
       "      <td>[4723, 2531, 12567, 11983, 8563, 9228, 2232, 6...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 8390, 10184, 15497, 8390, 101...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 282, 9329, 6134, 9243, 4368,...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 8171, 8262, 8420, 6608, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>(Z,*) is a group with a*b = a+b+1 for all a, b...</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 9649, 7063, 8920, 8648, 5...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 3380, 13826, 12340, 6368, ...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>[[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....</td>\n",
       "      <td>[15089, 14059, 7132, 3380, 6311, 14043, 14239,...</td>\n",
       "      <td>[[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...</td>\n",
       "      <td>[[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...</td>\n",
       "      <td>[9134, 6486, 14238, 967, 9889, 9627, 9331, 115...</td>\n",
       "      <td>[[12690, 11570, 6680, 14155, 13325, 5575, 1118...</td>\n",
       "      <td>[[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...</td>\n",
       "      <td>[12690, 11570, 6680, 960, 13580, 6717, 8791, 2...</td>\n",
       "      <td>[[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...</td>\n",
       "      <td>[[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...</td>\n",
       "      <td>[1059, 8392, 5148, 3235, 2066, 4706, 3701, 134...</td>\n",
       "      <td>[[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...</td>\n",
       "      <td>[[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...</td>\n",
       "      <td>[9743, 6201, 14077, 15854, 12062, 14445, 5260,...</td>\n",
       "      <td>[[12287, 14119, 14537, 516, 13236, 13027, 6142...</td>\n",
       "      <td>[[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...</td>\n",
       "      <td>[12287, 14119, 14537, 9664, 12287, 15564, 2686...</td>\n",
       "      <td>[[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...</td>\n",
       "      <td>[[868.33, 240.19, 224.46, 217.45, 134.61, 127....</td>\n",
       "      <td>[9213, 4399, 6069, 6291, 4311, 9213, 13451, 30...</td>\n",
       "      <td>[[12102, 5877, 3736, 9892, 10966, 12253, 4212,...</td>\n",
       "      <td>[[1050.34, 380.12, 201.91, 168.05, 167.84, 135...</td>\n",
       "      <td>[12102, 5877, 3736, 12102, 381, 4148, 1435, 13...</td>\n",
       "      <td>[[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...</td>\n",
       "      <td>[[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...</td>\n",
       "      <td>[4392, 2843, 3736, 4392, 3736, 14372, 3031, 12...</td>\n",
       "      <td>[[12945, 13423, 10772, 7228, 6222, 8238, 7675,...</td>\n",
       "      <td>[[1365.86, 254.11, 229.52, 216.75, 200.8, 160....</td>\n",
       "      <td>[12945, 13423, 10772, 12945, 13423, 10772, 161...</td>\n",
       "      <td>[[1041, 7507, 11087, 3220, 11767, 11752, 14669...</td>\n",
       "      <td>[[1436.4, 288.32, 274.44, 177.82, 175.78, 169....</td>\n",
       "      <td>[1041, 7507, 11087, 4667, 11087, 1178, 6810, 1...</td>\n",
       "      <td>[[11248, 13423, 15319, 12322, 15392, 12879, 15...</td>\n",
       "      <td>[[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...</td>\n",
       "      <td>[11248, 13423, 15319, 13423, 11248, 9076, 1588...</td>\n",
       "      <td>[[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...</td>\n",
       "      <td>[[1326.71, 937.5, 207.55, 193.66, 179.61, 165....</td>\n",
       "      <td>[15567, 7214, 6812, 16123, 15567, 12313, 15887...</td>\n",
       "      <td>[[10716, 8610, 13870, 14717, 6266, 10404, 7546...</td>\n",
       "      <td>[[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...</td>\n",
       "      <td>[10716, 8610, 13870, 10716, 14717, 8610, 2234,...</td>\n",
       "      <td>[[16028, 10480, 14919, 4500, 2717, 4631, 4005,...</td>\n",
       "      <td>[[1902.23, 718.23, 386.15, 328.9, 205.48, 198....</td>\n",
       "      <td>[16028, 10480, 14919, 4500, 16028, 10480, 1033...</td>\n",
       "      <td>[[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...</td>\n",
       "      <td>[[1963.47, 777.35, 402.1, 298.72, 265.57, 229....</td>\n",
       "      <td>[7127, 7921, 9095, 12546, 5373, 1003, 6492, 70...</td>\n",
       "      <td>[[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...</td>\n",
       "      <td>[[2052.88, 763.03, 348.91, 271.26, 259.58, 222...</td>\n",
       "      <td>[3851, 15394, 12685, 11527, 7373, 10793, 7373,...</td>\n",
       "      <td>[[12025, 11046, 3543, 14445, 6075, 7417, 11438...</td>\n",
       "      <td>[[2130.77, 634.11, 405.05, 283.16, 279.33, 242...</td>\n",
       "      <td>[12025, 11046, 3543, 10441, 15771, 4346, 4346,...</td>\n",
       "      <td>[[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...</td>\n",
       "      <td>[[2028.8, 781.4, 534.86, 264.19, 252.53, 251.0...</td>\n",
       "      <td>[6631, 743, 5052, 10949, 11527, 8684, 13451, 0...</td>\n",
       "      <td>[[4138, 13557, 15170, 2788, 4967, 15463, 5910,...</td>\n",
       "      <td>[[2020.26, 856.65, 758.71, 290.22, 261.91, 250...</td>\n",
       "      <td>[4138, 13557, 15170, 11527, 4782, 3461, 2286, ...</td>\n",
       "      <td>[[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...</td>\n",
       "      <td>[[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....</td>\n",
       "      <td>[15056, 2037, 630, 4454, 4384, 13017, 16364, 1...</td>\n",
       "      <td>[[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...</td>\n",
       "      <td>[[2067.19, 1388.15, 290.23, 256.19, 256.17, 24...</td>\n",
       "      <td>[3956, 6961, 8321, 13725, 5969, 4572, 6083, 11...</td>\n",
       "      <td>[[1802, 14391, 14836, 4182, 15109, 14832, 395,...</td>\n",
       "      <td>[[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...</td>\n",
       "      <td>[1802, 14391, 14836, 3932, 14448, 11326, 16317...</td>\n",
       "      <td>[[7479, 5149, 14186, 14325, 15861, 15298, 1734...</td>\n",
       "      <td>[[2302.48, 919.27, 913.31, 362.69, 330.19, 330...</td>\n",
       "      <td>[7479, 5149, 14186, 208, 15298, 14325, 15298, ...</td>\n",
       "      <td>[[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...</td>\n",
       "      <td>[[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...</td>\n",
       "      <td>[3880, 1421, 1608, 3880, 9944, 1608, 3121, 388...</td>\n",
       "      <td>[[15873, 7914, 11003, 7428, 15345, 5816, 14312...</td>\n",
       "      <td>[[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...</td>\n",
       "      <td>[15873, 7914, 11003, 15873, 11003, 7914, 3558,...</td>\n",
       "      <td>[[13234, 888, 11147, 8912, 14708, 3818, 9138, ...</td>\n",
       "      <td>[[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....</td>\n",
       "      <td>[13234, 888, 11147, 4598, 13234, 13530, 15293,...</td>\n",
       "      <td>[[6576, 4257, 10471, 12044, 14532, 7826, 1451,...</td>\n",
       "      <td>[[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....</td>\n",
       "      <td>[6576, 4257, 10471, 6576, 4257, 12708, 6576, 5...</td>\n",
       "      <td>[[5518, 4210, 10188, 8146, 14202, 12331, 884, ...</td>\n",
       "      <td>[[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...</td>\n",
       "      <td>[5518, 4210, 10188, 5518, 4742, 7240, 14596, 5...</td>\n",
       "      <td>[[5252, 11557, 11619, 4107, 14508, 3087, 12114...</td>\n",
       "      <td>[[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...</td>\n",
       "      <td>[5252, 11557, 11619, 5252, 11557, 11619, 5252,...</td>\n",
       "      <td>[[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...</td>\n",
       "      <td>[[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....</td>\n",
       "      <td>[1231, 9366, 15754, 4171, 6318, 1231, 1231, 41...</td>\n",
       "      <td>[[5514, 2461, 12467, 10364, 7156, 14085, 14823...</td>\n",
       "      <td>[[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...</td>\n",
       "      <td>[5514, 2461, 12467, 10364, 10258, 5514, 10258,...</td>\n",
       "      <td>[[4923, 11894, 10982, 11028, 9940, 2403, 5138,...</td>\n",
       "      <td>[[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...</td>\n",
       "      <td>[4923, 11894, 10982, 11382, 15743, 11894, 1189...</td>\n",
       "      <td>[[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...</td>\n",
       "      <td>[[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...</td>\n",
       "      <td>[4526, 1054, 15802, 10930, 4526, 4450, 4526, 1...</td>\n",
       "      <td>[[3101, 11995, 13952, 3748, 11799, 7547, 14552...</td>\n",
       "      <td>[[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...</td>\n",
       "      <td>[3101, 11995, 13952, 7876, 3101, 7844, 3101, 1...</td>\n",
       "      <td>[[8683, 2311, 1110, 11075, 11763, 10633, 10905...</td>\n",
       "      <td>[[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....</td>\n",
       "      <td>[8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...</td>\n",
       "      <td>[[6884, 10255, 14886, 486, 12861, 9087, 10703,...</td>\n",
       "      <td>[[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....</td>\n",
       "      <td>[6884, 10255, 14886, 13166, 10703, 6884, 14886...</td>\n",
       "      <td>[[6025, 1654, 15853, 8632, 15290, 14175, 8202,...</td>\n",
       "      <td>[[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....</td>\n",
       "      <td>[6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...</td>\n",
       "      <td>[[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...</td>\n",
       "      <td>[[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...</td>\n",
       "      <td>[3356, 2036, 1508, 12301, 261, 15018, 261, 984...</td>\n",
       "      <td>[[4542, 14855, 11886, 3064, 12706, 69, 13693, ...</td>\n",
       "      <td>[[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...</td>\n",
       "      <td>[4542, 14855, 11886, 4542, 12706, 8038, 4447, ...</td>\n",
       "      <td>[[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...</td>\n",
       "      <td>[[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...</td>\n",
       "      <td>[11259, 4776, 3719, 11390, 16350, 12299, 16350...</td>\n",
       "      <td>[[14463, 11256, 1901, 11739, 15874, 7041, 1212...</td>\n",
       "      <td>[[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....</td>\n",
       "      <td>[14463, 11256, 1901, 13628, 12260, 14463, 1446...</td>\n",
       "      <td>[[7096, 7462, 12750, 15159, 14710, 14336, 8274...</td>\n",
       "      <td>[[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....</td>\n",
       "      <td>[7096, 7462, 12750, 7096, 9729, 6420, 7096, 11...</td>\n",
       "      <td>[[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...</td>\n",
       "      <td>[[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....</td>\n",
       "      <td>[12896, 7538, 1889, 12796, 7896, 12896, 12896,...</td>\n",
       "      <td>[[9566, 12583, 4881, 12769, 11388, 2808, 5912,...</td>\n",
       "      <td>[[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...</td>\n",
       "      <td>[9566, 12583, 4881, 753, 9566, 12583, 14863, 9...</td>\n",
       "      <td>[[11959, 16293, 1028, 6700, 783, 12140, 4377, ...</td>\n",
       "      <td>[[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....</td>\n",
       "      <td>[11959, 16293, 1028, 3858, 16293, 5795, 6359, ...</td>\n",
       "      <td>[[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...</td>\n",
       "      <td>[[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[14953, 12042, 11637, 14953, 6306, 16361, 1495...</td>\n",
       "      <td>[[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...</td>\n",
       "      <td>[[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....</td>\n",
       "      <td>[5279, 11288, 13838, 10395, 3820, 2704, 7953, ...</td>\n",
       "      <td>[[12402, 3678, 10405, 7012, 7290, 12500, 5465,...</td>\n",
       "      <td>[[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...</td>\n",
       "      <td>[12402, 3678, 10405, 12402, 1315, 1095, 12402,...</td>\n",
       "      <td>[[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...</td>\n",
       "      <td>[[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....</td>\n",
       "      <td>[5364, 11788, 9449, 5714, 4846, 3222, 8280, 48...</td>\n",
       "      <td>[[15745, 2628, 10077, 8629, 9147, 3088, 10698,...</td>\n",
       "      <td>[[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...</td>\n",
       "      <td>[15745, 2628, 10077, 9038, 13955, 14932, 13955...</td>\n",
       "      <td>[[7101, 890, 11950, 11426, 9709, 15133, 3060, ...</td>\n",
       "      <td>[[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....</td>\n",
       "      <td>[7101, 890, 11950, 12057, 322, 13730, 4684, 12...</td>\n",
       "      <td>[[5817, 4198, 2493, 4736, 962, 266, 12247, 953...</td>\n",
       "      <td>[[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...</td>\n",
       "      <td>[5817, 4198, 2493, 2900, 15525, 15165, 3077, 3...</td>\n",
       "      <td>[[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...</td>\n",
       "      <td>[[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...</td>\n",
       "      <td>[4730, 6258, 5254, 4730, 12740, 7272, 13839, 4...</td>\n",
       "      <td>[[12597, 10159, 14164, 11873, 14566, 12669, 74...</td>\n",
       "      <td>[[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...</td>\n",
       "      <td>[12597, 10159, 14164, 2793, 14164, 6186, 2793,...</td>\n",
       "      <td>[[15592, 12904, 4700, 13680, 2955, 9554, 15209...</td>\n",
       "      <td>[[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....</td>\n",
       "      <td>[15592, 12904, 4700, 686, 15592, 1067, 15592, ...</td>\n",
       "      <td>[[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...</td>\n",
       "      <td>[[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...</td>\n",
       "      <td>[7589, 6941, 7590, 178, 5371, 9058, 9583, 8424...</td>\n",
       "      <td>[[12096, 11676, 7040, 4053, 9060, 11423, 13517...</td>\n",
       "      <td>[[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...</td>\n",
       "      <td>[12096, 11676, 7040, 12096, 9778, 4053, 12096,...</td>\n",
       "      <td>[[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...</td>\n",
       "      <td>[[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...</td>\n",
       "      <td>[1367, 10938, 5451, 8286, 7282, 9743, 1367, 76...</td>\n",
       "      <td>[[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...</td>\n",
       "      <td>[[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...</td>\n",
       "      <td>[11525, 11530, 2788, 11525, 2788, 7622, 11525,...</td>\n",
       "      <td>[[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...</td>\n",
       "      <td>[[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...</td>\n",
       "      <td>[7495, 3117, 6381, 7495, 8202, 13140, 6972, 11...</td>\n",
       "      <td>[[6316, 3458, 15102, 4397, 10966, 6806, 10388,...</td>\n",
       "      <td>[[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...</td>\n",
       "      <td>[6316, 3458, 15102, 6316, 3318, 3458, 6316, 83...</td>\n",
       "      <td>[[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...</td>\n",
       "      <td>[[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...</td>\n",
       "      <td>[9338, 2350, 11394, 2636, 9338, 8191, 9034, 67...</td>\n",
       "      <td>[[13617, 4166, 16213, 12064, 10652, 7512, 1589...</td>\n",
       "      <td>[[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...</td>\n",
       "      <td>[13617, 4166, 16213, 249, 3869, 6952, 12754, 8...</td>\n",
       "      <td>[[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...</td>\n",
       "      <td>[[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...</td>\n",
       "      <td>[14672, 2673, 3001, 8681, 2564, 13451, 14722, ...</td>\n",
       "      <td>[[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...</td>\n",
       "      <td>[[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...</td>\n",
       "      <td>[75, 12355, 8833, 75, 8833, 11574, 15086, 75, ...</td>\n",
       "      <td>[[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...</td>\n",
       "      <td>[[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...</td>\n",
       "      <td>[9218, 7586, 6883, 11167, 2604, 9601, 7302, 92...</td>\n",
       "      <td>[[5845, 11167, 1359, 15100, 5745, 10491, 12367...</td>\n",
       "      <td>[[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...</td>\n",
       "      <td>[5845, 11167, 1359, 2506, 1600, 3944, 16045, 5...</td>\n",
       "      <td>[[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...</td>\n",
       "      <td>[[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...</td>\n",
       "      <td>[77, 7228, 16359, 6192, 2406, 8193, 11819, 619...</td>\n",
       "      <td>[[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...</td>\n",
       "      <td>[[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...</td>\n",
       "      <td>[9071, 3170, 11447, 11359, 988, 13414, 13231, ...</td>\n",
       "      <td>[[8468, 14729, 12522, 13882, 7302, 15247, 1488...</td>\n",
       "      <td>[[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....</td>\n",
       "      <td>[8468, 14729, 12522, 12449, 5494, 2795, 3701, ...</td>\n",
       "      <td>[[10730, 13775, 6168, 13924, 1222, 14050, 1107...</td>\n",
       "      <td>[[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...</td>\n",
       "      <td>[10730, 13775, 6168, 6921, 6694, 14050, 8762, ...</td>\n",
       "      <td>[[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...</td>\n",
       "      <td>[[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...</td>\n",
       "      <td>[4723, 2531, 12567, 15916, 11406, 4029, 12899,...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 4957, 14957, 3567, 10184, 517...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 1416, 282, 9243, 9243, 282, ...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 15048, 6608, 7327, 15890...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>Statement 1 | For any two groups G and G', the...</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 11864, 4698, 3798, 6186, ...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 10183, 3848, 8835, 8994, 1...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>[[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....</td>\n",
       "      <td>[15089, 14059, 7132, 9407, 1650, 4592, 1401, 1...</td>\n",
       "      <td>[[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...</td>\n",
       "      <td>[[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...</td>\n",
       "      <td>[9134, 6486, 14238, 7173, 5806, 4303, 5371, 21...</td>\n",
       "      <td>[[12690, 11570, 6680, 14155, 13325, 5575, 1118...</td>\n",
       "      <td>[[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...</td>\n",
       "      <td>[12690, 11570, 6680, 11333, 6717, 6680, 6232, ...</td>\n",
       "      <td>[[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...</td>\n",
       "      <td>[[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...</td>\n",
       "      <td>[1059, 8392, 5148, 6131, 3235, 1059, 15280, 19...</td>\n",
       "      <td>[[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...</td>\n",
       "      <td>[[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...</td>\n",
       "      <td>[9743, 6201, 14077, 2686, 15854, 12531, 15012,...</td>\n",
       "      <td>[[12287, 14119, 14537, 516, 13236, 13027, 6142...</td>\n",
       "      <td>[[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...</td>\n",
       "      <td>[12287, 14119, 14537, 9664, 8039, 2523, 3660, ...</td>\n",
       "      <td>[[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...</td>\n",
       "      <td>[[868.33, 240.19, 224.46, 217.45, 134.61, 127....</td>\n",
       "      <td>[9213, 4399, 6069, 6291, 6966, 2024, 13041, 16...</td>\n",
       "      <td>[[12102, 5877, 3736, 9892, 10966, 12253, 4212,...</td>\n",
       "      <td>[[1050.34, 380.12, 201.91, 168.05, 167.84, 135...</td>\n",
       "      <td>[12102, 5877, 3736, 12102, 381, 7266, 15789, 9...</td>\n",
       "      <td>[[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...</td>\n",
       "      <td>[[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...</td>\n",
       "      <td>[4392, 2843, 3736, 4392, 3736, 14372, 4444, 67...</td>\n",
       "      <td>[[12945, 13423, 10772, 7228, 6222, 8238, 7675,...</td>\n",
       "      <td>[[1365.86, 254.11, 229.52, 216.75, 200.8, 160....</td>\n",
       "      <td>[12945, 13423, 10772, 12945, 13423, 10772, 695...</td>\n",
       "      <td>[[1041, 7507, 11087, 3220, 11767, 11752, 14669...</td>\n",
       "      <td>[[1436.4, 288.32, 274.44, 177.82, 175.78, 169....</td>\n",
       "      <td>[1041, 7507, 11087, 4667, 11087, 1178, 6810, 8...</td>\n",
       "      <td>[[11248, 13423, 15319, 12322, 15392, 12879, 15...</td>\n",
       "      <td>[[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...</td>\n",
       "      <td>[11248, 13423, 15319, 13423, 11248, 6665, 3149...</td>\n",
       "      <td>[[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...</td>\n",
       "      <td>[[1326.71, 937.5, 207.55, 193.66, 179.61, 165....</td>\n",
       "      <td>[15567, 7214, 6812, 16123, 12313, 15567, 15887...</td>\n",
       "      <td>[[10716, 8610, 13870, 14717, 6266, 10404, 7546...</td>\n",
       "      <td>[[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...</td>\n",
       "      <td>[10716, 8610, 13870, 10716, 14717, 8610, 2234,...</td>\n",
       "      <td>[[16028, 10480, 14919, 4500, 2717, 4631, 4005,...</td>\n",
       "      <td>[[1902.23, 718.23, 386.15, 328.9, 205.48, 198....</td>\n",
       "      <td>[16028, 10480, 14919, 4500, 16028, 10480, 1295...</td>\n",
       "      <td>[[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...</td>\n",
       "      <td>[[1963.47, 777.35, 402.1, 298.72, 265.57, 229....</td>\n",
       "      <td>[7127, 7921, 9095, 1935, 11527, 1003, 6492, 50...</td>\n",
       "      <td>[[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...</td>\n",
       "      <td>[[2052.88, 763.03, 348.91, 271.26, 259.58, 222...</td>\n",
       "      <td>[3851, 15394, 12685, 10793, 7373, 15897, 7373,...</td>\n",
       "      <td>[[12025, 11046, 3543, 14445, 6075, 7417, 11438...</td>\n",
       "      <td>[[2130.78, 634.11, 405.05, 283.16, 279.33, 242...</td>\n",
       "      <td>[12025, 11046, 3543, 8475, 10441, 5111, 6655, ...</td>\n",
       "      <td>[[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...</td>\n",
       "      <td>[[2028.81, 781.4, 534.86, 264.19, 252.53, 251....</td>\n",
       "      <td>[6631, 743, 5052, 292, 11527, 13785, 2045, 292...</td>\n",
       "      <td>[[4138, 13557, 15170, 2788, 4967, 15463, 5910,...</td>\n",
       "      <td>[[2020.26, 856.65, 758.72, 290.22, 261.91, 250...</td>\n",
       "      <td>[4138, 13557, 15170, 14723, 1003, 5111, 4366, ...</td>\n",
       "      <td>[[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...</td>\n",
       "      <td>[[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....</td>\n",
       "      <td>[15056, 2037, 630, 10752, 8962, 16143, 5112, 1...</td>\n",
       "      <td>[[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...</td>\n",
       "      <td>[[2067.18, 1388.15, 290.23, 256.19, 256.17, 24...</td>\n",
       "      <td>[3956, 6961, 8321, 932, 5286, 8797, 2385, 9382...</td>\n",
       "      <td>[[1802, 14391, 14836, 4182, 15109, 14832, 395,...</td>\n",
       "      <td>[[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...</td>\n",
       "      <td>[1802, 14391, 14836, 12205, 3848, 501, 3650, 1...</td>\n",
       "      <td>[[7479, 5149, 14186, 14325, 15861, 15298, 1734...</td>\n",
       "      <td>[[2302.48, 919.27, 913.31, 362.69, 330.19, 330...</td>\n",
       "      <td>[7479, 5149, 14186, 14325, 3627, 484, 13749, 1...</td>\n",
       "      <td>[[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...</td>\n",
       "      <td>[[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...</td>\n",
       "      <td>[3880, 1421, 1608, 3880, 1608, 9944, 8636, 142...</td>\n",
       "      <td>[[15873, 7914, 11003, 7428, 15345, 5816, 14312...</td>\n",
       "      <td>[[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...</td>\n",
       "      <td>[15873, 7914, 11003, 15873, 11003, 7914, 15157...</td>\n",
       "      <td>[[13234, 888, 11147, 8912, 14708, 3818, 9138, ...</td>\n",
       "      <td>[[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....</td>\n",
       "      <td>[13234, 888, 11147, 13644, 12037, 8012, 12169,...</td>\n",
       "      <td>[[6576, 4257, 10471, 12044, 14532, 7826, 1451,...</td>\n",
       "      <td>[[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....</td>\n",
       "      <td>[6576, 4257, 10471, 6576, 15575, 3030, 4226, 9...</td>\n",
       "      <td>[[5518, 4210, 10188, 8146, 14202, 12331, 884, ...</td>\n",
       "      <td>[[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...</td>\n",
       "      <td>[5518, 4210, 10188, 5518, 4742, 4210, 5518, 47...</td>\n",
       "      <td>[[5252, 11557, 11619, 4107, 14508, 3087, 12114...</td>\n",
       "      <td>[[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...</td>\n",
       "      <td>[5252, 11557, 11619, 5252, 11557, 11619, 5252,...</td>\n",
       "      <td>[[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...</td>\n",
       "      <td>[[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....</td>\n",
       "      <td>[1231, 9366, 15754, 4171, 1231, 12948, 1231, 5...</td>\n",
       "      <td>[[5514, 2461, 12467, 10364, 7156, 14085, 14823...</td>\n",
       "      <td>[[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...</td>\n",
       "      <td>[5514, 2461, 12467, 10258, 10364, 5514, 10364,...</td>\n",
       "      <td>[[4923, 11894, 10982, 11028, 9940, 2403, 5138,...</td>\n",
       "      <td>[[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...</td>\n",
       "      <td>[4923, 11894, 10982, 11382, 4923, 11894, 11894...</td>\n",
       "      <td>[[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...</td>\n",
       "      <td>[[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...</td>\n",
       "      <td>[4526, 1054, 15802, 4526, 10930, 1054, 4526, 1...</td>\n",
       "      <td>[[3101, 11995, 13952, 3748, 11799, 7547, 14552...</td>\n",
       "      <td>[[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...</td>\n",
       "      <td>[3101, 11995, 13952, 7876, 3101, 7844, 3101, 1...</td>\n",
       "      <td>[[8683, 2311, 1110, 11075, 11763, 10633, 10905...</td>\n",
       "      <td>[[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....</td>\n",
       "      <td>[8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...</td>\n",
       "      <td>[[6884, 10255, 14886, 486, 12861, 9087, 10703,...</td>\n",
       "      <td>[[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....</td>\n",
       "      <td>[6884, 10255, 14886, 13166, 10703, 6884, 14886...</td>\n",
       "      <td>[[6025, 1654, 15853, 8632, 15290, 14175, 8202,...</td>\n",
       "      <td>[[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....</td>\n",
       "      <td>[6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...</td>\n",
       "      <td>[[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...</td>\n",
       "      <td>[[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...</td>\n",
       "      <td>[3356, 2036, 1508, 12301, 261, 15018, 9843, 33...</td>\n",
       "      <td>[[4542, 14855, 11886, 3064, 12706, 69, 13693, ...</td>\n",
       "      <td>[[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...</td>\n",
       "      <td>[4542, 14855, 11886, 4542, 12706, 8038, 4447, ...</td>\n",
       "      <td>[[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...</td>\n",
       "      <td>[[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...</td>\n",
       "      <td>[11259, 4776, 3719, 11390, 16350, 15727, 16350...</td>\n",
       "      <td>[[14463, 11256, 1901, 11739, 15874, 7041, 1212...</td>\n",
       "      <td>[[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....</td>\n",
       "      <td>[14463, 11256, 1901, 13628, 14463, 11305, 1446...</td>\n",
       "      <td>[[7096, 7462, 12750, 15159, 14710, 14336, 8274...</td>\n",
       "      <td>[[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....</td>\n",
       "      <td>[7096, 7462, 12750, 7096, 5053, 14984, 14984, ...</td>\n",
       "      <td>[[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...</td>\n",
       "      <td>[[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....</td>\n",
       "      <td>[12896, 7538, 1889, 12796, 12896, 7896, 16316,...</td>\n",
       "      <td>[[9566, 12583, 4881, 12769, 11388, 2808, 5912,...</td>\n",
       "      <td>[[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...</td>\n",
       "      <td>[9566, 12583, 4881, 9566, 12583, 4766, 9566, 4...</td>\n",
       "      <td>[[11959, 16293, 1028, 6700, 783, 12140, 4377, ...</td>\n",
       "      <td>[[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....</td>\n",
       "      <td>[11959, 16293, 1028, 3858, 16293, 11959, 11959...</td>\n",
       "      <td>[[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...</td>\n",
       "      <td>[[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[14953, 12042, 11637, 14953, 697, 5889, 14953,...</td>\n",
       "      <td>[[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...</td>\n",
       "      <td>[[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....</td>\n",
       "      <td>[5279, 11288, 13838, 5279, 8424, 3820, 5279, 6...</td>\n",
       "      <td>[[12402, 3678, 10405, 7012, 7290, 12500, 5465,...</td>\n",
       "      <td>[[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...</td>\n",
       "      <td>[12402, 3678, 10405, 13983, 12402, 14623, 1398...</td>\n",
       "      <td>[[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...</td>\n",
       "      <td>[[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....</td>\n",
       "      <td>[5364, 11788, 9449, 15678, 4382, 9024, 13675, ...</td>\n",
       "      <td>[[15745, 2628, 10077, 8629, 9147, 3088, 10698,...</td>\n",
       "      <td>[[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...</td>\n",
       "      <td>[15745, 2628, 10077, 9038, 10698, 6214, 13955,...</td>\n",
       "      <td>[[7101, 890, 11950, 11426, 9709, 15133, 3060, ...</td>\n",
       "      <td>[[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....</td>\n",
       "      <td>[7101, 890, 11950, 12057, 322, 9790, 12057, 11...</td>\n",
       "      <td>[[5817, 4198, 2493, 4736, 962, 266, 12247, 953...</td>\n",
       "      <td>[[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...</td>\n",
       "      <td>[5817, 4198, 2493, 13276, 15637, 14206, 4736, ...</td>\n",
       "      <td>[[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...</td>\n",
       "      <td>[[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...</td>\n",
       "      <td>[4730, 6258, 5254, 4185, 3710, 3680, 1427, 79,...</td>\n",
       "      <td>[[12597, 10159, 14164, 11873, 14566, 12669, 74...</td>\n",
       "      <td>[[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...</td>\n",
       "      <td>[12597, 10159, 14164, 2793, 12597, 6186, 12597...</td>\n",
       "      <td>[[15592, 12904, 4700, 13680, 2955, 9554, 15209...</td>\n",
       "      <td>[[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....</td>\n",
       "      <td>[15592, 12904, 4700, 686, 15592, 5758, 15592, ...</td>\n",
       "      <td>[[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...</td>\n",
       "      <td>[[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...</td>\n",
       "      <td>[7589, 6941, 7590, 9583, 5371, 7730, 4143, 958...</td>\n",
       "      <td>[[12096, 11676, 7040, 4053, 9060, 11423, 13517...</td>\n",
       "      <td>[[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...</td>\n",
       "      <td>[12096, 11676, 7040, 12096, 9778, 6117, 12096,...</td>\n",
       "      <td>[[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...</td>\n",
       "      <td>[[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...</td>\n",
       "      <td>[1367, 10938, 5451, 10312, 13, 7282, 6279, 136...</td>\n",
       "      <td>[[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...</td>\n",
       "      <td>[[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...</td>\n",
       "      <td>[11525, 11530, 2788, 11525, 2788, 7622, 13788,...</td>\n",
       "      <td>[[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...</td>\n",
       "      <td>[[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...</td>\n",
       "      <td>[7495, 3117, 6381, 7495, 8202, 5376, 7495, 860...</td>\n",
       "      <td>[[6316, 3458, 15102, 4397, 10966, 6806, 10388,...</td>\n",
       "      <td>[[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...</td>\n",
       "      <td>[6316, 3458, 15102, 6316, 3318, 3458, 5421, 13...</td>\n",
       "      <td>[[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...</td>\n",
       "      <td>[[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...</td>\n",
       "      <td>[9338, 2350, 11394, 2636, 8191, 10598, 9819, 1...</td>\n",
       "      <td>[[13617, 4166, 16213, 12064, 10652, 7512, 1589...</td>\n",
       "      <td>[[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...</td>\n",
       "      <td>[13617, 4166, 16213, 249, 3869, 4290, 13617, 1...</td>\n",
       "      <td>[[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...</td>\n",
       "      <td>[[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...</td>\n",
       "      <td>[14672, 2673, 3001, 8681, 2564, 7488, 8681, 12...</td>\n",
       "      <td>[[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...</td>\n",
       "      <td>[[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...</td>\n",
       "      <td>[75, 12355, 8833, 75, 14877, 8833, 75, 14261, ...</td>\n",
       "      <td>[[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...</td>\n",
       "      <td>[[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...</td>\n",
       "      <td>[9218, 7586, 6883, 11167, 2604, 593, 9218, 155...</td>\n",
       "      <td>[[5845, 11167, 1359, 15100, 5745, 10491, 12367...</td>\n",
       "      <td>[[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...</td>\n",
       "      <td>[5845, 11167, 1359, 2506, 1600, 14844, 9380, 4...</td>\n",
       "      <td>[[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...</td>\n",
       "      <td>[[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...</td>\n",
       "      <td>[77, 7228, 16359, 9584, 8081, 5949, 9584, 1179...</td>\n",
       "      <td>[[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...</td>\n",
       "      <td>[[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...</td>\n",
       "      <td>[9071, 3170, 11447, 11447, 670, 1828, 1125, 11...</td>\n",
       "      <td>[[8468, 14729, 12522, 13882, 7302, 15247, 1488...</td>\n",
       "      <td>[[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....</td>\n",
       "      <td>[8468, 14729, 12522, 13882, 13143, 5910, 13882...</td>\n",
       "      <td>[[10730, 13775, 6168, 13924, 1222, 14050, 1107...</td>\n",
       "      <td>[[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...</td>\n",
       "      <td>[10730, 13775, 6168, 13966, 15701, 13509, 1247...</td>\n",
       "      <td>[[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...</td>\n",
       "      <td>[[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...</td>\n",
       "      <td>[4723, 2531, 12567, 11983, 8563, 9228, 2232, 6...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 8390, 10184, 15497, 8390, 101...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 282, 9329, 6134, 9243, 4368,...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 8171, 8262, 8420, 6608, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mmlu</td>\n",
       "      <td>Let A and B be sets, f: A -&gt; B and g: B -&gt; A b...</td>\n",
       "      <td>abstract_algebra</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 2198, 14163, 14506, 15495...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 13486, 10773, 11191, 426, ...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>[[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....</td>\n",
       "      <td>[15089, 14059, 7132, 5861, 4492, 1650, 9310, 1...</td>\n",
       "      <td>[[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...</td>\n",
       "      <td>[[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...</td>\n",
       "      <td>[9134, 6486, 14238, 5861, 5806, 6132, 11141, 6...</td>\n",
       "      <td>[[12690, 11570, 6680, 14155, 13325, 5575, 1118...</td>\n",
       "      <td>[[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...</td>\n",
       "      <td>[12690, 11570, 6680, 7394, 404, 6717, 2684, 41...</td>\n",
       "      <td>[[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...</td>\n",
       "      <td>[[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...</td>\n",
       "      <td>[1059, 8392, 5148, 3235, 1059, 4492, 2405, 102...</td>\n",
       "      <td>[[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...</td>\n",
       "      <td>[[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...</td>\n",
       "      <td>[9743, 6201, 14077, 6458, 15854, 12062, 15014,...</td>\n",
       "      <td>[[12287, 14119, 14537, 516, 13236, 13027, 6142...</td>\n",
       "      <td>[[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...</td>\n",
       "      <td>[12287, 14119, 14537, 9664, 12287, 2540, 225, ...</td>\n",
       "      <td>[[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...</td>\n",
       "      <td>[[868.33, 240.19, 224.46, 217.45, 134.61, 127....</td>\n",
       "      <td>[9213, 4399, 6069, 6291, 4520, 12062, 7240, 56...</td>\n",
       "      <td>[[12102, 5877, 3736, 9892, 10966, 12253, 4212,...</td>\n",
       "      <td>[[1050.34, 380.12, 201.91, 168.05, 167.84, 135...</td>\n",
       "      <td>[12102, 5877, 3736, 12102, 381, 4148, 2243, 10...</td>\n",
       "      <td>[[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...</td>\n",
       "      <td>[[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...</td>\n",
       "      <td>[4392, 2843, 3736, 4392, 3736, 14372, 10996, 3...</td>\n",
       "      <td>[[12945, 13423, 10772, 7228, 6222, 8238, 7675,...</td>\n",
       "      <td>[[1365.86, 254.11, 229.52, 216.75, 200.8, 160....</td>\n",
       "      <td>[12945, 13423, 10772, 12945, 13423, 10772, 17,...</td>\n",
       "      <td>[[1041, 7507, 11087, 3220, 11767, 11752, 14669...</td>\n",
       "      <td>[[1436.4, 288.32, 274.44, 177.82, 175.78, 169....</td>\n",
       "      <td>[1041, 7507, 11087, 4667, 11087, 1178, 10563, ...</td>\n",
       "      <td>[[11248, 13423, 15319, 12322, 15392, 12879, 15...</td>\n",
       "      <td>[[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...</td>\n",
       "      <td>[11248, 13423, 15319, 13423, 11248, 13462, 999...</td>\n",
       "      <td>[[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...</td>\n",
       "      <td>[[1326.71, 937.5, 207.55, 193.66, 179.61, 165....</td>\n",
       "      <td>[15567, 7214, 6812, 16123, 15567, 12313, 7214,...</td>\n",
       "      <td>[[10716, 8610, 13870, 14717, 6266, 10404, 7546...</td>\n",
       "      <td>[[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...</td>\n",
       "      <td>[10716, 8610, 13870, 10716, 14717, 8610, 4195,...</td>\n",
       "      <td>[[16028, 10480, 14919, 4500, 2717, 4631, 4005,...</td>\n",
       "      <td>[[1902.24, 718.23, 386.15, 328.9, 205.48, 198....</td>\n",
       "      <td>[16028, 10480, 14919, 4500, 16028, 15992, 2625...</td>\n",
       "      <td>[[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...</td>\n",
       "      <td>[[1963.47, 777.35, 402.1, 298.72, 265.57, 229....</td>\n",
       "      <td>[7127, 7921, 9095, 13462, 1003, 5373, 7400, 79...</td>\n",
       "      <td>[[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...</td>\n",
       "      <td>[[2052.88, 763.03, 348.91, 271.26, 259.58, 222...</td>\n",
       "      <td>[3851, 15394, 12685, 8545, 10793, 11527, 12543...</td>\n",
       "      <td>[[12025, 11046, 3543, 14445, 6075, 7417, 11438...</td>\n",
       "      <td>[[2130.77, 634.11, 405.05, 283.16, 279.33, 242...</td>\n",
       "      <td>[12025, 11046, 3543, 5875, 15771, 10441, 9843,...</td>\n",
       "      <td>[[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...</td>\n",
       "      <td>[[2028.8, 781.4, 534.86, 264.19, 252.53, 251.0...</td>\n",
       "      <td>[6631, 743, 5052, 2478, 11527, 14746, 8249, 66...</td>\n",
       "      <td>[[4138, 13557, 15170, 2788, 4967, 15463, 5910,...</td>\n",
       "      <td>[[2020.26, 856.65, 758.71, 290.22, 261.91, 250...</td>\n",
       "      <td>[4138, 13557, 15170, 9452, 2536, 7795, 10955, ...</td>\n",
       "      <td>[[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...</td>\n",
       "      <td>[[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....</td>\n",
       "      <td>[15056, 2037, 630, 10668, 13173, 10752, 15056,...</td>\n",
       "      <td>[[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...</td>\n",
       "      <td>[[2067.19, 1388.15, 290.23, 256.19, 256.17, 24...</td>\n",
       "      <td>[3956, 6961, 8321, 15401, 3220, 932, 2135, 696...</td>\n",
       "      <td>[[1802, 14391, 14836, 4182, 15109, 14832, 395,...</td>\n",
       "      <td>[[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...</td>\n",
       "      <td>[1802, 14391, 14836, 14746, 15730, 12893, 1444...</td>\n",
       "      <td>[[7479, 5149, 14186, 14325, 15861, 15298, 1734...</td>\n",
       "      <td>[[2302.48, 919.27, 913.31, 362.69, 330.19, 330...</td>\n",
       "      <td>[7479, 5149, 14186, 14325, 4263, 5588, 15298, ...</td>\n",
       "      <td>[[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...</td>\n",
       "      <td>[[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...</td>\n",
       "      <td>[3880, 1421, 1608, 3880, 1608, 9944, 3681, 142...</td>\n",
       "      <td>[[15873, 7914, 11003, 7428, 15345, 5816, 14312...</td>\n",
       "      <td>[[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...</td>\n",
       "      <td>[15873, 7914, 11003, 15873, 7914, 11003, 3823,...</td>\n",
       "      <td>[[13234, 888, 11147, 8912, 14708, 3818, 9138, ...</td>\n",
       "      <td>[[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....</td>\n",
       "      <td>[13234, 888, 11147, 7188, 8012, 4445, 9519, 10...</td>\n",
       "      <td>[[6576, 4257, 10471, 12044, 14532, 7826, 1451,...</td>\n",
       "      <td>[[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....</td>\n",
       "      <td>[6576, 4257, 10471, 6576, 10496, 15575, 15874,...</td>\n",
       "      <td>[[5518, 4210, 10188, 8146, 14202, 12331, 884, ...</td>\n",
       "      <td>[[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...</td>\n",
       "      <td>[5518, 4210, 10188, 5518, 4742, 3110, 10676, 2...</td>\n",
       "      <td>[[5252, 11557, 11619, 4107, 14508, 3087, 12114...</td>\n",
       "      <td>[[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...</td>\n",
       "      <td>[5252, 11557, 11619, 5252, 11557, 11619, 11557...</td>\n",
       "      <td>[[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...</td>\n",
       "      <td>[[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....</td>\n",
       "      <td>[1231, 9366, 15754, 4171, 1231, 5884, 1231, 50...</td>\n",
       "      <td>[[5514, 2461, 12467, 10364, 7156, 14085, 14823...</td>\n",
       "      <td>[[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...</td>\n",
       "      <td>[5514, 2461, 12467, 10258, 10364, 5514, 10364,...</td>\n",
       "      <td>[[4923, 11894, 10982, 11028, 9940, 2403, 5138,...</td>\n",
       "      <td>[[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...</td>\n",
       "      <td>[4923, 11894, 10982, 11382, 11894, 15743, 1189...</td>\n",
       "      <td>[[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...</td>\n",
       "      <td>[[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...</td>\n",
       "      <td>[4526, 1054, 15802, 4526, 10930, 4450, 4526, 1...</td>\n",
       "      <td>[[3101, 11995, 13952, 3748, 11799, 7547, 14552...</td>\n",
       "      <td>[[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...</td>\n",
       "      <td>[3101, 11995, 13952, 7876, 3101, 7844, 3101, 4...</td>\n",
       "      <td>[[8683, 2311, 1110, 11075, 11763, 10633, 10905...</td>\n",
       "      <td>[[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....</td>\n",
       "      <td>[8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...</td>\n",
       "      <td>[[6884, 10255, 14886, 486, 12861, 9087, 10703,...</td>\n",
       "      <td>[[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....</td>\n",
       "      <td>[6884, 10255, 14886, 13166, 10703, 6884, 14886...</td>\n",
       "      <td>[[6025, 1654, 15853, 8632, 15290, 14175, 8202,...</td>\n",
       "      <td>[[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....</td>\n",
       "      <td>[6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...</td>\n",
       "      <td>[[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...</td>\n",
       "      <td>[[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...</td>\n",
       "      <td>[3356, 2036, 1508, 12301, 261, 15018, 3356, 98...</td>\n",
       "      <td>[[4542, 14855, 11886, 3064, 12706, 69, 13693, ...</td>\n",
       "      <td>[[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...</td>\n",
       "      <td>[4542, 14855, 11886, 4542, 12706, 8038, 4447, ...</td>\n",
       "      <td>[[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...</td>\n",
       "      <td>[[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...</td>\n",
       "      <td>[11259, 4776, 3719, 11390, 16350, 11259, 11259...</td>\n",
       "      <td>[[14463, 11256, 1901, 11739, 15874, 7041, 1212...</td>\n",
       "      <td>[[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....</td>\n",
       "      <td>[14463, 11256, 1901, 13628, 14463, 12260, 1446...</td>\n",
       "      <td>[[7096, 7462, 12750, 15159, 14710, 14336, 8274...</td>\n",
       "      <td>[[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....</td>\n",
       "      <td>[7096, 7462, 12750, 7096, 9729, 2592, 7096, 55...</td>\n",
       "      <td>[[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...</td>\n",
       "      <td>[[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....</td>\n",
       "      <td>[12896, 7538, 1889, 12796, 7896, 16289, 8750, ...</td>\n",
       "      <td>[[9566, 12583, 4881, 12769, 11388, 2808, 5912,...</td>\n",
       "      <td>[[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...</td>\n",
       "      <td>[9566, 12583, 4881, 9566, 12583, 8704, 9566, 1...</td>\n",
       "      <td>[[11959, 16293, 1028, 6700, 783, 12140, 4377, ...</td>\n",
       "      <td>[[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....</td>\n",
       "      <td>[11959, 16293, 1028, 3858, 16293, 6819, 11959,...</td>\n",
       "      <td>[[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...</td>\n",
       "      <td>[[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...</td>\n",
       "      <td>[14953, 12042, 11637, 14953, 461, 9186, 14953,...</td>\n",
       "      <td>[[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...</td>\n",
       "      <td>[[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....</td>\n",
       "      <td>[5279, 11288, 13838, 2704, 8424, 5279, 2207, 5...</td>\n",
       "      <td>[[12402, 3678, 10405, 7012, 7290, 12500, 5465,...</td>\n",
       "      <td>[[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...</td>\n",
       "      <td>[12402, 3678, 10405, 12402, 1095, 21, 3954, 12...</td>\n",
       "      <td>[[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...</td>\n",
       "      <td>[[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....</td>\n",
       "      <td>[5364, 11788, 9449, 4337, 6438, 15678, 15678, ...</td>\n",
       "      <td>[[15745, 2628, 10077, 8629, 9147, 3088, 10698,...</td>\n",
       "      <td>[[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...</td>\n",
       "      <td>[15745, 2628, 10077, 9038, 3638, 15022, 13955,...</td>\n",
       "      <td>[[7101, 890, 11950, 11426, 9709, 15133, 3060, ...</td>\n",
       "      <td>[[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....</td>\n",
       "      <td>[7101, 890, 11950, 12057, 322, 11894, 598, 719...</td>\n",
       "      <td>[[5817, 4198, 2493, 4736, 962, 266, 12247, 953...</td>\n",
       "      <td>[[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...</td>\n",
       "      <td>[5817, 4198, 2493, 15619, 2673, 6158, 3236, 12...</td>\n",
       "      <td>[[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...</td>\n",
       "      <td>[[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...</td>\n",
       "      <td>[4730, 6258, 5254, 9322, 4456, 4185, 4730, 127...</td>\n",
       "      <td>[[12597, 10159, 14164, 11873, 14566, 12669, 74...</td>\n",
       "      <td>[[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...</td>\n",
       "      <td>[12597, 10159, 14164, 2793, 12597, 6186, 12597...</td>\n",
       "      <td>[[15592, 12904, 4700, 13680, 2955, 9554, 15209...</td>\n",
       "      <td>[[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....</td>\n",
       "      <td>[15592, 12904, 4700, 686, 15592, 14352, 15592,...</td>\n",
       "      <td>[[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...</td>\n",
       "      <td>[[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...</td>\n",
       "      <td>[7589, 6941, 7590, 178, 5046, 5371, 7499, 7589...</td>\n",
       "      <td>[[12096, 11676, 7040, 4053, 9060, 11423, 13517...</td>\n",
       "      <td>[[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...</td>\n",
       "      <td>[12096, 11676, 7040, 12096, 9778, 4053, 12096,...</td>\n",
       "      <td>[[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...</td>\n",
       "      <td>[[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...</td>\n",
       "      <td>[1367, 10938, 5451, 8286, 7282, 9743, 1367, 59...</td>\n",
       "      <td>[[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...</td>\n",
       "      <td>[[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...</td>\n",
       "      <td>[11525, 11530, 2788, 11525, 2788, 7622, 11525,...</td>\n",
       "      <td>[[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...</td>\n",
       "      <td>[[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...</td>\n",
       "      <td>[7495, 3117, 6381, 7495, 8202, 5376, 11388, 15...</td>\n",
       "      <td>[[6316, 3458, 15102, 4397, 10966, 6806, 10388,...</td>\n",
       "      <td>[[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...</td>\n",
       "      <td>[6316, 3458, 15102, 6316, 3318, 3458, 6316, 12...</td>\n",
       "      <td>[[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...</td>\n",
       "      <td>[[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...</td>\n",
       "      <td>[9338, 2350, 11394, 2636, 9338, 8191, 9338, 67...</td>\n",
       "      <td>[[13617, 4166, 16213, 12064, 10652, 7512, 1589...</td>\n",
       "      <td>[[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...</td>\n",
       "      <td>[13617, 4166, 16213, 249, 3869, 7095, 5233, 54...</td>\n",
       "      <td>[[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...</td>\n",
       "      <td>[[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...</td>\n",
       "      <td>[14672, 2673, 3001, 8681, 2564, 9646, 14672, 4...</td>\n",
       "      <td>[[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...</td>\n",
       "      <td>[[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...</td>\n",
       "      <td>[75, 12355, 8833, 75, 8833, 14877, 75, 3439, 9...</td>\n",
       "      <td>[[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...</td>\n",
       "      <td>[[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...</td>\n",
       "      <td>[9218, 7586, 6883, 11167, 2604, 3467, 9218, 40...</td>\n",
       "      <td>[[5845, 11167, 1359, 15100, 5745, 10491, 12367...</td>\n",
       "      <td>[[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...</td>\n",
       "      <td>[5845, 11167, 1359, 2506, 1600, 16318, 9817, 5...</td>\n",
       "      <td>[[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...</td>\n",
       "      <td>[[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...</td>\n",
       "      <td>[77, 7228, 16359, 6192, 10631, 8081, 77, 7013,...</td>\n",
       "      <td>[[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...</td>\n",
       "      <td>[[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...</td>\n",
       "      <td>[9071, 3170, 11447, 5866, 9380, 1883, 11447, 1...</td>\n",
       "      <td>[[8468, 14729, 12522, 13882, 7302, 15247, 1488...</td>\n",
       "      <td>[[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....</td>\n",
       "      <td>[8468, 14729, 12522, 13882, 11522, 12449, 8821...</td>\n",
       "      <td>[[10730, 13775, 6168, 13924, 1222, 14050, 1107...</td>\n",
       "      <td>[[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...</td>\n",
       "      <td>[10730, 13775, 6168, 6354, 3777, 14050, 9864, ...</td>\n",
       "      <td>[[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...</td>\n",
       "      <td>[[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...</td>\n",
       "      <td>[4723, 2531, 12567, 15113, 2978, 15793, 4723, ...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 10184, 15365, 15497, 10184, 8...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 282, 9329, 6115, 9329, 282, ...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 4589, 8171, 13264, 8242,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                             prompt          category  \\\n",
       "0  mmlu  Statement 1 | If a group has an element of ord...  abstract_algebra   \n",
       "1  mmlu  Statement 1 | If G, H and K are groups of orde...  abstract_algebra   \n",
       "2  mmlu  (Z,*) is a group with a*b = a+b+1 for all a, b...  abstract_algebra   \n",
       "3  mmlu  Statement 1 | For any two groups G and G', the...  abstract_algebra   \n",
       "4  mmlu  Let A and B be sets, f: A -> B and g: B -> A b...  abstract_algebra   \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "1  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "2  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "3  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "4  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "1  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "2  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "3  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "4  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-token_feature_ids  \\\n",
       "0  [8920, 12838, 12950, 11864, 4698, 3798, 6186, ...                              \n",
       "1  [8920, 12838, 12950, 11864, 4698, 3798, 6186, ...                              \n",
       "2  [8920, 12838, 12950, 9649, 7063, 8920, 8648, 5...                              \n",
       "3  [8920, 12838, 12950, 11864, 4698, 3798, 6186, ...                              \n",
       "4  [8920, 12838, 12950, 2198, 14163, 14506, 15495...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "1  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "2  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "3  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "4  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "1  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "2  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "3  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "4  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-token_feature_ids  \\\n",
       "0  [9770, 5146, 12054, 10183, 3848, 8835, 8994, 1...                              \n",
       "1  [9770, 5146, 12054, 10183, 3848, 8835, 8994, 1...                              \n",
       "2  [9770, 5146, 12054, 3380, 13826, 12340, 6368, ...                              \n",
       "3  [9770, 5146, 12054, 10183, 3848, 8835, 8994, 1...                              \n",
       "4  [9770, 5146, 12054, 13486, 10773, 11191, 426, ...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_2/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "1  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "2  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "3  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "4  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_2/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....                          \n",
       "1  [[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....                          \n",
       "2  [[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....                          \n",
       "3  [[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....                          \n",
       "4  [[501.74, 87.69, 72.02, 69.0, 66.37, 56.4, 42....                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_2/width_16k/canonical-token_feature_ids  \\\n",
       "0  [15089, 14059, 7132, 9407, 1650, 4592, 1401, 1...                              \n",
       "1  [15089, 14059, 7132, 9407, 1650, 4592, 1401, 1...                              \n",
       "2  [15089, 14059, 7132, 3380, 6311, 14043, 14239,...                              \n",
       "3  [15089, 14059, 7132, 9407, 1650, 4592, 1401, 1...                              \n",
       "4  [15089, 14059, 7132, 5861, 4492, 1650, 9310, 1...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_3/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...                         \n",
       "1  [[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...                         \n",
       "2  [[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...                         \n",
       "3  [[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...                         \n",
       "4  [[9134, 6486, 14238, 58, 3013, 16178, 2604, 79...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_3/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...                          \n",
       "1  [[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...                          \n",
       "2  [[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...                          \n",
       "3  [[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...                          \n",
       "4  [[579.36, 183.4, 158.94, 115.82, 50.67, 49.05,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_3/width_16k/canonical-token_feature_ids  \\\n",
       "0  [9134, 6486, 14238, 7173, 5806, 4303, 5371, 21...                              \n",
       "1  [9134, 6486, 14238, 7173, 5806, 4303, 5371, 21...                              \n",
       "2  [9134, 6486, 14238, 967, 9889, 9627, 9331, 115...                              \n",
       "3  [9134, 6486, 14238, 7173, 5806, 4303, 5371, 21...                              \n",
       "4  [9134, 6486, 14238, 5861, 5806, 6132, 11141, 6...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_4/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[12690, 11570, 6680, 14155, 13325, 5575, 1118...                         \n",
       "1  [[12690, 11570, 6680, 14155, 13325, 5575, 1118...                         \n",
       "2  [[12690, 11570, 6680, 14155, 13325, 5575, 1118...                         \n",
       "3  [[12690, 11570, 6680, 14155, 13325, 5575, 1118...                         \n",
       "4  [[12690, 11570, 6680, 14155, 13325, 5575, 1118...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_4/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...                          \n",
       "1  [[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...                          \n",
       "2  [[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...                          \n",
       "3  [[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...                          \n",
       "4  [[743.17, 95.37, 86.48, 61.69, 52.67, 48.11, 3...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_4/width_16k/canonical-token_feature_ids  \\\n",
       "0  [12690, 11570, 6680, 11333, 6717, 6680, 6232, ...                              \n",
       "1  [12690, 11570, 6680, 11333, 6717, 6680, 6232, ...                              \n",
       "2  [12690, 11570, 6680, 960, 13580, 6717, 8791, 2...                              \n",
       "3  [12690, 11570, 6680, 11333, 6717, 6680, 6232, ...                              \n",
       "4  [12690, 11570, 6680, 7394, 404, 6717, 2684, 41...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_5/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...                         \n",
       "1  [[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...                         \n",
       "2  [[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...                         \n",
       "3  [[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...                         \n",
       "4  [[1059, 8392, 5148, 1515, 13960, 10966, 9380, ...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_5/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...                          \n",
       "1  [[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...                          \n",
       "2  [[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...                          \n",
       "3  [[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...                          \n",
       "4  [[832.3, 225.54, 202.13, 71.05, 64.65, 64.17, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_5/width_16k/canonical-token_feature_ids  \\\n",
       "0  [1059, 8392, 5148, 6131, 3235, 1059, 15280, 19...                              \n",
       "1  [1059, 8392, 5148, 6131, 3235, 1059, 15280, 19...                              \n",
       "2  [1059, 8392, 5148, 3235, 2066, 4706, 3701, 134...                              \n",
       "3  [1059, 8392, 5148, 6131, 3235, 1059, 15280, 19...                              \n",
       "4  [1059, 8392, 5148, 3235, 1059, 4492, 2405, 102...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_6/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...                         \n",
       "1  [[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...                         \n",
       "2  [[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...                         \n",
       "3  [[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...                         \n",
       "4  [[9743, 6201, 14077, 4478, 4485, 8883, 8765, 4...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_6/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...                          \n",
       "1  [[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...                          \n",
       "2  [[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...                          \n",
       "3  [[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...                          \n",
       "4  [[801.57, 559.81, 114.14, 102.16, 99.88, 94.44...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_6/width_16k/canonical-token_feature_ids  \\\n",
       "0  [9743, 6201, 14077, 2686, 15854, 12531, 15012,...                              \n",
       "1  [9743, 6201, 14077, 2686, 15854, 12531, 15012,...                              \n",
       "2  [9743, 6201, 14077, 15854, 12062, 14445, 5260,...                              \n",
       "3  [9743, 6201, 14077, 2686, 15854, 12531, 15012,...                              \n",
       "4  [9743, 6201, 14077, 6458, 15854, 12062, 15014,...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_7/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[12287, 14119, 14537, 516, 13236, 13027, 6142...                         \n",
       "1  [[12287, 14119, 14537, 516, 13236, 13027, 6142...                         \n",
       "2  [[12287, 14119, 14537, 516, 13236, 13027, 6142...                         \n",
       "3  [[12287, 14119, 14537, 516, 13236, 13027, 6142...                         \n",
       "4  [[12287, 14119, 14537, 516, 13236, 13027, 6142...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_7/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...                          \n",
       "1  [[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...                          \n",
       "2  [[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...                          \n",
       "3  [[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...                          \n",
       "4  [[818.7, 369.01, 350.63, 185.27, 182.41, 159.3...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_7/width_16k/canonical-token_feature_ids  \\\n",
       "0  [12287, 14119, 14537, 9664, 8039, 2523, 3660, ...                              \n",
       "1  [12287, 14119, 14537, 9664, 8039, 2523, 3660, ...                              \n",
       "2  [12287, 14119, 14537, 9664, 12287, 15564, 2686...                              \n",
       "3  [12287, 14119, 14537, 9664, 8039, 2523, 3660, ...                              \n",
       "4  [12287, 14119, 14537, 9664, 12287, 2540, 225, ...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_8/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...                         \n",
       "1  [[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...                         \n",
       "2  [[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...                         \n",
       "3  [[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...                         \n",
       "4  [[9213, 4399, 6069, 3397, 13188, 12695, 6524, ...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_8/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[868.33, 240.19, 224.46, 217.45, 134.61, 127....                          \n",
       "1  [[868.33, 240.19, 224.46, 217.45, 134.61, 127....                          \n",
       "2  [[868.33, 240.19, 224.46, 217.45, 134.61, 127....                          \n",
       "3  [[868.33, 240.19, 224.46, 217.45, 134.61, 127....                          \n",
       "4  [[868.33, 240.19, 224.46, 217.45, 134.61, 127....                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_8/width_16k/canonical-token_feature_ids  \\\n",
       "0  [9213, 4399, 6069, 6291, 6966, 2024, 13041, 16...                              \n",
       "1  [9213, 4399, 6069, 6291, 6966, 2024, 13041, 16...                              \n",
       "2  [9213, 4399, 6069, 6291, 4311, 9213, 13451, 30...                              \n",
       "3  [9213, 4399, 6069, 6291, 6966, 2024, 13041, 16...                              \n",
       "4  [9213, 4399, 6069, 6291, 4520, 12062, 7240, 56...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_9/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[12102, 5877, 3736, 9892, 10966, 12253, 4212,...                         \n",
       "1  [[12102, 5877, 3736, 9892, 10966, 12253, 4212,...                         \n",
       "2  [[12102, 5877, 3736, 9892, 10966, 12253, 4212,...                         \n",
       "3  [[12102, 5877, 3736, 9892, 10966, 12253, 4212,...                         \n",
       "4  [[12102, 5877, 3736, 9892, 10966, 12253, 4212,...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_9/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1050.34, 380.12, 201.91, 168.05, 167.84, 135...                          \n",
       "1  [[1050.34, 380.12, 201.91, 168.05, 167.84, 135...                          \n",
       "2  [[1050.34, 380.12, 201.91, 168.05, 167.84, 135...                          \n",
       "3  [[1050.34, 380.12, 201.91, 168.05, 167.84, 135...                          \n",
       "4  [[1050.34, 380.12, 201.91, 168.05, 167.84, 135...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_9/width_16k/canonical-token_feature_ids  \\\n",
       "0  [12102, 5877, 3736, 12102, 381, 7266, 15789, 9...                              \n",
       "1  [12102, 5877, 3736, 12102, 381, 7266, 15789, 9...                              \n",
       "2  [12102, 5877, 3736, 12102, 381, 4148, 1435, 13...                              \n",
       "3  [12102, 5877, 3736, 12102, 381, 7266, 15789, 9...                              \n",
       "4  [12102, 5877, 3736, 12102, 381, 4148, 2243, 10...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_10/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...                          \n",
       "1  [[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...                          \n",
       "2  [[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...                          \n",
       "3  [[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...                          \n",
       "4  [[4392, 2843, 3736, 2575, 5501, 6655, 9892, 57...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_10/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...                           \n",
       "1  [[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...                           \n",
       "2  [[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...                           \n",
       "3  [[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...                           \n",
       "4  [[1203.7, 499.6, 185.49, 177.32, 153.56, 137.8...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_10/width_16k/canonical-token_feature_ids  \\\n",
       "0  [4392, 2843, 3736, 4392, 3736, 14372, 4444, 67...                               \n",
       "1  [4392, 2843, 3736, 4392, 3736, 14372, 4444, 67...                               \n",
       "2  [4392, 2843, 3736, 4392, 3736, 14372, 3031, 12...                               \n",
       "3  [4392, 2843, 3736, 4392, 3736, 14372, 4444, 67...                               \n",
       "4  [4392, 2843, 3736, 4392, 3736, 14372, 10996, 3...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_11/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[12945, 13423, 10772, 7228, 6222, 8238, 7675,...                          \n",
       "1  [[12945, 13423, 10772, 7228, 6222, 8238, 7675,...                          \n",
       "2  [[12945, 13423, 10772, 7228, 6222, 8238, 7675,...                          \n",
       "3  [[12945, 13423, 10772, 7228, 6222, 8238, 7675,...                          \n",
       "4  [[12945, 13423, 10772, 7228, 6222, 8238, 7675,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_11/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1365.86, 254.11, 229.52, 216.75, 200.8, 160....                           \n",
       "1  [[1365.86, 254.11, 229.52, 216.75, 200.8, 160....                           \n",
       "2  [[1365.86, 254.11, 229.52, 216.75, 200.8, 160....                           \n",
       "3  [[1365.86, 254.11, 229.52, 216.75, 200.8, 160....                           \n",
       "4  [[1365.86, 254.11, 229.52, 216.75, 200.8, 160....                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_11/width_16k/canonical-token_feature_ids  \\\n",
       "0  [12945, 13423, 10772, 12945, 13423, 10772, 695...                               \n",
       "1  [12945, 13423, 10772, 12945, 13423, 10772, 695...                               \n",
       "2  [12945, 13423, 10772, 12945, 13423, 10772, 161...                               \n",
       "3  [12945, 13423, 10772, 12945, 13423, 10772, 695...                               \n",
       "4  [12945, 13423, 10772, 12945, 13423, 10772, 17,...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_12/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[1041, 7507, 11087, 3220, 11767, 11752, 14669...                          \n",
       "1  [[1041, 7507, 11087, 3220, 11767, 11752, 14669...                          \n",
       "2  [[1041, 7507, 11087, 3220, 11767, 11752, 14669...                          \n",
       "3  [[1041, 7507, 11087, 3220, 11767, 11752, 14669...                          \n",
       "4  [[1041, 7507, 11087, 3220, 11767, 11752, 14669...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_12/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1436.4, 288.32, 274.44, 177.82, 175.78, 169....                           \n",
       "1  [[1436.4, 288.32, 274.44, 177.82, 175.78, 169....                           \n",
       "2  [[1436.4, 288.32, 274.44, 177.82, 175.78, 169....                           \n",
       "3  [[1436.4, 288.32, 274.44, 177.82, 175.78, 169....                           \n",
       "4  [[1436.4, 288.32, 274.44, 177.82, 175.78, 169....                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_12/width_16k/canonical-token_feature_ids  \\\n",
       "0  [1041, 7507, 11087, 4667, 11087, 1178, 6810, 8...                               \n",
       "1  [1041, 7507, 11087, 4667, 11087, 1178, 6810, 8...                               \n",
       "2  [1041, 7507, 11087, 4667, 11087, 1178, 6810, 1...                               \n",
       "3  [1041, 7507, 11087, 4667, 11087, 1178, 6810, 8...                               \n",
       "4  [1041, 7507, 11087, 4667, 11087, 1178, 10563, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_13/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[11248, 13423, 15319, 12322, 15392, 12879, 15...                          \n",
       "1  [[11248, 13423, 15319, 12322, 15392, 12879, 15...                          \n",
       "2  [[11248, 13423, 15319, 12322, 15392, 12879, 15...                          \n",
       "3  [[11248, 13423, 15319, 12322, 15392, 12879, 15...                          \n",
       "4  [[11248, 13423, 15319, 12322, 15392, 12879, 15...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_13/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...                           \n",
       "1  [[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...                           \n",
       "2  [[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...                           \n",
       "3  [[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...                           \n",
       "4  [[1600.21, 427.64, 387.7, 267.35, 151.8, 147.0...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_13/width_16k/canonical-token_feature_ids  \\\n",
       "0  [11248, 13423, 15319, 13423, 11248, 6665, 3149...                               \n",
       "1  [11248, 13423, 15319, 13423, 11248, 6665, 3149...                               \n",
       "2  [11248, 13423, 15319, 13423, 11248, 9076, 1588...                               \n",
       "3  [11248, 13423, 15319, 13423, 11248, 6665, 3149...                               \n",
       "4  [11248, 13423, 15319, 13423, 11248, 13462, 999...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_14/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...                          \n",
       "1  [[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...                          \n",
       "2  [[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...                          \n",
       "3  [[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...                          \n",
       "4  [[15567, 7214, 6812, 9165, 7601, 8995, 8818, 3...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_14/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1326.71, 937.5, 207.55, 193.66, 179.61, 165....                           \n",
       "1  [[1326.71, 937.5, 207.55, 193.66, 179.61, 165....                           \n",
       "2  [[1326.71, 937.5, 207.55, 193.66, 179.61, 165....                           \n",
       "3  [[1326.71, 937.5, 207.55, 193.66, 179.61, 165....                           \n",
       "4  [[1326.71, 937.5, 207.55, 193.66, 179.61, 165....                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_14/width_16k/canonical-token_feature_ids  \\\n",
       "0  [15567, 7214, 6812, 16123, 12313, 15567, 15887...                               \n",
       "1  [15567, 7214, 6812, 16123, 12313, 15567, 15887...                               \n",
       "2  [15567, 7214, 6812, 16123, 15567, 12313, 15887...                               \n",
       "3  [15567, 7214, 6812, 16123, 12313, 15567, 15887...                               \n",
       "4  [15567, 7214, 6812, 16123, 15567, 12313, 7214,...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_15/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[10716, 8610, 13870, 14717, 6266, 10404, 7546...                          \n",
       "1  [[10716, 8610, 13870, 14717, 6266, 10404, 7546...                          \n",
       "2  [[10716, 8610, 13870, 14717, 6266, 10404, 7546...                          \n",
       "3  [[10716, 8610, 13870, 14717, 6266, 10404, 7546...                          \n",
       "4  [[10716, 8610, 13870, 14717, 6266, 10404, 7546...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_15/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...                           \n",
       "1  [[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...                           \n",
       "2  [[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...                           \n",
       "3  [[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...                           \n",
       "4  [[1806.66, 784.57, 486.8, 369.39, 286.7, 204.3...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_15/width_16k/canonical-token_feature_ids  \\\n",
       "0  [10716, 8610, 13870, 10716, 14717, 8610, 2234,...                               \n",
       "1  [10716, 8610, 13870, 10716, 14717, 8610, 2234,...                               \n",
       "2  [10716, 8610, 13870, 10716, 14717, 8610, 2234,...                               \n",
       "3  [10716, 8610, 13870, 10716, 14717, 8610, 2234,...                               \n",
       "4  [10716, 8610, 13870, 10716, 14717, 8610, 4195,...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_16/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[16028, 10480, 14919, 4500, 2717, 4631, 4005,...                          \n",
       "1  [[16028, 10480, 14919, 4500, 2717, 4631, 4005,...                          \n",
       "2  [[16028, 10480, 14919, 4500, 2717, 4631, 4005,...                          \n",
       "3  [[16028, 10480, 14919, 4500, 2717, 4631, 4005,...                          \n",
       "4  [[16028, 10480, 14919, 4500, 2717, 4631, 4005,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_16/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1902.23, 718.23, 386.15, 328.9, 205.48, 198....                           \n",
       "1  [[1902.24, 718.23, 386.15, 328.9, 205.48, 198....                           \n",
       "2  [[1902.23, 718.23, 386.15, 328.9, 205.48, 198....                           \n",
       "3  [[1902.23, 718.23, 386.15, 328.9, 205.48, 198....                           \n",
       "4  [[1902.24, 718.23, 386.15, 328.9, 205.48, 198....                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_16/width_16k/canonical-token_feature_ids  \\\n",
       "0  [16028, 10480, 14919, 4500, 16028, 10480, 1295...                               \n",
       "1  [16028, 10480, 14919, 4500, 16028, 10480, 1295...                               \n",
       "2  [16028, 10480, 14919, 4500, 16028, 10480, 1033...                               \n",
       "3  [16028, 10480, 14919, 4500, 16028, 10480, 1295...                               \n",
       "4  [16028, 10480, 14919, 4500, 16028, 15992, 2625...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_17/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...                          \n",
       "1  [[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...                          \n",
       "2  [[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...                          \n",
       "3  [[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...                          \n",
       "4  [[7127, 7921, 9095, 12507, 10848, 999, 1467, 1...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_17/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1963.47, 777.35, 402.1, 298.72, 265.57, 229....                           \n",
       "1  [[1963.47, 777.35, 402.1, 298.72, 265.57, 229....                           \n",
       "2  [[1963.47, 777.35, 402.1, 298.72, 265.57, 229....                           \n",
       "3  [[1963.47, 777.35, 402.1, 298.72, 265.57, 229....                           \n",
       "4  [[1963.47, 777.35, 402.1, 298.72, 265.57, 229....                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_17/width_16k/canonical-token_feature_ids  \\\n",
       "0  [7127, 7921, 9095, 1935, 11527, 1003, 6492, 50...                               \n",
       "1  [7127, 7921, 9095, 1935, 11527, 1003, 6492, 50...                               \n",
       "2  [7127, 7921, 9095, 12546, 5373, 1003, 6492, 70...                               \n",
       "3  [7127, 7921, 9095, 1935, 11527, 1003, 6492, 50...                               \n",
       "4  [7127, 7921, 9095, 13462, 1003, 5373, 7400, 79...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_18/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...                          \n",
       "1  [[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...                          \n",
       "2  [[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...                          \n",
       "3  [[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...                          \n",
       "4  [[3851, 15394, 12685, 1222, 2336, 5803, 4677, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_18/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2052.88, 763.03, 348.91, 271.26, 259.58, 222...                           \n",
       "1  [[2052.88, 763.03, 348.91, 271.26, 259.58, 222...                           \n",
       "2  [[2052.88, 763.03, 348.91, 271.26, 259.58, 222...                           \n",
       "3  [[2052.88, 763.03, 348.91, 271.26, 259.58, 222...                           \n",
       "4  [[2052.88, 763.03, 348.91, 271.26, 259.58, 222...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_18/width_16k/canonical-token_feature_ids  \\\n",
       "0  [3851, 15394, 12685, 10793, 7373, 15897, 7373,...                               \n",
       "1  [3851, 15394, 12685, 10793, 7373, 15897, 7373,...                               \n",
       "2  [3851, 15394, 12685, 11527, 7373, 10793, 7373,...                               \n",
       "3  [3851, 15394, 12685, 10793, 7373, 15897, 7373,...                               \n",
       "4  [3851, 15394, 12685, 8545, 10793, 11527, 12543...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_19/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[12025, 11046, 3543, 14445, 6075, 7417, 11438...                          \n",
       "1  [[12025, 11046, 3543, 14445, 6075, 7417, 11438...                          \n",
       "2  [[12025, 11046, 3543, 14445, 6075, 7417, 11438...                          \n",
       "3  [[12025, 11046, 3543, 14445, 6075, 7417, 11438...                          \n",
       "4  [[12025, 11046, 3543, 14445, 6075, 7417, 11438...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_19/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2130.78, 634.11, 405.05, 283.16, 279.33, 242...                           \n",
       "1  [[2130.77, 634.11, 405.05, 283.16, 279.33, 242...                           \n",
       "2  [[2130.77, 634.11, 405.05, 283.16, 279.33, 242...                           \n",
       "3  [[2130.78, 634.11, 405.05, 283.16, 279.33, 242...                           \n",
       "4  [[2130.77, 634.11, 405.05, 283.16, 279.33, 242...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_19/width_16k/canonical-token_feature_ids  \\\n",
       "0  [12025, 11046, 3543, 8475, 10441, 5111, 6655, ...                               \n",
       "1  [12025, 11046, 3543, 8475, 10441, 5111, 6655, ...                               \n",
       "2  [12025, 11046, 3543, 10441, 15771, 4346, 4346,...                               \n",
       "3  [12025, 11046, 3543, 8475, 10441, 5111, 6655, ...                               \n",
       "4  [12025, 11046, 3543, 5875, 15771, 10441, 9843,...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_20/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...                          \n",
       "1  [[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...                          \n",
       "2  [[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...                          \n",
       "3  [[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...                          \n",
       "4  [[6631, 743, 5052, 16057, 9479, 3518, 8887, 74...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_20/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2028.8, 781.4, 534.86, 264.19, 252.53, 251.0...                           \n",
       "1  [[2028.8, 781.4, 534.86, 264.19, 252.53, 251.0...                           \n",
       "2  [[2028.8, 781.4, 534.86, 264.19, 252.53, 251.0...                           \n",
       "3  [[2028.81, 781.4, 534.86, 264.19, 252.53, 251....                           \n",
       "4  [[2028.8, 781.4, 534.86, 264.19, 252.53, 251.0...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_20/width_16k/canonical-token_feature_ids  \\\n",
       "0  [6631, 743, 5052, 292, 11527, 13785, 2045, 292...                               \n",
       "1  [6631, 743, 5052, 292, 11527, 13785, 2045, 292...                               \n",
       "2  [6631, 743, 5052, 10949, 11527, 8684, 13451, 0...                               \n",
       "3  [6631, 743, 5052, 292, 11527, 13785, 2045, 292...                               \n",
       "4  [6631, 743, 5052, 2478, 11527, 14746, 8249, 66...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_21/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[4138, 13557, 15170, 2788, 4967, 15463, 5910,...                          \n",
       "1  [[4138, 13557, 15170, 2788, 4967, 15463, 5910,...                          \n",
       "2  [[4138, 13557, 15170, 2788, 4967, 15463, 5910,...                          \n",
       "3  [[4138, 13557, 15170, 2788, 4967, 15463, 5910,...                          \n",
       "4  [[4138, 13557, 15170, 2788, 4967, 15463, 5910,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_21/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2020.27, 856.65, 758.72, 290.22, 261.91, 250...                           \n",
       "1  [[2020.26, 856.65, 758.71, 290.22, 261.91, 250...                           \n",
       "2  [[2020.26, 856.65, 758.71, 290.22, 261.91, 250...                           \n",
       "3  [[2020.26, 856.65, 758.72, 290.22, 261.91, 250...                           \n",
       "4  [[2020.26, 856.65, 758.71, 290.22, 261.91, 250...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_21/width_16k/canonical-token_feature_ids  \\\n",
       "0  [4138, 13557, 15170, 14723, 1003, 5111, 4366, ...                               \n",
       "1  [4138, 13557, 15170, 14723, 1003, 5111, 4366, ...                               \n",
       "2  [4138, 13557, 15170, 11527, 4782, 3461, 2286, ...                               \n",
       "3  [4138, 13557, 15170, 14723, 1003, 5111, 4366, ...                               \n",
       "4  [4138, 13557, 15170, 9452, 2536, 7795, 10955, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_22/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...                          \n",
       "1  [[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...                          \n",
       "2  [[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...                          \n",
       "3  [[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...                          \n",
       "4  [[15056, 2037, 630, 11899, 8774, 5523, 8000, 1...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_22/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....                           \n",
       "1  [[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....                           \n",
       "2  [[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....                           \n",
       "3  [[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....                           \n",
       "4  [[1993.13, 1371.29, 295.7, 271.59, 260.3, 254....                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_22/width_16k/canonical-token_feature_ids  \\\n",
       "0  [15056, 2037, 630, 10752, 8962, 16143, 5112, 1...                               \n",
       "1  [15056, 2037, 630, 10752, 8962, 16143, 5112, 1...                               \n",
       "2  [15056, 2037, 630, 4454, 4384, 13017, 16364, 1...                               \n",
       "3  [15056, 2037, 630, 10752, 8962, 16143, 5112, 1...                               \n",
       "4  [15056, 2037, 630, 10668, 13173, 10752, 15056,...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_23/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...                          \n",
       "1  [[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...                          \n",
       "2  [[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...                          \n",
       "3  [[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...                          \n",
       "4  [[3956, 6961, 8321, 1344, 4770, 3854, 12258, 1...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_23/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2067.19, 1388.15, 290.23, 256.19, 256.17, 24...                           \n",
       "1  [[2067.19, 1388.15, 290.23, 256.19, 256.17, 24...                           \n",
       "2  [[2067.19, 1388.15, 290.23, 256.19, 256.17, 24...                           \n",
       "3  [[2067.18, 1388.15, 290.23, 256.19, 256.17, 24...                           \n",
       "4  [[2067.19, 1388.15, 290.23, 256.19, 256.17, 24...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_23/width_16k/canonical-token_feature_ids  \\\n",
       "0  [3956, 6961, 8321, 932, 5286, 8797, 2385, 9382...                               \n",
       "1  [3956, 6961, 8321, 932, 5286, 8797, 2385, 9382...                               \n",
       "2  [3956, 6961, 8321, 13725, 5969, 4572, 6083, 11...                               \n",
       "3  [3956, 6961, 8321, 932, 5286, 8797, 2385, 9382...                               \n",
       "4  [3956, 6961, 8321, 15401, 3220, 932, 2135, 696...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_24/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[1802, 14391, 14836, 4182, 15109, 14832, 395,...                          \n",
       "1  [[1802, 14391, 14836, 4182, 15109, 14832, 395,...                          \n",
       "2  [[1802, 14391, 14836, 4182, 15109, 14832, 395,...                          \n",
       "3  [[1802, 14391, 14836, 4182, 15109, 14832, 395,...                          \n",
       "4  [[1802, 14391, 14836, 4182, 15109, 14832, 395,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_24/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...                           \n",
       "1  [[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...                           \n",
       "2  [[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...                           \n",
       "3  [[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...                           \n",
       "4  [[2420.98, 746.7, 364.94, 320.53, 317.5, 286.8...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_24/width_16k/canonical-token_feature_ids  \\\n",
       "0  [1802, 14391, 14836, 12205, 3848, 501, 3650, 1...                               \n",
       "1  [1802, 14391, 14836, 12205, 3848, 501, 3650, 1...                               \n",
       "2  [1802, 14391, 14836, 3932, 14448, 11326, 16317...                               \n",
       "3  [1802, 14391, 14836, 12205, 3848, 501, 3650, 1...                               \n",
       "4  [1802, 14391, 14836, 14746, 15730, 12893, 1444...                               \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_25/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[7479, 5149, 14186, 14325, 15861, 15298, 1734...                          \n",
       "1  [[7479, 5149, 14186, 14325, 15861, 15298, 1734...                          \n",
       "2  [[7479, 5149, 14186, 14325, 15861, 15298, 1734...                          \n",
       "3  [[7479, 5149, 14186, 14325, 15861, 15298, 1734...                          \n",
       "4  [[7479, 5149, 14186, 14325, 15861, 15298, 1734...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_25/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2302.48, 919.27, 913.31, 362.69, 330.19, 330...                           \n",
       "1  [[2302.48, 919.27, 913.31, 362.69, 330.19, 330...                           \n",
       "2  [[2302.48, 919.27, 913.31, 362.69, 330.19, 330...                           \n",
       "3  [[2302.48, 919.27, 913.31, 362.69, 330.19, 330...                           \n",
       "4  [[2302.48, 919.27, 913.31, 362.69, 330.19, 330...                           \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_25/width_16k/canonical-token_feature_ids  \\\n",
       "0  [7479, 5149, 14186, 14325, 3627, 484, 13749, 1...                               \n",
       "1  [7479, 5149, 14186, 14325, 3627, 484, 13749, 1...                               \n",
       "2  [7479, 5149, 14186, 208, 15298, 14325, 15298, ...                               \n",
       "3  [7479, 5149, 14186, 14325, 3627, 484, 13749, 1...                               \n",
       "4  [7479, 5149, 14186, 14325, 4263, 5588, 15298, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_0/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...                         \n",
       "1  [[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...                         \n",
       "2  [[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...                         \n",
       "3  [[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...                         \n",
       "4  [[3880, 1421, 1608, 9944, 6706, 14044, 655, 23...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_0/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...                          \n",
       "1  [[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...                          \n",
       "2  [[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...                          \n",
       "3  [[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...                          \n",
       "4  [[5.51, 5.38, 4.9, 4.81, 3.76, 3.16, 2.85, 2.5...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_0/width_16k/canonical-token_feature_ids  \\\n",
       "0  [3880, 1421, 1608, 3880, 1608, 9944, 8636, 142...                              \n",
       "1  [3880, 1421, 1608, 3880, 1608, 9944, 8636, 142...                              \n",
       "2  [3880, 1421, 1608, 3880, 9944, 1608, 3121, 388...                              \n",
       "3  [3880, 1421, 1608, 3880, 1608, 9944, 8636, 142...                              \n",
       "4  [3880, 1421, 1608, 3880, 1608, 9944, 3681, 142...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_1/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[15873, 7914, 11003, 7428, 15345, 5816, 14312...                         \n",
       "1  [[15873, 7914, 11003, 7428, 15345, 5816, 14312...                         \n",
       "2  [[15873, 7914, 11003, 7428, 15345, 5816, 14312...                         \n",
       "3  [[15873, 7914, 11003, 7428, 15345, 5816, 14312...                         \n",
       "4  [[15873, 7914, 11003, 7428, 15345, 5816, 14312...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_1/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...                          \n",
       "1  [[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...                          \n",
       "2  [[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...                          \n",
       "3  [[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...                          \n",
       "4  [[2.64, 1.16, 1.06, 0.74, 0.4, 0.39, 0.34, 0.3...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_1/width_16k/canonical-token_feature_ids  \\\n",
       "0  [15873, 7914, 11003, 15873, 11003, 7914, 15157...                              \n",
       "1  [15873, 7914, 11003, 15873, 11003, 7914, 15157...                              \n",
       "2  [15873, 7914, 11003, 15873, 11003, 7914, 3558,...                              \n",
       "3  [15873, 7914, 11003, 15873, 11003, 7914, 15157...                              \n",
       "4  [15873, 7914, 11003, 15873, 7914, 11003, 3823,...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_2/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[13234, 888, 11147, 8912, 14708, 3818, 9138, ...                         \n",
       "1  [[13234, 888, 11147, 8912, 14708, 3818, 9138, ...                         \n",
       "2  [[13234, 888, 11147, 8912, 14708, 3818, 9138, ...                         \n",
       "3  [[13234, 888, 11147, 8912, 14708, 3818, 9138, ...                         \n",
       "4  [[13234, 888, 11147, 8912, 14708, 3818, 9138, ...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_2/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....                          \n",
       "1  [[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....                          \n",
       "2  [[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....                          \n",
       "3  [[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....                          \n",
       "4  [[3.03, 2.29, 2.24, 1.92, 0.72, 0.57, 0.53, 0....                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_2/width_16k/canonical-token_feature_ids  \\\n",
       "0  [13234, 888, 11147, 13644, 12037, 8012, 12169,...                              \n",
       "1  [13234, 888, 11147, 13644, 12037, 8012, 12169,...                              \n",
       "2  [13234, 888, 11147, 4598, 13234, 13530, 15293,...                              \n",
       "3  [13234, 888, 11147, 13644, 12037, 8012, 12169,...                              \n",
       "4  [13234, 888, 11147, 7188, 8012, 4445, 9519, 10...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_3/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[6576, 4257, 10471, 12044, 14532, 7826, 1451,...                         \n",
       "1  [[6576, 4257, 10471, 12044, 14532, 7826, 1451,...                         \n",
       "2  [[6576, 4257, 10471, 12044, 14532, 7826, 1451,...                         \n",
       "3  [[6576, 4257, 10471, 12044, 14532, 7826, 1451,...                         \n",
       "4  [[6576, 4257, 10471, 12044, 14532, 7826, 1451,...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_3/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....                          \n",
       "1  [[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....                          \n",
       "2  [[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....                          \n",
       "3  [[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....                          \n",
       "4  [[7.07, 1.42, 1.17, 1.06, 0.98, 0.81, 0.78, 0....                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_3/width_16k/canonical-token_feature_ids  \\\n",
       "0  [6576, 4257, 10471, 6576, 15575, 3030, 4226, 9...                              \n",
       "1  [6576, 4257, 10471, 6576, 15575, 3030, 4226, 9...                              \n",
       "2  [6576, 4257, 10471, 6576, 4257, 12708, 6576, 5...                              \n",
       "3  [6576, 4257, 10471, 6576, 15575, 3030, 4226, 9...                              \n",
       "4  [6576, 4257, 10471, 6576, 10496, 15575, 15874,...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_4/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[5518, 4210, 10188, 8146, 14202, 12331, 884, ...                         \n",
       "1  [[5518, 4210, 10188, 8146, 14202, 12331, 884, ...                         \n",
       "2  [[5518, 4210, 10188, 8146, 14202, 12331, 884, ...                         \n",
       "3  [[5518, 4210, 10188, 8146, 14202, 12331, 884, ...                         \n",
       "4  [[5518, 4210, 10188, 8146, 14202, 12331, 884, ...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_4/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...                          \n",
       "1  [[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...                          \n",
       "2  [[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...                          \n",
       "3  [[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...                          \n",
       "4  [[4.3, 2.79, 1.36, 1.27, 1.2, 1.19, 1.12, 1.05...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_4/width_16k/canonical-token_feature_ids  \\\n",
       "0  [5518, 4210, 10188, 5518, 4742, 4210, 5518, 47...                              \n",
       "1  [5518, 4210, 10188, 5518, 4742, 4210, 5518, 47...                              \n",
       "2  [5518, 4210, 10188, 5518, 4742, 7240, 14596, 5...                              \n",
       "3  [5518, 4210, 10188, 5518, 4742, 4210, 5518, 47...                              \n",
       "4  [5518, 4210, 10188, 5518, 4742, 3110, 10676, 2...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_5/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[5252, 11557, 11619, 4107, 14508, 3087, 12114...                         \n",
       "1  [[5252, 11557, 11619, 4107, 14508, 3087, 12114...                         \n",
       "2  [[5252, 11557, 11619, 4107, 14508, 3087, 12114...                         \n",
       "3  [[5252, 11557, 11619, 4107, 14508, 3087, 12114...                         \n",
       "4  [[5252, 11557, 11619, 4107, 14508, 3087, 12114...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_5/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...                          \n",
       "1  [[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...                          \n",
       "2  [[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...                          \n",
       "3  [[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...                          \n",
       "4  [[6.01, 5.04, 4.51, 2.5, 2.34, 2.2, 1.92, 1.82...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_5/width_16k/canonical-token_feature_ids  \\\n",
       "0  [5252, 11557, 11619, 5252, 11557, 11619, 5252,...                              \n",
       "1  [5252, 11557, 11619, 5252, 11557, 11619, 5252,...                              \n",
       "2  [5252, 11557, 11619, 5252, 11557, 11619, 5252,...                              \n",
       "3  [5252, 11557, 11619, 5252, 11557, 11619, 5252,...                              \n",
       "4  [5252, 11557, 11619, 5252, 11557, 11619, 11557...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_6/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...                         \n",
       "1  [[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...                         \n",
       "2  [[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...                         \n",
       "3  [[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...                         \n",
       "4  [[1231, 9366, 15754, 9506, 6549, 3484, 9623, 3...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_6/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....                          \n",
       "1  [[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....                          \n",
       "2  [[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....                          \n",
       "3  [[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....                          \n",
       "4  [[4.84, 4.39, 3.47, 2.81, 2.75, 2.69, 2.35, 1....                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_6/width_16k/canonical-token_feature_ids  \\\n",
       "0  [1231, 9366, 15754, 4171, 1231, 12948, 1231, 5...                              \n",
       "1  [1231, 9366, 15754, 4171, 1231, 12948, 1231, 5...                              \n",
       "2  [1231, 9366, 15754, 4171, 6318, 1231, 1231, 41...                              \n",
       "3  [1231, 9366, 15754, 4171, 1231, 12948, 1231, 5...                              \n",
       "4  [1231, 9366, 15754, 4171, 1231, 5884, 1231, 50...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_7/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[5514, 2461, 12467, 10364, 7156, 14085, 14823...                         \n",
       "1  [[5514, 2461, 12467, 10364, 7156, 14085, 14823...                         \n",
       "2  [[5514, 2461, 12467, 10364, 7156, 14085, 14823...                         \n",
       "3  [[5514, 2461, 12467, 10364, 7156, 14085, 14823...                         \n",
       "4  [[5514, 2461, 12467, 10364, 7156, 14085, 14823...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_7/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...                          \n",
       "1  [[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...                          \n",
       "2  [[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...                          \n",
       "3  [[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...                          \n",
       "4  [[2.95, 2.91, 2.86, 2.3, 1.57, 1.55, 1.42, 1.3...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_7/width_16k/canonical-token_feature_ids  \\\n",
       "0  [5514, 2461, 12467, 10258, 10364, 5514, 10364,...                              \n",
       "1  [5514, 2461, 12467, 10258, 10364, 5514, 10364,...                              \n",
       "2  [5514, 2461, 12467, 10364, 10258, 5514, 10258,...                              \n",
       "3  [5514, 2461, 12467, 10258, 10364, 5514, 10364,...                              \n",
       "4  [5514, 2461, 12467, 10258, 10364, 5514, 10364,...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_8/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[4923, 11894, 10982, 11028, 9940, 2403, 5138,...                         \n",
       "1  [[4923, 11894, 10982, 11028, 9940, 2403, 5138,...                         \n",
       "2  [[4923, 11894, 10982, 11028, 9940, 2403, 5138,...                         \n",
       "3  [[4923, 11894, 10982, 11028, 9940, 2403, 5138,...                         \n",
       "4  [[4923, 11894, 10982, 11028, 9940, 2403, 5138,...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_8/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...                          \n",
       "1  [[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...                          \n",
       "2  [[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...                          \n",
       "3  [[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...                          \n",
       "4  [[6.41, 6.0, 3.54, 2.24, 1.89, 1.84, 1.81, 1.5...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_8/width_16k/canonical-token_feature_ids  \\\n",
       "0  [4923, 11894, 10982, 11382, 4923, 11894, 11894...                              \n",
       "1  [4923, 11894, 10982, 11382, 4923, 11894, 11894...                              \n",
       "2  [4923, 11894, 10982, 11382, 15743, 11894, 1189...                              \n",
       "3  [4923, 11894, 10982, 11382, 4923, 11894, 11894...                              \n",
       "4  [4923, 11894, 10982, 11382, 11894, 15743, 1189...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_9/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...                         \n",
       "1  [[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...                         \n",
       "2  [[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...                         \n",
       "3  [[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...                         \n",
       "4  [[4526, 1054, 15802, 5566, 4179, 677, 16154, 1...                         \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_9/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...                          \n",
       "1  [[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...                          \n",
       "2  [[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...                          \n",
       "3  [[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...                          \n",
       "4  [[10.48, 6.56, 6.01, 2.2, 2.04, 1.9, 1.6, 1.59...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_9/width_16k/canonical-token_feature_ids  \\\n",
       "0  [4526, 1054, 15802, 4526, 10930, 1054, 4526, 1...                              \n",
       "1  [4526, 1054, 15802, 4526, 10930, 1054, 4526, 1...                              \n",
       "2  [4526, 1054, 15802, 10930, 4526, 4450, 4526, 1...                              \n",
       "3  [4526, 1054, 15802, 4526, 10930, 1054, 4526, 1...                              \n",
       "4  [4526, 1054, 15802, 4526, 10930, 4450, 4526, 1...                              \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_10/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[3101, 11995, 13952, 3748, 11799, 7547, 14552...                          \n",
       "1  [[3101, 11995, 13952, 3748, 11799, 7547, 14552...                          \n",
       "2  [[3101, 11995, 13952, 3748, 11799, 7547, 14552...                          \n",
       "3  [[3101, 11995, 13952, 3748, 11799, 7547, 14552...                          \n",
       "4  [[3101, 11995, 13952, 3748, 11799, 7547, 14552...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_10/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...                           \n",
       "1  [[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...                           \n",
       "2  [[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...                           \n",
       "3  [[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...                           \n",
       "4  [[10.14, 8.27, 4.82, 4.52, 1.62, 1.59, 1.59, 1...                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_10/width_16k/canonical-token_feature_ids  \\\n",
       "0  [3101, 11995, 13952, 7876, 3101, 7844, 3101, 1...                               \n",
       "1  [3101, 11995, 13952, 7876, 3101, 7844, 3101, 1...                               \n",
       "2  [3101, 11995, 13952, 7876, 3101, 7844, 3101, 1...                               \n",
       "3  [3101, 11995, 13952, 7876, 3101, 7844, 3101, 1...                               \n",
       "4  [3101, 11995, 13952, 7876, 3101, 7844, 3101, 4...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_11/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[8683, 2311, 1110, 11075, 11763, 10633, 10905...                          \n",
       "1  [[8683, 2311, 1110, 11075, 11763, 10633, 10905...                          \n",
       "2  [[8683, 2311, 1110, 11075, 11763, 10633, 10905...                          \n",
       "3  [[8683, 2311, 1110, 11075, 11763, 10633, 10905...                          \n",
       "4  [[8683, 2311, 1110, 11075, 11763, 10633, 10905...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_11/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....                           \n",
       "1  [[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....                           \n",
       "2  [[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....                           \n",
       "3  [[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....                           \n",
       "4  [[6.83, 6.23, 4.19, 2.95, 2.64, 1.47, 1.43, 1....                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_11/width_16k/canonical-token_feature_ids  \\\n",
       "0  [8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...                               \n",
       "1  [8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...                               \n",
       "2  [8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...                               \n",
       "3  [8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...                               \n",
       "4  [8683, 2311, 1110, 5656, 2311, 947, 2311, 4895...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_12/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[6884, 10255, 14886, 486, 12861, 9087, 10703,...                          \n",
       "1  [[6884, 10255, 14886, 486, 12861, 9087, 10703,...                          \n",
       "2  [[6884, 10255, 14886, 486, 12861, 9087, 10703,...                          \n",
       "3  [[6884, 10255, 14886, 486, 12861, 9087, 10703,...                          \n",
       "4  [[6884, 10255, 14886, 486, 12861, 9087, 10703,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_12/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....                           \n",
       "1  [[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....                           \n",
       "2  [[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....                           \n",
       "3  [[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....                           \n",
       "4  [[9.58, 5.33, 5.23, 4.39, 2.43, 2.26, 2.08, 2....                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_12/width_16k/canonical-token_feature_ids  \\\n",
       "0  [6884, 10255, 14886, 13166, 10703, 6884, 14886...                               \n",
       "1  [6884, 10255, 14886, 13166, 10703, 6884, 14886...                               \n",
       "2  [6884, 10255, 14886, 13166, 10703, 6884, 14886...                               \n",
       "3  [6884, 10255, 14886, 13166, 10703, 6884, 14886...                               \n",
       "4  [6884, 10255, 14886, 13166, 10703, 6884, 14886...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_13/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[6025, 1654, 15853, 8632, 15290, 14175, 8202,...                          \n",
       "1  [[6025, 1654, 15853, 8632, 15290, 14175, 8202,...                          \n",
       "2  [[6025, 1654, 15853, 8632, 15290, 14175, 8202,...                          \n",
       "3  [[6025, 1654, 15853, 8632, 15290, 14175, 8202,...                          \n",
       "4  [[6025, 1654, 15853, 8632, 15290, 14175, 8202,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_13/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....                           \n",
       "1  [[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....                           \n",
       "2  [[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....                           \n",
       "3  [[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....                           \n",
       "4  [[6.24, 4.15, 2.02, 1.84, 1.71, 1.54, 1.45, 1....                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_13/width_16k/canonical-token_feature_ids  \\\n",
       "0  [6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...                               \n",
       "1  [6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...                               \n",
       "2  [6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...                               \n",
       "3  [6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...                               \n",
       "4  [6025, 1654, 15853, 14988, 6956, 6025, 6956, 1...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_14/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...                          \n",
       "1  [[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...                          \n",
       "2  [[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...                          \n",
       "3  [[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...                          \n",
       "4  [[3356, 2036, 1508, 12616, 12451, 882, 5526, 6...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_14/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...                           \n",
       "1  [[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...                           \n",
       "2  [[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...                           \n",
       "3  [[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...                           \n",
       "4  [[7.88, 5.54, 4.2, 3.27, 3.01, 2.71, 2.09, 1.6...                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_14/width_16k/canonical-token_feature_ids  \\\n",
       "0  [3356, 2036, 1508, 12301, 261, 15018, 9843, 33...                               \n",
       "1  [3356, 2036, 1508, 12301, 261, 15018, 9843, 33...                               \n",
       "2  [3356, 2036, 1508, 12301, 261, 15018, 261, 984...                               \n",
       "3  [3356, 2036, 1508, 12301, 261, 15018, 9843, 33...                               \n",
       "4  [3356, 2036, 1508, 12301, 261, 15018, 3356, 98...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_15/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[4542, 14855, 11886, 3064, 12706, 69, 13693, ...                          \n",
       "1  [[4542, 14855, 11886, 3064, 12706, 69, 13693, ...                          \n",
       "2  [[4542, 14855, 11886, 3064, 12706, 69, 13693, ...                          \n",
       "3  [[4542, 14855, 11886, 3064, 12706, 69, 13693, ...                          \n",
       "4  [[4542, 14855, 11886, 3064, 12706, 69, 13693, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_15/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...                           \n",
       "1  [[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...                           \n",
       "2  [[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...                           \n",
       "3  [[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...                           \n",
       "4  [[9.9, 3.58, 2.65, 2.55, 2.19, 1.72, 1.7, 1.49...                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_15/width_16k/canonical-token_feature_ids  \\\n",
       "0  [4542, 14855, 11886, 4542, 12706, 8038, 4447, ...                               \n",
       "1  [4542, 14855, 11886, 4542, 12706, 8038, 4447, ...                               \n",
       "2  [4542, 14855, 11886, 4542, 12706, 8038, 4447, ...                               \n",
       "3  [4542, 14855, 11886, 4542, 12706, 8038, 4447, ...                               \n",
       "4  [4542, 14855, 11886, 4542, 12706, 8038, 4447, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_16/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...                          \n",
       "1  [[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...                          \n",
       "2  [[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...                          \n",
       "3  [[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...                          \n",
       "4  [[11259, 4776, 3719, 1314, 12784, 7386, 1245, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_16/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...                           \n",
       "1  [[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...                           \n",
       "2  [[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...                           \n",
       "3  [[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...                           \n",
       "4  [[7.37, 3.82, 2.93, 2.0, 1.33, 1.07, 0.93, 0.8...                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_16/width_16k/canonical-token_feature_ids  \\\n",
       "0  [11259, 4776, 3719, 11390, 16350, 15727, 16350...                               \n",
       "1  [11259, 4776, 3719, 11390, 16350, 15727, 16350...                               \n",
       "2  [11259, 4776, 3719, 11390, 16350, 12299, 16350...                               \n",
       "3  [11259, 4776, 3719, 11390, 16350, 15727, 16350...                               \n",
       "4  [11259, 4776, 3719, 11390, 16350, 11259, 11259...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_17/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[14463, 11256, 1901, 11739, 15874, 7041, 1212...                          \n",
       "1  [[14463, 11256, 1901, 11739, 15874, 7041, 1212...                          \n",
       "2  [[14463, 11256, 1901, 11739, 15874, 7041, 1212...                          \n",
       "3  [[14463, 11256, 1901, 11739, 15874, 7041, 1212...                          \n",
       "4  [[14463, 11256, 1901, 11739, 15874, 7041, 1212...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_17/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....                           \n",
       "1  [[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....                           \n",
       "2  [[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....                           \n",
       "3  [[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....                           \n",
       "4  [[5.86, 5.14, 3.33, 1.75, 1.69, 1.47, 1.44, 1....                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_17/width_16k/canonical-token_feature_ids  \\\n",
       "0  [14463, 11256, 1901, 13628, 14463, 11305, 1446...                               \n",
       "1  [14463, 11256, 1901, 13628, 14463, 11305, 1446...                               \n",
       "2  [14463, 11256, 1901, 13628, 12260, 14463, 1446...                               \n",
       "3  [14463, 11256, 1901, 13628, 14463, 11305, 1446...                               \n",
       "4  [14463, 11256, 1901, 13628, 14463, 12260, 1446...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_18/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[7096, 7462, 12750, 15159, 14710, 14336, 8274...                          \n",
       "1  [[7096, 7462, 12750, 15159, 14710, 14336, 8274...                          \n",
       "2  [[7096, 7462, 12750, 15159, 14710, 14336, 8274...                          \n",
       "3  [[7096, 7462, 12750, 15159, 14710, 14336, 8274...                          \n",
       "4  [[7096, 7462, 12750, 15159, 14710, 14336, 8274...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_18/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....                           \n",
       "1  [[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....                           \n",
       "2  [[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....                           \n",
       "3  [[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....                           \n",
       "4  [[5.84, 2.04, 0.64, 0.63, 0.52, 0.48, 0.47, 0....                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_18/width_16k/canonical-token_feature_ids  \\\n",
       "0  [7096, 7462, 12750, 7096, 5053, 14984, 14984, ...                               \n",
       "1  [7096, 7462, 12750, 7096, 5053, 14984, 14984, ...                               \n",
       "2  [7096, 7462, 12750, 7096, 9729, 6420, 7096, 11...                               \n",
       "3  [7096, 7462, 12750, 7096, 5053, 14984, 14984, ...                               \n",
       "4  [7096, 7462, 12750, 7096, 9729, 2592, 7096, 55...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_19/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...                          \n",
       "1  [[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...                          \n",
       "2  [[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...                          \n",
       "3  [[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...                          \n",
       "4  [[12896, 7538, 1889, 3280, 10328, 9542, 560, 1...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_19/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....                           \n",
       "1  [[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....                           \n",
       "2  [[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....                           \n",
       "3  [[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....                           \n",
       "4  [[7.02, 4.12, 1.36, 1.04, 0.92, 0.91, 0.88, 0....                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_19/width_16k/canonical-token_feature_ids  \\\n",
       "0  [12896, 7538, 1889, 12796, 12896, 7896, 16316,...                               \n",
       "1  [12896, 7538, 1889, 12796, 12896, 7896, 16316,...                               \n",
       "2  [12896, 7538, 1889, 12796, 7896, 12896, 12896,...                               \n",
       "3  [12896, 7538, 1889, 12796, 12896, 7896, 16316,...                               \n",
       "4  [12896, 7538, 1889, 12796, 7896, 16289, 8750, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_20/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[9566, 12583, 4881, 12769, 11388, 2808, 5912,...                          \n",
       "1  [[9566, 12583, 4881, 12769, 11388, 2808, 5912,...                          \n",
       "2  [[9566, 12583, 4881, 12769, 11388, 2808, 5912,...                          \n",
       "3  [[9566, 12583, 4881, 12769, 11388, 2808, 5912,...                          \n",
       "4  [[9566, 12583, 4881, 12769, 11388, 2808, 5912,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_20/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...                           \n",
       "1  [[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...                           \n",
       "2  [[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...                           \n",
       "3  [[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...                           \n",
       "4  [[3.4, 1.8, 0.68, 0.64, 0.63, 0.61, 0.61, 0.6,...                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_20/width_16k/canonical-token_feature_ids  \\\n",
       "0  [9566, 12583, 4881, 9566, 12583, 4766, 9566, 4...                               \n",
       "1  [9566, 12583, 4881, 9566, 12583, 4766, 9566, 4...                               \n",
       "2  [9566, 12583, 4881, 753, 9566, 12583, 14863, 9...                               \n",
       "3  [9566, 12583, 4881, 9566, 12583, 4766, 9566, 4...                               \n",
       "4  [9566, 12583, 4881, 9566, 12583, 8704, 9566, 1...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_21/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[11959, 16293, 1028, 6700, 783, 12140, 4377, ...                          \n",
       "1  [[11959, 16293, 1028, 6700, 783, 12140, 4377, ...                          \n",
       "2  [[11959, 16293, 1028, 6700, 783, 12140, 4377, ...                          \n",
       "3  [[11959, 16293, 1028, 6700, 783, 12140, 4377, ...                          \n",
       "4  [[11959, 16293, 1028, 6700, 783, 12140, 4377, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_21/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....                           \n",
       "1  [[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....                           \n",
       "2  [[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....                           \n",
       "3  [[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....                           \n",
       "4  [[5.19, 4.07, 1.51, 0.99, 0.97, 0.96, 0.94, 0....                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_21/width_16k/canonical-token_feature_ids  \\\n",
       "0  [11959, 16293, 1028, 3858, 16293, 11959, 11959...                               \n",
       "1  [11959, 16293, 1028, 3858, 16293, 11959, 11959...                               \n",
       "2  [11959, 16293, 1028, 3858, 16293, 5795, 6359, ...                               \n",
       "3  [11959, 16293, 1028, 3858, 16293, 11959, 11959...                               \n",
       "4  [11959, 16293, 1028, 3858, 16293, 6819, 11959,...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_22/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...                          \n",
       "1  [[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...                          \n",
       "2  [[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...                          \n",
       "3  [[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...                          \n",
       "4  [[14953, 12042, 11637, 0, 6, 3, 5, 4, 1, 2], [...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_22/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...                           \n",
       "1  [[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...                           \n",
       "2  [[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...                           \n",
       "3  [[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...                           \n",
       "4  [[3.93, 0.41, 0.21, 0.0, 0.0, 0.0, 0.0, 0.0, 0...                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_22/width_16k/canonical-token_feature_ids  \\\n",
       "0  [14953, 12042, 11637, 14953, 697, 5889, 14953,...                               \n",
       "1  [14953, 12042, 11637, 14953, 697, 5889, 14953,...                               \n",
       "2  [14953, 12042, 11637, 14953, 6306, 16361, 1495...                               \n",
       "3  [14953, 12042, 11637, 14953, 697, 5889, 14953,...                               \n",
       "4  [14953, 12042, 11637, 14953, 461, 9186, 14953,...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_23/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...                          \n",
       "1  [[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...                          \n",
       "2  [[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...                          \n",
       "3  [[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...                          \n",
       "4  [[5279, 11288, 13838, 4812, 7859, 2470, 7298, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_23/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....                           \n",
       "1  [[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....                           \n",
       "2  [[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....                           \n",
       "3  [[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....                           \n",
       "4  [[3.17, 3.08, 1.16, 0.99, 0.86, 0.83, 0.83, 0....                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_23/width_16k/canonical-token_feature_ids  \\\n",
       "0  [5279, 11288, 13838, 5279, 8424, 3820, 5279, 6...                               \n",
       "1  [5279, 11288, 13838, 5279, 8424, 3820, 5279, 6...                               \n",
       "2  [5279, 11288, 13838, 10395, 3820, 2704, 7953, ...                               \n",
       "3  [5279, 11288, 13838, 5279, 8424, 3820, 5279, 6...                               \n",
       "4  [5279, 11288, 13838, 2704, 8424, 5279, 2207, 5...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_24/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[12402, 3678, 10405, 7012, 7290, 12500, 5465,...                          \n",
       "1  [[12402, 3678, 10405, 7012, 7290, 12500, 5465,...                          \n",
       "2  [[12402, 3678, 10405, 7012, 7290, 12500, 5465,...                          \n",
       "3  [[12402, 3678, 10405, 7012, 7290, 12500, 5465,...                          \n",
       "4  [[12402, 3678, 10405, 7012, 7290, 12500, 5465,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_24/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...                           \n",
       "1  [[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...                           \n",
       "2  [[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...                           \n",
       "3  [[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...                           \n",
       "4  [[4.12, 1.22, 1.14, 1.0, 1.0, 0.98, 0.94, 0.94...                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_24/width_16k/canonical-token_feature_ids  \\\n",
       "0  [12402, 3678, 10405, 13983, 12402, 14623, 1398...                               \n",
       "1  [12402, 3678, 10405, 13983, 12402, 14623, 1398...                               \n",
       "2  [12402, 3678, 10405, 12402, 1315, 1095, 12402,...                               \n",
       "3  [12402, 3678, 10405, 13983, 12402, 14623, 1398...                               \n",
       "4  [12402, 3678, 10405, 12402, 1095, 21, 3954, 12...                               \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_25/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...                          \n",
       "1  [[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...                          \n",
       "2  [[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...                          \n",
       "3  [[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...                          \n",
       "4  [[5364, 11788, 9449, 10494, 3704, 7379, 1957, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_25/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....                           \n",
       "1  [[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....                           \n",
       "2  [[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....                           \n",
       "3  [[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....                           \n",
       "4  [[2.18, 2.17, 2.08, 1.27, 1.18, 0.93, 0.89, 0....                           \n",
       "\n",
       "  gemma-scope-2b-pt-att-canonical-layer_25/width_16k/canonical-token_feature_ids  \\\n",
       "0  [5364, 11788, 9449, 15678, 4382, 9024, 13675, ...                               \n",
       "1  [5364, 11788, 9449, 15678, 4382, 9024, 13675, ...                               \n",
       "2  [5364, 11788, 9449, 5714, 4846, 3222, 8280, 48...                               \n",
       "3  [5364, 11788, 9449, 15678, 4382, 9024, 13675, ...                               \n",
       "4  [5364, 11788, 9449, 4337, 6438, 15678, 15678, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_0/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[15745, 2628, 10077, 8629, 9147, 3088, 10698,...                         \n",
       "1  [[15745, 2628, 10077, 8629, 9147, 3088, 10698,...                         \n",
       "2  [[15745, 2628, 10077, 8629, 9147, 3088, 10698,...                         \n",
       "3  [[15745, 2628, 10077, 8629, 9147, 3088, 10698,...                         \n",
       "4  [[15745, 2628, 10077, 8629, 9147, 3088, 10698,...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_0/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...                          \n",
       "1  [[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...                          \n",
       "2  [[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...                          \n",
       "3  [[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...                          \n",
       "4  [[132.36, 56.69, 44.72, 34.79, 13.81, 11.45, 1...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_0/width_16k/canonical-token_feature_ids  \\\n",
       "0  [15745, 2628, 10077, 9038, 10698, 6214, 13955,...                              \n",
       "1  [15745, 2628, 10077, 9038, 10698, 6214, 13955,...                              \n",
       "2  [15745, 2628, 10077, 9038, 13955, 14932, 13955...                              \n",
       "3  [15745, 2628, 10077, 9038, 10698, 6214, 13955,...                              \n",
       "4  [15745, 2628, 10077, 9038, 3638, 15022, 13955,...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_1/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[7101, 890, 11950, 11426, 9709, 15133, 3060, ...                         \n",
       "1  [[7101, 890, 11950, 11426, 9709, 15133, 3060, ...                         \n",
       "2  [[7101, 890, 11950, 11426, 9709, 15133, 3060, ...                         \n",
       "3  [[7101, 890, 11950, 11426, 9709, 15133, 3060, ...                         \n",
       "4  [[7101, 890, 11950, 11426, 9709, 15133, 3060, ...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_1/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....                          \n",
       "1  [[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....                          \n",
       "2  [[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....                          \n",
       "3  [[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....                          \n",
       "4  [[145.91, 39.93, 22.56, 18.54, 15.94, 9.79, 9....                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_1/width_16k/canonical-token_feature_ids  \\\n",
       "0  [7101, 890, 11950, 12057, 322, 9790, 12057, 11...                              \n",
       "1  [7101, 890, 11950, 12057, 322, 9790, 12057, 11...                              \n",
       "2  [7101, 890, 11950, 12057, 322, 13730, 4684, 12...                              \n",
       "3  [7101, 890, 11950, 12057, 322, 9790, 12057, 11...                              \n",
       "4  [7101, 890, 11950, 12057, 322, 11894, 598, 719...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_2/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[5817, 4198, 2493, 4736, 962, 266, 12247, 953...                         \n",
       "1  [[5817, 4198, 2493, 4736, 962, 266, 12247, 953...                         \n",
       "2  [[5817, 4198, 2493, 4736, 962, 266, 12247, 953...                         \n",
       "3  [[5817, 4198, 2493, 4736, 962, 266, 12247, 953...                         \n",
       "4  [[5817, 4198, 2493, 4736, 962, 266, 12247, 953...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_2/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...                          \n",
       "1  [[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...                          \n",
       "2  [[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...                          \n",
       "3  [[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...                          \n",
       "4  [[55.55, 31.71, 10.95, 8.22, 4.67, 4.54, 4.46,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_2/width_16k/canonical-token_feature_ids  \\\n",
       "0  [5817, 4198, 2493, 13276, 15637, 14206, 4736, ...                              \n",
       "1  [5817, 4198, 2493, 13276, 15637, 14206, 4736, ...                              \n",
       "2  [5817, 4198, 2493, 2900, 15525, 15165, 3077, 3...                              \n",
       "3  [5817, 4198, 2493, 13276, 15637, 14206, 4736, ...                              \n",
       "4  [5817, 4198, 2493, 15619, 2673, 6158, 3236, 12...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_3/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...                         \n",
       "1  [[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...                         \n",
       "2  [[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...                         \n",
       "3  [[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...                         \n",
       "4  [[4730, 6258, 5254, 1290, 9918, 11886, 9159, 2...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_3/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...                          \n",
       "1  [[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...                          \n",
       "2  [[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...                          \n",
       "3  [[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...                          \n",
       "4  [[99.95, 34.77, 29.53, 8.71, 7.37, 6.11, 5.85,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_3/width_16k/canonical-token_feature_ids  \\\n",
       "0  [4730, 6258, 5254, 4185, 3710, 3680, 1427, 79,...                              \n",
       "1  [4730, 6258, 5254, 4185, 3710, 3680, 1427, 79,...                              \n",
       "2  [4730, 6258, 5254, 4730, 12740, 7272, 13839, 4...                              \n",
       "3  [4730, 6258, 5254, 4185, 3710, 3680, 1427, 79,...                              \n",
       "4  [4730, 6258, 5254, 9322, 4456, 4185, 4730, 127...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_4/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[12597, 10159, 14164, 11873, 14566, 12669, 74...                         \n",
       "1  [[12597, 10159, 14164, 11873, 14566, 12669, 74...                         \n",
       "2  [[12597, 10159, 14164, 11873, 14566, 12669, 74...                         \n",
       "3  [[12597, 10159, 14164, 11873, 14566, 12669, 74...                         \n",
       "4  [[12597, 10159, 14164, 11873, 14566, 12669, 74...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_4/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...                          \n",
       "1  [[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...                          \n",
       "2  [[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...                          \n",
       "3  [[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...                          \n",
       "4  [[96.92, 39.67, 25.2, 7.74, 6.13, 4.32, 4.28, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_4/width_16k/canonical-token_feature_ids  \\\n",
       "0  [12597, 10159, 14164, 2793, 12597, 6186, 12597...                              \n",
       "1  [12597, 10159, 14164, 2793, 12597, 6186, 12597...                              \n",
       "2  [12597, 10159, 14164, 2793, 14164, 6186, 2793,...                              \n",
       "3  [12597, 10159, 14164, 2793, 12597, 6186, 12597...                              \n",
       "4  [12597, 10159, 14164, 2793, 12597, 6186, 12597...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_5/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[15592, 12904, 4700, 13680, 2955, 9554, 15209...                         \n",
       "1  [[15592, 12904, 4700, 13680, 2955, 9554, 15209...                         \n",
       "2  [[15592, 12904, 4700, 13680, 2955, 9554, 15209...                         \n",
       "3  [[15592, 12904, 4700, 13680, 2955, 9554, 15209...                         \n",
       "4  [[15592, 12904, 4700, 13680, 2955, 9554, 15209...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_5/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....                          \n",
       "1  [[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....                          \n",
       "2  [[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....                          \n",
       "3  [[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....                          \n",
       "4  [[86.35, 38.9, 30.02, 20.18, 16.62, 13.71, 10....                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_5/width_16k/canonical-token_feature_ids  \\\n",
       "0  [15592, 12904, 4700, 686, 15592, 5758, 15592, ...                              \n",
       "1  [15592, 12904, 4700, 686, 15592, 5758, 15592, ...                              \n",
       "2  [15592, 12904, 4700, 686, 15592, 1067, 15592, ...                              \n",
       "3  [15592, 12904, 4700, 686, 15592, 5758, 15592, ...                              \n",
       "4  [15592, 12904, 4700, 686, 15592, 14352, 15592,...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_6/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...                         \n",
       "1  [[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...                         \n",
       "2  [[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...                         \n",
       "3  [[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...                         \n",
       "4  [[7589, 6941, 7590, 15936, 3112, 4335, 7444, 1...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_6/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...                          \n",
       "1  [[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...                          \n",
       "2  [[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...                          \n",
       "3  [[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...                          \n",
       "4  [[152.88, 40.7, 23.18, 10.84, 7.17, 6.92, 4.77...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_6/width_16k/canonical-token_feature_ids  \\\n",
       "0  [7589, 6941, 7590, 9583, 5371, 7730, 4143, 958...                              \n",
       "1  [7589, 6941, 7590, 9583, 5371, 7730, 4143, 958...                              \n",
       "2  [7589, 6941, 7590, 178, 5371, 9058, 9583, 8424...                              \n",
       "3  [7589, 6941, 7590, 9583, 5371, 7730, 4143, 958...                              \n",
       "4  [7589, 6941, 7590, 178, 5046, 5371, 7499, 7589...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_7/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[12096, 11676, 7040, 4053, 9060, 11423, 13517...                         \n",
       "1  [[12096, 11676, 7040, 4053, 9060, 11423, 13517...                         \n",
       "2  [[12096, 11676, 7040, 4053, 9060, 11423, 13517...                         \n",
       "3  [[12096, 11676, 7040, 4053, 9060, 11423, 13517...                         \n",
       "4  [[12096, 11676, 7040, 4053, 9060, 11423, 13517...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_7/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...                          \n",
       "1  [[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...                          \n",
       "2  [[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...                          \n",
       "3  [[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...                          \n",
       "4  [[144.65, 47.84, 26.56, 9.8, 9.53, 7.65, 7.13,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_7/width_16k/canonical-token_feature_ids  \\\n",
       "0  [12096, 11676, 7040, 12096, 9778, 6117, 12096,...                              \n",
       "1  [12096, 11676, 7040, 12096, 9778, 6117, 12096,...                              \n",
       "2  [12096, 11676, 7040, 12096, 9778, 4053, 12096,...                              \n",
       "3  [12096, 11676, 7040, 12096, 9778, 6117, 12096,...                              \n",
       "4  [12096, 11676, 7040, 12096, 9778, 4053, 12096,...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_8/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...                         \n",
       "1  [[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...                         \n",
       "2  [[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...                         \n",
       "3  [[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...                         \n",
       "4  [[1367, 10938, 5451, 3126, 10152, 2341, 4021, ...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_8/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...                          \n",
       "1  [[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...                          \n",
       "2  [[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...                          \n",
       "3  [[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...                          \n",
       "4  [[147.4, 28.13, 25.94, 8.62, 6.36, 5.75, 5.11,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_8/width_16k/canonical-token_feature_ids  \\\n",
       "0  [1367, 10938, 5451, 10312, 13, 7282, 6279, 136...                              \n",
       "1  [1367, 10938, 5451, 10312, 13, 7282, 6279, 136...                              \n",
       "2  [1367, 10938, 5451, 8286, 7282, 9743, 1367, 76...                              \n",
       "3  [1367, 10938, 5451, 10312, 13, 7282, 6279, 136...                              \n",
       "4  [1367, 10938, 5451, 8286, 7282, 9743, 1367, 59...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_9/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...                         \n",
       "1  [[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...                         \n",
       "2  [[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...                         \n",
       "3  [[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...                         \n",
       "4  [[11525, 11530, 2788, 7622, 7418, 7946, 3748, ...                         \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_9/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...                          \n",
       "1  [[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...                          \n",
       "2  [[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...                          \n",
       "3  [[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...                          \n",
       "4  [[241.42, 19.2, 15.71, 15.19, 14.47, 12.52, 10...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_9/width_16k/canonical-token_feature_ids  \\\n",
       "0  [11525, 11530, 2788, 11525, 2788, 7622, 13788,...                              \n",
       "1  [11525, 11530, 2788, 11525, 2788, 7622, 13788,...                              \n",
       "2  [11525, 11530, 2788, 11525, 2788, 7622, 11525,...                              \n",
       "3  [11525, 11530, 2788, 11525, 2788, 7622, 13788,...                              \n",
       "4  [11525, 11530, 2788, 11525, 2788, 7622, 11525,...                              \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_10/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...                          \n",
       "1  [[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...                          \n",
       "2  [[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...                          \n",
       "3  [[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...                          \n",
       "4  [[7495, 3117, 6381, 1202, 4114, 7758, 7257, 53...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_10/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...                           \n",
       "1  [[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...                           \n",
       "2  [[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...                           \n",
       "3  [[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...                           \n",
       "4  [[184.66, 23.19, 8.31, 7.67, 7.64, 7.59, 7.58,...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_10/width_16k/canonical-token_feature_ids  \\\n",
       "0  [7495, 3117, 6381, 7495, 8202, 5376, 7495, 860...                               \n",
       "1  [7495, 3117, 6381, 7495, 8202, 5376, 7495, 860...                               \n",
       "2  [7495, 3117, 6381, 7495, 8202, 13140, 6972, 11...                               \n",
       "3  [7495, 3117, 6381, 7495, 8202, 5376, 7495, 860...                               \n",
       "4  [7495, 3117, 6381, 7495, 8202, 5376, 11388, 15...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_11/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[6316, 3458, 15102, 4397, 10966, 6806, 10388,...                          \n",
       "1  [[6316, 3458, 15102, 4397, 10966, 6806, 10388,...                          \n",
       "2  [[6316, 3458, 15102, 4397, 10966, 6806, 10388,...                          \n",
       "3  [[6316, 3458, 15102, 4397, 10966, 6806, 10388,...                          \n",
       "4  [[6316, 3458, 15102, 4397, 10966, 6806, 10388,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_11/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...                           \n",
       "1  [[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...                           \n",
       "2  [[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...                           \n",
       "3  [[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...                           \n",
       "4  [[197.23, 23.48, 23.0, 11.53, 9.46, 8.27, 5.83...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_11/width_16k/canonical-token_feature_ids  \\\n",
       "0  [6316, 3458, 15102, 6316, 3318, 3458, 5421, 13...                               \n",
       "1  [6316, 3458, 15102, 6316, 3318, 3458, 5421, 13...                               \n",
       "2  [6316, 3458, 15102, 6316, 3318, 3458, 6316, 83...                               \n",
       "3  [6316, 3458, 15102, 6316, 3318, 3458, 5421, 13...                               \n",
       "4  [6316, 3458, 15102, 6316, 3318, 3458, 6316, 12...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_12/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...                          \n",
       "1  [[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...                          \n",
       "2  [[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...                          \n",
       "3  [[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...                          \n",
       "4  [[9338, 2350, 11394, 2651, 1261, 14995, 6764, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_12/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...                           \n",
       "1  [[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...                           \n",
       "2  [[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...                           \n",
       "3  [[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...                           \n",
       "4  [[175.46, 22.35, 19.9, 14.64, 10.1, 9.78, 6.02...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_12/width_16k/canonical-token_feature_ids  \\\n",
       "0  [9338, 2350, 11394, 2636, 8191, 10598, 9819, 1...                               \n",
       "1  [9338, 2350, 11394, 2636, 8191, 10598, 9819, 1...                               \n",
       "2  [9338, 2350, 11394, 2636, 9338, 8191, 9034, 67...                               \n",
       "3  [9338, 2350, 11394, 2636, 8191, 10598, 9819, 1...                               \n",
       "4  [9338, 2350, 11394, 2636, 9338, 8191, 9338, 67...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_13/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[13617, 4166, 16213, 12064, 10652, 7512, 1589...                          \n",
       "1  [[13617, 4166, 16213, 12064, 10652, 7512, 1589...                          \n",
       "2  [[13617, 4166, 16213, 12064, 10652, 7512, 1589...                          \n",
       "3  [[13617, 4166, 16213, 12064, 10652, 7512, 1589...                          \n",
       "4  [[13617, 4166, 16213, 12064, 10652, 7512, 1589...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_13/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...                           \n",
       "1  [[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...                           \n",
       "2  [[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...                           \n",
       "3  [[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...                           \n",
       "4  [[192.08, 23.67, 15.95, 12.16, 9.67, 6.56, 6.4...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_13/width_16k/canonical-token_feature_ids  \\\n",
       "0  [13617, 4166, 16213, 249, 3869, 4290, 13617, 1...                               \n",
       "1  [13617, 4166, 16213, 249, 3869, 4290, 13617, 1...                               \n",
       "2  [13617, 4166, 16213, 249, 3869, 6952, 12754, 8...                               \n",
       "3  [13617, 4166, 16213, 249, 3869, 4290, 13617, 1...                               \n",
       "4  [13617, 4166, 16213, 249, 3869, 7095, 5233, 54...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_14/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...                          \n",
       "1  [[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...                          \n",
       "2  [[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...                          \n",
       "3  [[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...                          \n",
       "4  [[14672, 2673, 3001, 12860, 4958, 2412, 9354, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_14/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...                           \n",
       "1  [[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...                           \n",
       "2  [[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...                           \n",
       "3  [[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...                           \n",
       "4  [[166.83, 33.77, 9.57, 5.5, 4.53, 4.37, 3.99, ...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_14/width_16k/canonical-token_feature_ids  \\\n",
       "0  [14672, 2673, 3001, 8681, 2564, 7488, 8681, 12...                               \n",
       "1  [14672, 2673, 3001, 8681, 2564, 7488, 8681, 12...                               \n",
       "2  [14672, 2673, 3001, 8681, 2564, 13451, 14722, ...                               \n",
       "3  [14672, 2673, 3001, 8681, 2564, 7488, 8681, 12...                               \n",
       "4  [14672, 2673, 3001, 8681, 2564, 9646, 14672, 4...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_15/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...                          \n",
       "1  [[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...                          \n",
       "2  [[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...                          \n",
       "3  [[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...                          \n",
       "4  [[75, 12355, 8833, 2255, 13336, 15296, 5174, 1...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_15/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...                           \n",
       "1  [[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...                           \n",
       "2  [[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...                           \n",
       "3  [[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...                           \n",
       "4  [[175.74, 30.56, 12.1, 11.83, 5.81, 3.91, 3.44...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_15/width_16k/canonical-token_feature_ids  \\\n",
       "0  [75, 12355, 8833, 75, 14877, 8833, 75, 14261, ...                               \n",
       "1  [75, 12355, 8833, 75, 14877, 8833, 75, 14261, ...                               \n",
       "2  [75, 12355, 8833, 75, 8833, 11574, 15086, 75, ...                               \n",
       "3  [75, 12355, 8833, 75, 14877, 8833, 75, 14261, ...                               \n",
       "4  [75, 12355, 8833, 75, 8833, 14877, 75, 3439, 9...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_16/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...                          \n",
       "1  [[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...                          \n",
       "2  [[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...                          \n",
       "3  [[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...                          \n",
       "4  [[9218, 7586, 6883, 14386, 9885, 16117, 7776, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_16/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...                           \n",
       "1  [[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...                           \n",
       "2  [[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...                           \n",
       "3  [[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...                           \n",
       "4  [[192.63, 43.28, 13.59, 7.88, 5.73, 5.47, 4.0,...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_16/width_16k/canonical-token_feature_ids  \\\n",
       "0  [9218, 7586, 6883, 11167, 2604, 593, 9218, 155...                               \n",
       "1  [9218, 7586, 6883, 11167, 2604, 593, 9218, 155...                               \n",
       "2  [9218, 7586, 6883, 11167, 2604, 9601, 7302, 92...                               \n",
       "3  [9218, 7586, 6883, 11167, 2604, 593, 9218, 155...                               \n",
       "4  [9218, 7586, 6883, 11167, 2604, 3467, 9218, 40...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_17/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[5845, 11167, 1359, 15100, 5745, 10491, 12367...                          \n",
       "1  [[5845, 11167, 1359, 15100, 5745, 10491, 12367...                          \n",
       "2  [[5845, 11167, 1359, 15100, 5745, 10491, 12367...                          \n",
       "3  [[5845, 11167, 1359, 15100, 5745, 10491, 12367...                          \n",
       "4  [[5845, 11167, 1359, 15100, 5745, 10491, 12367...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_17/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...                           \n",
       "1  [[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...                           \n",
       "2  [[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...                           \n",
       "3  [[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...                           \n",
       "4  [[168.95, 59.23, 8.13, 6.43, 6.21, 5.98, 4.63,...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_17/width_16k/canonical-token_feature_ids  \\\n",
       "0  [5845, 11167, 1359, 2506, 1600, 14844, 9380, 4...                               \n",
       "1  [5845, 11167, 1359, 2506, 1600, 14844, 9380, 4...                               \n",
       "2  [5845, 11167, 1359, 2506, 1600, 3944, 16045, 5...                               \n",
       "3  [5845, 11167, 1359, 2506, 1600, 14844, 9380, 4...                               \n",
       "4  [5845, 11167, 1359, 2506, 1600, 16318, 9817, 5...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_18/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...                          \n",
       "1  [[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...                          \n",
       "2  [[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...                          \n",
       "3  [[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...                          \n",
       "4  [[77, 7228, 16359, 61, 3571, 6094, 7534, 16039...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_18/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...                           \n",
       "1  [[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...                           \n",
       "2  [[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...                           \n",
       "3  [[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...                           \n",
       "4  [[73.63, 69.18, 33.7, 15.11, 5.75, 2.97, 2.95,...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_18/width_16k/canonical-token_feature_ids  \\\n",
       "0  [77, 7228, 16359, 9584, 8081, 5949, 9584, 1179...                               \n",
       "1  [77, 7228, 16359, 9584, 8081, 5949, 9584, 1179...                               \n",
       "2  [77, 7228, 16359, 6192, 2406, 8193, 11819, 619...                               \n",
       "3  [77, 7228, 16359, 9584, 8081, 5949, 9584, 1179...                               \n",
       "4  [77, 7228, 16359, 6192, 10631, 8081, 77, 7013,...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_19/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...                          \n",
       "1  [[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...                          \n",
       "2  [[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...                          \n",
       "3  [[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...                          \n",
       "4  [[9071, 3170, 11447, 5455, 314, 9041, 7105, 37...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_19/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...                           \n",
       "1  [[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...                           \n",
       "2  [[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...                           \n",
       "3  [[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...                           \n",
       "4  [[73.95, 54.55, 25.74, 11.56, 9.0, 7.69, 7.14,...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_19/width_16k/canonical-token_feature_ids  \\\n",
       "0  [9071, 3170, 11447, 11447, 670, 1828, 1125, 11...                               \n",
       "1  [9071, 3170, 11447, 11447, 670, 1828, 1125, 11...                               \n",
       "2  [9071, 3170, 11447, 11359, 988, 13414, 13231, ...                               \n",
       "3  [9071, 3170, 11447, 11447, 670, 1828, 1125, 11...                               \n",
       "4  [9071, 3170, 11447, 5866, 9380, 1883, 11447, 1...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_20/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[8468, 14729, 12522, 13882, 7302, 15247, 1488...                          \n",
       "1  [[8468, 14729, 12522, 13882, 7302, 15247, 1488...                          \n",
       "2  [[8468, 14729, 12522, 13882, 7302, 15247, 1488...                          \n",
       "3  [[8468, 14729, 12522, 13882, 7302, 15247, 1488...                          \n",
       "4  [[8468, 14729, 12522, 13882, 7302, 15247, 1488...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_20/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....                           \n",
       "1  [[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....                           \n",
       "2  [[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....                           \n",
       "3  [[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....                           \n",
       "4  [[83.09, 51.35, 27.63, 19.2, 12.67, 12.13, 10....                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_20/width_16k/canonical-token_feature_ids  \\\n",
       "0  [8468, 14729, 12522, 13882, 13143, 5910, 13882...                               \n",
       "1  [8468, 14729, 12522, 13882, 13143, 5910, 13882...                               \n",
       "2  [8468, 14729, 12522, 12449, 5494, 2795, 3701, ...                               \n",
       "3  [8468, 14729, 12522, 13882, 13143, 5910, 13882...                               \n",
       "4  [8468, 14729, 12522, 13882, 11522, 12449, 8821...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_21/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[10730, 13775, 6168, 13924, 1222, 14050, 1107...                          \n",
       "1  [[10730, 13775, 6168, 13924, 1222, 14050, 1107...                          \n",
       "2  [[10730, 13775, 6168, 13924, 1222, 14050, 1107...                          \n",
       "3  [[10730, 13775, 6168, 13924, 1222, 14050, 1107...                          \n",
       "4  [[10730, 13775, 6168, 13924, 1222, 14050, 1107...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_21/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...                           \n",
       "1  [[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...                           \n",
       "2  [[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...                           \n",
       "3  [[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...                           \n",
       "4  [[115.7, 19.4, 15.43, 12.01, 10.93, 10.79, 9.7...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_21/width_16k/canonical-token_feature_ids  \\\n",
       "0  [10730, 13775, 6168, 13966, 15701, 13509, 1247...                               \n",
       "1  [10730, 13775, 6168, 13966, 15701, 13509, 1247...                               \n",
       "2  [10730, 13775, 6168, 6921, 6694, 14050, 8762, ...                               \n",
       "3  [10730, 13775, 6168, 13966, 15701, 13509, 1247...                               \n",
       "4  [10730, 13775, 6168, 6354, 3777, 14050, 9864, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_22/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...                          \n",
       "1  [[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...                          \n",
       "2  [[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...                          \n",
       "3  [[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...                          \n",
       "4  [[4723, 2531, 12567, 5040, 14090, 5479, 2834, ...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_22/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...                           \n",
       "1  [[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...                           \n",
       "2  [[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...                           \n",
       "3  [[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...                           \n",
       "4  [[87.11, 86.32, 69.38, 44.28, 16.5, 15.0, 9.76...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_22/width_16k/canonical-token_feature_ids  \\\n",
       "0  [4723, 2531, 12567, 11983, 8563, 9228, 2232, 6...                               \n",
       "1  [4723, 2531, 12567, 11983, 8563, 9228, 2232, 6...                               \n",
       "2  [4723, 2531, 12567, 15916, 11406, 4029, 12899,...                               \n",
       "3  [4723, 2531, 12567, 11983, 8563, 9228, 2232, 6...                               \n",
       "4  [4723, 2531, 12567, 15113, 2978, 15793, 4723, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "1  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "2  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "3  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "4  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "1  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "2  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "3  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "4  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-token_feature_ids  \\\n",
       "0  [3567, 14957, 0, 8390, 10184, 15497, 8390, 101...                               \n",
       "1  [3567, 14957, 0, 8390, 10184, 15497, 8390, 101...                               \n",
       "2  [3567, 14957, 0, 4957, 14957, 3567, 10184, 517...                               \n",
       "3  [3567, 14957, 0, 8390, 10184, 15497, 8390, 101...                               \n",
       "4  [3567, 14957, 0, 10184, 15365, 15497, 10184, 8...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "1  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "2  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "3  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "4  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "1  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "2  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "3  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "4  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-token_feature_ids  \\\n",
       "0  [16058, 282, 102, 282, 9329, 6134, 9243, 4368,...                               \n",
       "1  [16058, 282, 102, 282, 9329, 6134, 9243, 4368,...                               \n",
       "2  [16058, 282, 102, 1416, 282, 9243, 9243, 282, ...                               \n",
       "3  [16058, 282, 102, 282, 9329, 6134, 9243, 4368,...                               \n",
       "4  [16058, 282, 102, 282, 9329, 6115, 9329, 282, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "1  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "2  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "3  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "4  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "1  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "2  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "3  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "4  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-token_feature_ids  \n",
       "0  [15890, 12642, 10593, 8171, 8262, 8420, 6608, ...                              \n",
       "1  [15890, 12642, 10593, 8171, 8262, 8420, 6608, ...                              \n",
       "2  [15890, 12642, 10593, 15048, 6608, 7327, 15890...                              \n",
       "3  [15890, 12642, 10593, 8171, 8262, 8420, 6608, ...                              \n",
       "4  [15890, 12642, 10593, 4589, 8171, 13264, 8242,...                              "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ! df.dropna(inplace=True)    # for analysis and vis keep all  \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f281dff-d7ff-4d45-9750-8248c6d9a748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "programming            5000\n",
      "math                   4998\n",
      "empathetic_dialogue    4992\n",
      "mmlu                   4984\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "counts = df['type'].value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc611109-912d-4aa6-b504-d8f56acd528d",
   "metadata": {},
   "source": [
    "# Dot product within class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388d6b22-b524-40fd-8b8b-72ac058a951a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create freq of vectors [0, 0, 0, .., 0]\n",
    "VECTOR_SIZE_SAE = 16384\n",
    "def to_vector(specialized_df, col_name, binary_vector=False):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        specialized_df: pandas df \n",
    "        col_name: col name with its layer and type \n",
    "    output:\n",
    "        vector of size 16500\n",
    "            max neuron 16383\n",
    "    \"\"\"\n",
    "    shared_neurons = [0] * VECTOR_SIZE_SAE\n",
    "    for row_list_str in specialized_df[col_name]:      # TODO: optimize with counter\n",
    "        # skip missing entries\n",
    "        if pd.isna(row_list_str):\n",
    "            continue\n",
    "        neuron_list = ast.literal_eval(row_list_str)\n",
    "        for neuron in neuron_list:\n",
    "            if binary_vector:\n",
    "                shared_neurons[neuron] = 1\n",
    "            else:\n",
    "                shared_neurons[neuron] += 1\n",
    "            \n",
    "    return shared_neurons\n",
    "    \n",
    "# to_vector(df, \"gemma-scope-2b-pt-res-canonical-layer0-token_feature_ids\")\n",
    "# first_list = ast.literal_eval(df[\"gemma-scope-2b-pt-res-canonical-layer0-token_feature_ids\"].iloc[0] )  # now a Python list of ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40695392-ccdd-4252-80a0-36efc51253a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def get_element_wise_product(typ, layer, class1, class2, vec1, vec2, top_n=10):\n",
    "    \"\"\"\n",
    "    Identifies neurons that contribute most significantly to the dot product\n",
    "    between two frequency vectors.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    typ : str\n",
    "        A label for the type of comparison.\n",
    "    layer : int or str\n",
    "        Layer identifier.\n",
    "    class1 : str\n",
    "        Name of the first class.\n",
    "    class2 : str\n",
    "        Name of the second class.\n",
    "    vec1, vec2 : list, np.array, or str\n",
    "        The two frequency vectors (or their literal strings).\n",
    "    top_n : int\n",
    "        Number of top neurons to return.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Columns = ['type', 'layer', 'class1', 'class2', 'Neuron_ID', 'Contribution']\n",
    "        Sorted by descending Contribution, up to top_n rows.\n",
    "    \"\"\"\n",
    "    # to numpy arrays\n",
    "    v1 = np.array(vec1, dtype=float)\n",
    "    v2 = np.array(vec2, dtype=float)\n",
    "\n",
    "    # element-wise contributions\n",
    "    contrib = v1 * v2\n",
    "\n",
    "    # build full DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'type':       typ,\n",
    "        'layer':      layer,\n",
    "        'class1':     class1,\n",
    "        'class2':     class2,\n",
    "        'Neuron_ID':  np.arange(contrib.shape[0]),\n",
    "        'Contribution': contrib\n",
    "    })\n",
    "\n",
    "    # keep only positive contributions\n",
    "    df = df[df['Contribution'] > 0]\n",
    "\n",
    "    # ensure all columns present even if empty\n",
    "    return df.reindex(columns=[\n",
    "        'type', 'layer', 'class1', 'class2', 'Neuron_ID', 'Contribution'\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f4b382f-c295-4d0d-8554-1ca6b4dcd0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['empathetic_dialogue', 'math', 'mmlu', 'programming']\n"
     ]
    }
   ],
   "source": [
    "# DATASET_TYPES = {\n",
    "#     \"empathetic_dialogue\": df.loc[df[\"type\"] == \"empathetic_dialogue\", \"category\"].unique(),\n",
    "#     \"math\":                df.loc[df[\"type\"] == \"math\",                \"category\"].unique(),\n",
    "#     \"mmlu\":                df.loc[df[\"type\"] == \"mmlu\",                \"category\"].unique(),\n",
    "#     \"programming\":         df.loc[df[\"type\"] == \"programming\",         \"category\"].unique(),\n",
    "# }\n",
    "\n",
    "\n",
    "DATASET_TYPES = [\n",
    "                \"empathetic_dialogue\", \n",
    "                \"math\", \n",
    "                \"mmlu\", \n",
    "                \"programming\"\n",
    "                ]\n",
    "\n",
    "print(DATASET_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7695ac50-9cb7-4210-a7cb-6955ef1623cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All skills are present in df['category'].\n"
     ]
    }
   ],
   "source": [
    "# skills = [\"jurisprudence\", \"professional_law\", \"international_law\", \"us_foreign_policy\", \"security_studies\"]\n",
    "skills = [\"philosophy\", \"moral_disputes\", \"moral_scenarios\", \"world_religions\"]\n",
    "\n",
    "# Which skills actually appear in df['category']?\n",
    "present = set(df['category'].unique())\n",
    "missing = [s for s in skills if s not in present]\n",
    "\n",
    "if not missing:\n",
    "    print(\" All skills are present in df['category'].\")\n",
    "else:\n",
    "    print(\" Missing skills:\", missing)\n",
    "\n",
    "# df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a8d276-72b4-4faf-bd89-cb2dea20314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# --- your settings ---\n",
    "dataset = \"mmlu\"\n",
    "# skills = [\n",
    "#     \"afraid\", \"angry\", \"annoyed\", \"anxious\", \"ashamed\", \n",
    "#     \"devastated\", \"disappointed\", \"disgusted\", \"embarrassed\", \n",
    "#     \"furious\", \"guilty\", \"jealous\", \"lonely\", \"sad\", \"terrified\"\n",
    "# ]\n",
    "\n",
    "# skills = [\"caring\", \"confident\", \"content\", \"excited\", \"faithful\", \"grateful\", \"hopeful\", \"impressed\", \"joyful\", \"prepared\", \"proud\", \"surprised\", \"trusting\"]\n",
    "# skills = [\"jurisprudence\", \"professional_law\", \"international_law\", \"us_foreign_policy\", \"security_studies\"]\n",
    "skills = [\"philosophy\", \"moral_disputes\", \"moral_scenarios\", \"world_religions\"]\n",
    "\n",
    "TYPES = [\"res\", \"mlp\", \"att\"]\n",
    "LAYERS = list(range(26))\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# --- main loops ---\n",
    "for typ in TYPES:\n",
    "    for layer in LAYERS:\n",
    "        col = (\n",
    "            f\"gemma-scope-2b-pt-{typ}-canonical-layer_{layer}\"\n",
    "            \"/width_16k/canonical-token_feature_ids\"\n",
    "        )\n",
    "\n",
    "        # for every unordered pair of skills\n",
    "        for skill1, skill2 in itertools.combinations(skills, 2):\n",
    "            # 1. filter each skills rows\n",
    "            df1 = df[\n",
    "                (df[\"type\"] == dataset) &\n",
    "                (df[\"category\"] == skill1)\n",
    "            ]\n",
    "            df2 = df[\n",
    "                (df[\"type\"] == dataset) &\n",
    "                (df[\"category\"] == skill2)\n",
    "            ]\n",
    "\n",
    "            # 2. turn into vectors\n",
    "            vec1 = to_vector(df1, col, binary_vector=False)\n",
    "            vec2 = to_vector(df2, col, binary_vector=False)\n",
    "\n",
    "            # 3. compute elementwise product\n",
    "            contribution_df = get_element_wise_product(\n",
    "                typ, layer,\n",
    "                skill1, skill2,\n",
    "                vec1, vec2\n",
    "            )\n",
    "\n",
    "            # 4. collect nonempty results\n",
    "            if not contribution_df.empty:\n",
    "                results_list.append(contribution_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "433eb66b-0d8d-4ac8-9866-e05779bd9574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res 0\n",
      "res 1\n",
      "res 2\n",
      "res 3\n",
      "res 4\n",
      "res 5\n",
      "res 6\n",
      "res 7\n",
      "res 8\n",
      "res 9\n",
      "res 10\n",
      "res 11\n",
      "res 12\n",
      "res 13\n",
      "res 14\n",
      "res 15\n",
      "res 16\n",
      "res 17\n",
      "res 18\n",
      "res 19\n",
      "res 20\n",
      "res 21\n",
      "res 22\n",
      "res 23\n",
      "res 24\n",
      "res 25\n",
      "mlp 0\n",
      "mlp 1\n",
      "mlp 2\n",
      "mlp 3\n",
      "mlp 4\n",
      "mlp 5\n",
      "mlp 6\n",
      "mlp 7\n",
      "mlp 8\n",
      "mlp 9\n",
      "mlp 10\n",
      "mlp 11\n",
      "mlp 12\n",
      "mlp 13\n",
      "mlp 14\n",
      "mlp 15\n",
      "mlp 16\n",
      "mlp 17\n",
      "mlp 18\n",
      "mlp 19\n",
      "mlp 20\n",
      "mlp 21\n",
      "mlp 22\n",
      "mlp 23\n",
      "mlp 24\n",
      "mlp 25\n",
      "att 0\n",
      "att 1\n",
      "att 2\n",
      "att 3\n",
      "att 4\n",
      "att 5\n",
      "att 6\n",
      "att 7\n",
      "att 8\n",
      "att 9\n",
      "att 10\n",
      "att 11\n",
      "att 12\n",
      "att 13\n",
      "att 14\n",
      "att 15\n",
      "att 16\n",
      "att 17\n",
      "att 18\n",
      "att 19\n",
      "att 20\n",
      "att 21\n",
      "att 22\n",
      "att 23\n",
      "att 24\n",
      "att 25\n"
     ]
    }
   ],
   "source": [
    "# # 2 SKILLS \n",
    "\n",
    "# # DATASET_NAMES = [\"emotion\", \"math\", \"mmlu\", \"programming\"]\n",
    "# import itertools\n",
    "# import pandas as pd \n",
    "# # for type/ layer  \n",
    "# # c1 \n",
    "# # c2 \n",
    "\n",
    "# TYPE = [\n",
    "#         \"res\", \n",
    "#         \"mlp\", \n",
    "#         \"att\",\n",
    "#        ]\n",
    "# LAYER = [i for i in range(26)]\n",
    "# results_list = []\n",
    "\n",
    "# # your params\n",
    "# class1, skill1 = \"empathetic_dialogue\", \"sad\"\n",
    "# class2, skill2 = \"empathetic_dialogue\", \"anxious\"\n",
    "# # class1 = \"empathetic_dialogue\"\n",
    "# # skills = [\"afraid\", \"angry\", \"annoyed\", \"anxious\", \"ashamed\", \"devastated\", \"disappointed\", \"disgusted\", \"embarrassed\", \"furious\", \"guilty\", \"jealous\", \"lonely\", \"sad\", \"terrified\"]\n",
    "\n",
    "# for typ in TYPE:\n",
    "#     for layer in LAYER:\n",
    "#         # between class\n",
    "#         # for class1, class2 in itertools.combinations(skills, 2):\n",
    "#             # for class1 in DATASET_TYPES:\n",
    "#             #     for class2 in DATASET_TYPES:\n",
    "#             #         if class1 < class2:\n",
    "#             #             continue\n",
    "#         col = f\"gemma-scope-2b-pt-{typ}-canonical-layer_{layer}/width_16k/canonical-token_feature_ids\"\n",
    "        \n",
    "#         # 1. get df \n",
    "#         class1_filtered = df[\n",
    "#             (df['type'] == class1) &\n",
    "#             (df['category'] == skill1)\n",
    "#         ]\n",
    "        \n",
    "#         class2_filtered = df[\n",
    "#             (df['type'] == class2) &\n",
    "#             (df['category'] == skill2)\n",
    "#         ]\n",
    "        \n",
    "#         # 2. to vector\n",
    "#         vec_class1 = to_vector(class1_filtered, col, binary_vector=False)\n",
    "#         vec_class2 = to_vector(class2_filtered, col, binary_vector=False)\n",
    "\n",
    "#         print(typ, layer)\n",
    "\n",
    "#         # return df : type layer class1 class2 contrib\n",
    "#         # df += get_element_wise_product(typ, layer, class1, class2, vec_class1, vec_class2)\n",
    "\n",
    "#         # 3. Calculate the element-wise product and get the results as a DataFrame\n",
    "#         contribution_df = get_element_wise_product(typ, layer, skill1, skill2, vec_class1, vec_class2)\n",
    "        \n",
    "#         # 4. Append the resulting DataFrame to our list\n",
    "#         if not contribution_df.empty:\n",
    "#             results_list.append(contribution_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e7a90a-97e0-47fd-8e31-18baaee8e832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hard' 'easy' 'external' 'harder' 'hardest' 'medium' 'codeforces']\n"
     ]
    }
   ],
   "source": [
    "class1 = \"programming\"\n",
    "skills = df[\"category\"].unique()\n",
    "print(skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11243f28-bc89-43a3-9936-6d3ce245cafb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Type:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Layer:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
      "Layer:   4%|         | 1/26 [01:33<38:57, 93.50s/it]\u001b[A\n",
      "Layer:   8%|         | 2/26 [03:12<38:35, 96.48s/it]\u001b[A\n",
      "Layer:  12%|        | 3/26 [04:48<36:59, 96.52s/it]\u001b[A\n",
      "Layer:  15%|        | 4/26 [06:22<35:01, 95.53s/it]\u001b[A\n",
      "Layer:  19%|        | 5/26 [07:56<33:11, 94.84s/it]\u001b[A\n",
      "Layer:  23%|       | 6/26 [09:30<31:30, 94.54s/it]\u001b[A\n",
      "Layer:  27%|       | 7/26 [11:08<30:21, 95.88s/it]\u001b[A\n",
      "Layer:  31%|       | 8/26 [12:45<28:52, 96.27s/it]\u001b[A\n",
      "Layer:  35%|      | 9/26 [14:20<27:08, 95.80s/it]\u001b[A\n",
      "Layer:  38%|      | 10/26 [15:55<25:27, 95.49s/it]\u001b[A\n",
      "Layer:  42%|     | 11/26 [17:30<23:50, 95.36s/it]\u001b[A\n",
      "Layer:  46%|     | 12/26 [19:05<22:14, 95.29s/it]\u001b[A\n",
      "Layer:  50%|     | 13/26 [20:41<20:40, 95.41s/it]\u001b[A\n",
      "Layer:  54%|    | 14/26 [22:18<19:09, 95.79s/it]\u001b[A\n",
      "Layer:  58%|    | 15/26 [23:54<17:35, 95.98s/it]\u001b[A\n",
      "Layer:  62%|   | 16/26 [25:29<15:57, 95.72s/it]\u001b[A\n",
      "Layer:  65%|   | 17/26 [27:04<14:19, 95.52s/it]\u001b[A\n",
      "Layer:  69%|   | 18/26 [28:39<12:41, 95.22s/it]\u001b[A\n",
      "Layer:  73%|  | 19/26 [30:14<11:06, 95.18s/it]\u001b[A\n",
      "Layer:  77%|  | 20/26 [31:48<09:29, 94.96s/it]\u001b[A\n",
      "Layer:  81%|  | 21/26 [33:22<07:53, 94.70s/it]\u001b[A\n",
      "Layer:  85%| | 22/26 [34:57<06:18, 94.70s/it]\u001b[A\n",
      "Layer:  88%| | 23/26 [36:33<04:45, 95.21s/it]\u001b[A\n",
      "Layer:  92%|| 24/26 [38:09<03:10, 95.44s/it]\u001b[A\n",
      "Layer:  96%|| 25/26 [39:44<01:35, 95.29s/it]\u001b[A\n",
      "Layer: 100%|| 26/26 [41:19<00:00, 94.96s/it]\u001b[A\n",
      "Type:  33%|      | 1/3 [41:19<1:22:38, 2479.03s/it][A\n",
      "Layer:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
      "Layer:   4%|         | 1/26 [01:34<39:34, 94.99s/it]\u001b[A\n",
      "Layer:   8%|         | 2/26 [03:11<38:15, 95.66s/it]\u001b[A\n",
      "Layer:  12%|        | 3/26 [04:46<36:37, 95.56s/it]\u001b[A\n",
      "Layer:  15%|        | 4/26 [06:21<34:54, 95.19s/it]\u001b[A\n",
      "Layer:  19%|        | 5/26 [07:55<33:11, 94.82s/it]\u001b[A\n",
      "Layer:  23%|       | 6/26 [09:30<31:36, 94.80s/it]\u001b[A\n",
      "Layer:  27%|       | 7/26 [11:05<30:05, 95.05s/it]\u001b[A\n",
      "Layer:  31%|       | 8/26 [12:41<28:35, 95.31s/it]\u001b[A\n",
      "Layer:  35%|      | 9/26 [14:16<26:56, 95.10s/it]\u001b[A\n",
      "Layer:  38%|      | 10/26 [15:50<25:19, 94.97s/it]\u001b[A\n",
      "Layer:  42%|     | 11/26 [17:25<23:43, 94.93s/it]\u001b[A\n",
      "Layer:  46%|     | 12/26 [19:00<22:08, 94.91s/it]\u001b[A\n",
      "Layer:  50%|     | 13/26 [20:35<20:34, 94.95s/it]\u001b[A\n",
      "Layer:  54%|    | 14/26 [22:12<19:06, 95.51s/it]\u001b[A\n",
      "Layer:  58%|    | 15/26 [23:48<17:33, 95.74s/it]\u001b[A\n",
      "Layer:  62%|   | 16/26 [25:24<15:57, 95.71s/it]\u001b[A\n",
      "Layer:  65%|   | 17/26 [26:59<14:20, 95.59s/it]\u001b[A\n",
      "Layer:  69%|   | 18/26 [28:34<12:44, 95.52s/it]\u001b[A\n",
      "Layer:  73%|  | 19/26 [30:10<11:07, 95.43s/it]\u001b[A\n",
      "Layer:  77%|  | 20/26 [31:45<09:32, 95.49s/it]\u001b[A\n",
      "Layer:  81%|  | 21/26 [33:21<07:58, 95.64s/it]\u001b[A\n",
      "Layer:  85%| | 22/26 [34:57<06:22, 95.63s/it]\u001b[A\n",
      "Layer:  88%| | 23/26 [36:33<04:47, 95.89s/it]\u001b[A\n",
      "Layer:  92%|| 24/26 [38:11<03:12, 96.35s/it]\u001b[A\n",
      "Layer:  96%|| 25/26 [39:46<01:36, 96.03s/it]\u001b[A\n",
      "Layer: 100%|| 26/26 [41:21<00:00, 95.79s/it]\u001b[A\n",
      "Type:  67%|   | 2/3 [1:22:40<41:20, 2480.70s/it][A\n",
      "Layer:   0%|          | 0/26 [00:00<?, ?it/s]\u001b[A\n",
      "Layer:   4%|         | 1/26 [01:35<39:47, 95.49s/it]\u001b[A\n",
      "Layer:   8%|         | 2/26 [03:10<38:08, 95.35s/it]\u001b[A\n",
      "Layer:  12%|        | 3/26 [04:46<36:40, 95.68s/it]\u001b[A\n",
      "Layer:  15%|        | 4/26 [06:22<35:02, 95.55s/it]\u001b[A\n",
      "Layer:  19%|        | 5/26 [07:58<33:35, 95.98s/it]\u001b[A\n",
      "Layer:  23%|       | 6/26 [09:35<32:06, 96.31s/it]\u001b[A\n",
      "Layer:  27%|       | 7/26 [11:11<30:26, 96.11s/it]\u001b[A\n",
      "Layer:  31%|       | 8/26 [12:46<28:45, 95.85s/it]\u001b[A\n",
      "Layer:  35%|      | 9/26 [14:21<27:04, 95.55s/it]\u001b[A\n",
      "Layer:  38%|      | 10/26 [15:56<25:25, 95.33s/it]\u001b[A\n",
      "Layer:  42%|     | 11/26 [17:31<23:48, 95.21s/it]\u001b[A\n",
      "Layer:  46%|     | 12/26 [19:05<22:09, 94.97s/it]\u001b[A\n",
      "Layer:  50%|     | 13/26 [20:40<20:33, 94.86s/it]\u001b[A\n",
      "Layer:  54%|    | 14/26 [22:15<18:57, 94.80s/it]\u001b[A\n",
      "Layer:  58%|    | 15/26 [23:51<17:27, 95.20s/it]\u001b[A\n",
      "Layer:  62%|   | 16/26 [25:26<15:51, 95.13s/it]\u001b[A\n",
      "Layer:  65%|   | 17/26 [27:00<14:13, 94.83s/it]\u001b[A\n",
      "Layer:  69%|   | 18/26 [28:34<12:36, 94.61s/it]\u001b[A\n",
      "Layer:  73%|  | 19/26 [30:08<11:01, 94.48s/it]\u001b[A\n",
      "Layer:  77%|  | 20/26 [31:43<09:26, 94.47s/it]\u001b[A\n",
      "Layer:  81%|  | 21/26 [33:17<07:51, 94.36s/it]\u001b[A\n",
      "Layer:  85%| | 22/26 [34:52<06:19, 94.76s/it]\u001b[A\n",
      "Layer:  88%| | 23/26 [36:28<04:44, 94.96s/it]\u001b[A\n",
      "Layer:  92%|| 24/26 [38:02<03:09, 94.70s/it]\u001b[A\n",
      "Layer:  96%|| 25/26 [39:36<01:34, 94.65s/it]\u001b[A\n",
      "Layer: 100%|| 26/26 [41:11<00:00, 94.50s/it]\u001b[A\n",
      "Type: 100%|| 3/3 [2:03:52<00:00, 2477.36s/it][A\n"
     ]
    }
   ],
   "source": [
    "# FOR MANY CLASSES BETWEEN CLASS\n",
    "\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# --- your settings ---\n",
    "TYPES = [\"res\", \"mlp\", \"att\"]\n",
    "LAYERS = list(range(26))\n",
    "\n",
    "results_list = []\n",
    "\n",
    "# for typ in TYPES:\n",
    "for typ in tqdm(TYPES, desc=\"Type\"):\n",
    "    # Wrap the LAYERS loop, leave=False so it doesnt linger when done\n",
    "    # for layer in LAYERS:\n",
    "    for layer in tqdm(LAYERS, desc=\"Layer\", leave=False):\n",
    "        col = (\n",
    "            f\"gemma-scope-2b-pt-{typ}-canonical-\"\n",
    "            f\"layer_{layer}/width_16k/canonical-token_feature_ids\"\n",
    "        )\n",
    "\n",
    "        for skill1, skill2 in itertools.combinations(skills, 2):\n",
    "            # 1. filter for each skill within the same class\n",
    "            df1 = df[\n",
    "                (df[\"type\"] == class1) &\n",
    "                (df[\"category\"] == skill1)\n",
    "            ]\n",
    "            df2 = df[\n",
    "                (df[\"type\"] == class1) &\n",
    "                (df[\"category\"] == skill2)\n",
    "            ]\n",
    "\n",
    "            # 2. turn each into a vector\n",
    "            vec1 = to_vector(df1, col, binary_vector=False)\n",
    "            vec2 = to_vector(df2, col, binary_vector=False)\n",
    "\n",
    "            # 3. get elementwise contributions\n",
    "            contrib_df = get_element_wise_product(\n",
    "                typ, layer, skill1, skill2, vec1, vec2\n",
    "            )\n",
    "            if contrib_df is None or contrib_df.empty:\n",
    "                continue\n",
    "            results_list.append(contrib_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8732b8b-2308-4a08-8670-52523d252dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVE DATASET =======================================================\n",
      "Successfully saved all neuron contributions to './datasets/dot_product/philosophy_and_ethics.csv'\n",
      "\n",
      "Final DataFrame head:\n",
      "  type  layer          class1           class2  Neuron_ID  Contribution\n",
      "0  mlp     24  moral_disputes  moral_scenarios        282    10771296.0\n",
      "1  mlp     24  moral_disputes  moral_scenarios       9329    10638350.0\n",
      "2  att     12  moral_disputes  moral_scenarios       2424     9586056.0\n",
      "3  mlp      7  moral_disputes  moral_scenarios       6117     9477090.0\n",
      "4  att      5  moral_disputes  moral_scenarios       9670     9419795.0\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all the individual result DataFrames into one large DataFrame\n",
    "print(\"SAVE DATASET =======================================================\")\n",
    "final_df = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "final_df = (\n",
    "    final_df\n",
    "    .sort_values('Contribution', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Save the final DataFrame to a CSV file\n",
    "# path = f\"./datasets/{skill1}_vs_{skill2}.csv\"\n",
    "# path = f\"./datasets/dot_product/{class1}_between_class.csv\"\n",
    "# path = f\"./datasets/dot_product/law_and_policy.csv\"\n",
    "path = f\"./datasets/dot_product/philosophy_and_ethics.csv\"\n",
    "final_df.to_csv(path, index=False)\n",
    "\n",
    "print(f\"Successfully saved all neuron contributions to '{path}'\")\n",
    "print(\"\\nFinal DataFrame head:\")\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8f9dae-acb9-4f9d-acb0-00ddc9d36cd8",
   "metadata": {},
   "source": [
    "# Remove duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71032fb4-3656-48e4-9795-40c0072deb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE DUPLICATES \n",
    "# path = f\"./datasets/dot_product/{class1}_between_class.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .sort_values(\"Contribution\", ascending=False)  # largestsmallest\n",
    "    .drop_duplicates(\n",
    "        subset=[\"type\", \"layer\", \"Neuron_ID\"],\n",
    "        keep=\"first\"                               # now keeps the *largest* Contribution\n",
    "    )\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# path = f\"./datasets/dot_product/{class1}_between_class_clean.csv\"\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b3ecbc-8b57-4eed-8741-1d735bcfeb5a",
   "metadata": {},
   "source": [
    "# Percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a3a0e8-0b9e-4872-acb7-2715786b76f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>layer</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>282</td>\n",
       "      <td>12699340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>att</td>\n",
       "      <td>22</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>14953</td>\n",
       "      <td>12099597.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>att</td>\n",
       "      <td>12</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>2424</td>\n",
       "      <td>10867400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>9329</td>\n",
       "      <td>10860906.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>att</td>\n",
       "      <td>7</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>10364</td>\n",
       "      <td>10214085.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type  layer       class1       class2  Neuron_ID  Contribution\n",
       "0  mlp     24   devastated  embarrassed        282    12699340.0\n",
       "1  att     22   devastated  embarrassed      14953    12099597.0\n",
       "2  att     12   devastated  embarrassed       2424    10867400.0\n",
       "3  mlp     24  embarrassed      furious       9329    10860906.0\n",
       "4  att      7      ashamed  embarrassed      10364    10214085.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = \"./scratch/content_vs_hopeful.csv\"\n",
    "# path = f\"./datasets/{skill1}_vs_{skill2}.csv\"\n",
    "# path = f\"./datasets/negative_feelings.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd2d1b1a-c4fc-4410-ba73-f32a6cbebc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Percentage  Data point  Contribution\n",
      "0         0.01        6390    10494080.0\n",
      "1         0.05       31952      372186.0\n",
      "2         0.10       63905       67980.0\n",
      "3         0.12       76686       40984.0\n",
      "4         0.15       95857       21660.0\n",
      "5         0.18      115029       12464.0\n",
      "6         0.20      127810        8892.0\n",
      "7         0.30      191715        2200.0\n",
      "8         0.40      255620         700.0\n",
      "9         0.50      319526         252.0\n",
      "10        0.60      383431          95.0\n",
      "11        0.70      447336          35.0\n",
      "12        0.80      511241          12.0\n",
      "13        0.90      575146           4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_X_contribution(p):\n",
    "    \"\"\"\n",
    "    Returns (idx, contribution) at percentile p through the DESC-sorted list.\n",
    "    p should be between 0 and 1.\n",
    "    \"\"\"\n",
    "    N = df.shape[0]\n",
    "    idx = int(p * (N - 1))\n",
    "    return idx, df.iloc[idx][\"Contribution\"]\n",
    "\n",
    "topK = [0.01, 0.05 , 0.10, 0.12, 0.15, 0.18, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90]\n",
    "\n",
    "idx_list = []\n",
    "percentage_list = []\n",
    "contrib_list = []\n",
    "\n",
    "for p in topK:\n",
    "    idx, contrib = get_X_contribution(p)\n",
    "    percentage_list.append(p)\n",
    "    idx_list.append(idx)\n",
    "    contrib_list.append(contrib)\n",
    "\n",
    "# now build a DataFrame\n",
    "pct_df = pd.DataFrame({\n",
    "    \"Percentage\": percentage_list,\n",
    "    \"Data point\":    idx_list,\n",
    "    \"Contribution\": contrib_list\n",
    "})\n",
    "\n",
    "print(pct_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289c0546-8442-4f16-bc5f-c23e3ea276c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = f\"./datasets/dot_product/positive_felings.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "# compute how many rows = 15%\n",
    "# n = int(0.15 * len(df))\n",
    "\n",
    "# take the first n rows\n",
    "# top15pct = df.iloc[:n]\n",
    "# print(f\"Taking {n} rows out of {len(df)} total  {len(df)} rows\")\n",
    "top15pct = df.iloc[:50000]\n",
    "\n",
    "print(top15pct.head())\n",
    "print(top15pct.shape)\n",
    "\n",
    "path = f\"./datasets/dot_product/positive_felings.csv\"\n",
    "top15pct.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a9e3d7-40ad-4bfc-bb08-456c503a9c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  type  layer        class1    class2  Neuron_ID  Contribution\n",
      "0  mlp     24  apprehensive  trusting        282    15015042.0\n",
      "1  att     22  apprehensive  trusting      14953    13710207.0\n",
      "2  mlp     24  apprehensive  trusting       9329    12911080.0\n",
      "3  att     12  apprehensive  trusting       2424    12815097.0\n",
      "4  att      7  apprehensive  trusting      10364    11636983.0\n",
      "(50000, 6)\n",
      "  type  layer       class1      class2  Neuron_ID  Contribution\n",
      "0  mlp      7  precalculus    geometry       6117  4.830805e+09\n",
      "1  mlp     24  precalculus    geometry       9329  4.825307e+09\n",
      "2  mlp     23  precalculus    geometry      10184  4.382280e+09\n",
      "3  res      1  precalculus    geometry      12054  3.802484e+09\n",
      "4  att      4     geometry  prealgebra       4742  3.458361e+09\n",
      "(50000, 6)\n",
      "  type  layer                        class1                     class2  \\\n",
      "0  mlp      7  high_school_european_history  high_school_world_history   \n",
      "1  mlp     23  high_school_european_history  high_school_world_history   \n",
      "2  mlp     24  high_school_european_history  high_school_world_history   \n",
      "3  mlp     24  high_school_european_history  high_school_world_history   \n",
      "4  res      1  high_school_european_history  high_school_world_history   \n",
      "\n",
      "   Neuron_ID  Contribution  \n",
      "0       6117   652151696.0  \n",
      "1      10184   598321647.0  \n",
      "2        282   516972456.0  \n",
      "3       9329   507061800.0  \n",
      "4      12054   433595304.0  \n",
      "(50000, 6)\n",
      "  type  layer    class1      class2  Neuron_ID  Contribution\n",
      "0  mlp      7  external  codeforces       6117  6.946736e+11\n",
      "1  mlp     23  external  codeforces      10184  6.392421e+11\n",
      "2  mlp     24  external  codeforces       9329  6.118761e+11\n",
      "3  res      1  external  codeforces      12054  5.498718e+11\n",
      "4  mlp      4  external  codeforces       2793  4.683499e+11\n",
      "(50000, 6)\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# classes = [\"empathetic_dialogue\", \"math\", \"mmlu\", \"programming\"]\n",
    "\n",
    "# for cls in classes:\n",
    "#     path = f\"./datasets/dot_product/{cls}_between_class_clean.csv\"\n",
    "\n",
    "#     df = pd.read_csv(path)\n",
    "#     # compute how many rows = 15%\n",
    "#     # n = int(0.15 * len(df))\n",
    "    \n",
    "#     # take the first n rows\n",
    "#     # top15pct = df.iloc[:n]\n",
    "#     # print(f\"Taking {n} rows out of {len(df)} total  {len(df)} rows\")\n",
    "#     top15pct = df.iloc[:50000]\n",
    "    \n",
    "#     print(top15pct.head())\n",
    "#     print(top15pct.shape)\n",
    "    \n",
    "#     path = f\"./datasets/dot_product/{cls}_between_class_clean_topk.csv\"\n",
    "#     top15pct.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6287f70-27a0-4f8a-a3af-3591494eeef6",
   "metadata": {},
   "source": [
    "# Auto interpert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07d5817-3aea-4053-a5c2-37ef91d21976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>layer</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>7</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>6117</td>\n",
       "      <td>6.946736e+11</td>\n",
       "      <td>topics related to nutrition and health measur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp</td>\n",
       "      <td>23</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>10184</td>\n",
       "      <td>6.392421e+11</td>\n",
       "      <td>mathematical or analytical expressions related...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>9329</td>\n",
       "      <td>6.118761e+11</td>\n",
       "      <td>legal terms and phrases related to court case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res</td>\n",
       "      <td>1</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>12054</td>\n",
       "      <td>5.498718e+11</td>\n",
       "      <td>content related to medical conditions and trea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>4</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>2793</td>\n",
       "      <td>4.683499e+11</td>\n",
       "      <td>terms related to legal and regulatory document...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>282</td>\n",
       "      <td>4.611576e+11</td>\n",
       "      <td>hyperlinks and web addresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>att</td>\n",
       "      <td>4</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>4742</td>\n",
       "      <td>4.099533e+11</td>\n",
       "      <td>attends to specific keywords marked with doub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlp</td>\n",
       "      <td>4</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>14164</td>\n",
       "      <td>3.239907e+11</td>\n",
       "      <td>structured programming elements and documentat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mlp</td>\n",
       "      <td>25</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>10593</td>\n",
       "      <td>2.584844e+11</td>\n",
       "      <td>references to personal experiences and societ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>res</td>\n",
       "      <td>25</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>13749</td>\n",
       "      <td>2.384867e+11</td>\n",
       "      <td>specific references to medical and clinical tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>res</td>\n",
       "      <td>4</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>6680</td>\n",
       "      <td>2.102960e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mlp</td>\n",
       "      <td>8</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>8286</td>\n",
       "      <td>1.750500e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>att</td>\n",
       "      <td>8</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>8535</td>\n",
       "      <td>1.515542e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>att</td>\n",
       "      <td>22</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>3192</td>\n",
       "      <td>1.508630e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>att</td>\n",
       "      <td>20</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>4118</td>\n",
       "      <td>1.491435e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>att</td>\n",
       "      <td>9</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>13240</td>\n",
       "      <td>1.469209e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mlp</td>\n",
       "      <td>11</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>4397</td>\n",
       "      <td>1.465267e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>att</td>\n",
       "      <td>10</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>13576</td>\n",
       "      <td>1.439727e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>mlp</td>\n",
       "      <td>0</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>13955</td>\n",
       "      <td>1.396190e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>mlp</td>\n",
       "      <td>25</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>6608</td>\n",
       "      <td>1.300314e+11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  layer    class1      class2  Neuron_ID  Contribution  \\\n",
       "0   mlp      7  external  codeforces       6117  6.946736e+11   \n",
       "1   mlp     23  external  codeforces      10184  6.392421e+11   \n",
       "2   mlp     24  external  codeforces       9329  6.118761e+11   \n",
       "3   res      1  external  codeforces      12054  5.498718e+11   \n",
       "4   mlp      4  external  codeforces       2793  4.683499e+11   \n",
       "5   mlp     24  external  codeforces        282  4.611576e+11   \n",
       "6   att      4  external  codeforces       4742  4.099533e+11   \n",
       "7   mlp      4  external  codeforces      14164  3.239907e+11   \n",
       "8   mlp     25  external  codeforces      10593  2.584844e+11   \n",
       "9   res     25  external  codeforces      13749  2.384867e+11   \n",
       "10  res      4  external  codeforces       6680  2.102960e+11   \n",
       "11  mlp      8  external  codeforces       8286  1.750500e+11   \n",
       "12  att      8  external  codeforces       8535  1.515542e+11   \n",
       "13  att     22  external  codeforces       3192  1.508630e+11   \n",
       "14  att     20  external  codeforces       4118  1.491435e+11   \n",
       "15  att      9  external  codeforces      13240  1.469209e+11   \n",
       "16  mlp     11  external  codeforces       4397  1.465267e+11   \n",
       "17  att     10  external  codeforces      13576  1.439727e+11   \n",
       "18  mlp      0  external  codeforces      13955  1.396190e+11   \n",
       "19  mlp     25  external  codeforces       6608  1.300314e+11   \n",
       "\n",
       "                                          Explanation  \n",
       "0    topics related to nutrition and health measur...  \n",
       "1   mathematical or analytical expressions related...  \n",
       "2    legal terms and phrases related to court case...  \n",
       "3   content related to medical conditions and trea...  \n",
       "4   terms related to legal and regulatory document...  \n",
       "5                        hyperlinks and web addresses  \n",
       "6    attends to specific keywords marked with doub...  \n",
       "7   structured programming elements and documentat...  \n",
       "8    references to personal experiences and societ...  \n",
       "9   specific references to medical and clinical tr...  \n",
       "10                                                NaN  \n",
       "11                                                NaN  \n",
       "12                                                NaN  \n",
       "13                                                NaN  \n",
       "14                                                NaN  \n",
       "15                                                NaN  \n",
       "16                                                NaN  \n",
       "17                                                NaN  \n",
       "18                                                NaN  \n",
       "19                                                NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# path = \"./datasets/negative_feelings.csv\"\n",
    "classes = [\"empathetic_dialogue\", \"math\", \"mmlu\", \"programming\"]\n",
    "path = f\"./datasets/dot_product/{classes[0]}_between_class_clean_topk.csv\"\n",
    "df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aabaa0e-fb6d-43c6-91c9-2e15ef3af207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_feature(model_id, source, index):\n",
    "    try:\n",
    "        url = f\"https://www.neuronpedia.org/api/feature/{model_id}/{source}/{index}\"\n",
    "        resp = requests.get(url)\n",
    "        resp.raise_for_status()            # throws if not 200\n",
    "        feature = resp.json()\n",
    "        \n",
    "        # 2. Grab the list of explanations (might be empty!)\n",
    "        explanations = feature.get(\"explanations\", [])\n",
    "        \n",
    "        # 3. first description:\n",
    "        # if explanations:\n",
    "        return explanations[0][\"description\"]\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ddd6b-6ca3-4b96-a603-4327556f10df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec5129640754b2991f91db21daeb06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching features:   0%|          | 0/24700 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = \"gemma-2-2b\"\n",
    "explanations = []\n",
    "df[\"Explanation\"] = None\n",
    "\n",
    "\n",
    "# for idx, row in df.head(24700).iterrows():\n",
    "# for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Fetching features\"):\n",
    "for idx, row in tqdm(df.head(24700).iterrows(), total=min(24700, len(df)), desc=\"Fetching features\"):\n",
    "    sae_type  = row[\"type\"]\n",
    "    layer     = row[\"layer\"]\n",
    "    neuron_id = row[\"Neuron_ID\"]\n",
    "    source    = f\"{layer}-gemmascope-{sae_type}-16k\"\n",
    "\n",
    "    feat = get_feature(model, source, neuron_id)\n",
    "    df.at[idx, \"Explanation\"] = feat\n",
    "    # explanations.append(feat)\n",
    "\n",
    "# df[\"Explanation\"] = explanations\n",
    "df.to_csv(path, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de50853-70eb-4551-885f-dd82c02f4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sad sad \n",
    "sad anxious \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2db6d9-7bde-41e2-9fc4-a364a3163454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Async fetching: 100%|| 25000/25000 [00:12<00:00, 2008.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "model = \"gemma-2-2b\"\n",
    "if \"Explanation\" not in df.columns:\n",
    "    df[\"Explanation\"] = None\n",
    "\n",
    "chunk = df.iloc[0:25000]\n",
    "\n",
    "# --- Define async API call ---\n",
    "async def fetch_feature(session, idx, row):\n",
    "    sae_type = row[\"type\"]\n",
    "    layer = row[\"layer\"]\n",
    "    neuron_id = row[\"Neuron_ID\"]\n",
    "    explanation = row[\"Explanation\"]\n",
    "    if pd.notna(explanation):\n",
    "        return idx, explanation\n",
    "    source = f\"{layer}-gemmascope-{sae_type}-16k\"\n",
    "    url = f\"https://www.neuronpedia.org/api/feature/{model}/{source}/{neuron_id}\"\n",
    "\n",
    "    try:\n",
    "        async with session.get(url, timeout=10) as resp:\n",
    "            data = await resp.json()\n",
    "            explanations = data.get(\"explanations\", [])\n",
    "            return idx, explanations[0][\"description\"] if explanations else None\n",
    "    except Exception as e:\n",
    "        return idx, None\n",
    "\n",
    "# --- Async executor ---\n",
    "async def run():\n",
    "    connector = aiohttp.TCPConnector(limit=1)  # Controls concurrency level\n",
    "    timeout = aiohttp.ClientTimeout(total=10)\n",
    "    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:\n",
    "        tasks = [fetch_feature(session, idx, row) for idx, row in chunk.iterrows()]\n",
    "        results = []\n",
    "        for f in tqdm.as_completed(tasks, total=len(tasks), desc=\"Async fetching\"):\n",
    "            result = await f\n",
    "            results.append(result)\n",
    "        return results\n",
    "\n",
    "# --- Run & apply results ---\n",
    "results = await run()\n",
    "for idx, explanation in results:\n",
    "    df.at[idx, \"Explanation\"] = explanation\n",
    "\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55461964-abcb-4daf-9c69-b285a01d43e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>layer</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>att</td>\n",
       "      <td>21</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>8769</td>\n",
       "      <td>68010708.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>res</td>\n",
       "      <td>21</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>11346</td>\n",
       "      <td>67939326.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>res</td>\n",
       "      <td>0</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>2896</td>\n",
       "      <td>67936050.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>res</td>\n",
       "      <td>18</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>11250</td>\n",
       "      <td>67930604.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>att</td>\n",
       "      <td>1</td>\n",
       "      <td>external</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>2935</td>\n",
       "      <td>67895360.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  layer    class1      class2  Neuron_ID  Contribution Explanation\n",
       "2495  att     21  external  codeforces       8769    68010708.0        None\n",
       "2496  res     21  external  codeforces      11346    67939326.0        None\n",
       "2497  res      0  external  codeforces       2896    67936050.0        None\n",
       "2498  res     18  external  codeforces      11250    67930604.0        None\n",
       "2499  att      1  external  codeforces       2935    67895360.0        None"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2495:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859d5cb0-3f99-40a2-9b86-26f550f784d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
