{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d7e862c-98ac-4d3d-8ed4-f513bda97f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-openai\n",
    "# !pip install -U langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa490a0-df09-46e2-b24d-93028e2978b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>layer</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>282</td>\n",
       "      <td>9656475.0</td>\n",
       "      <td>hyperlinks and web addresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>att</td>\n",
       "      <td>22</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>14953</td>\n",
       "      <td>9325212.0</td>\n",
       "      <td>attends to specific significant tokens from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>9329</td>\n",
       "      <td>8175526.0</td>\n",
       "      <td>legal terms and phrases related to court case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>att</td>\n",
       "      <td>12</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>2424</td>\n",
       "      <td>7996512.0</td>\n",
       "      <td>attends from tokens denoting an action or con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>att</td>\n",
       "      <td>7</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>10364</td>\n",
       "      <td>7670500.0</td>\n",
       "      <td>attends to instances of the token followed by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type  layer               class1               class2  Neuron_ID  \\\n",
       "0  mlp     24  empathetic_dialogue  empathetic_dialogue        282   \n",
       "1  att     22  empathetic_dialogue  empathetic_dialogue      14953   \n",
       "2  mlp     24  empathetic_dialogue  empathetic_dialogue       9329   \n",
       "3  att     12  empathetic_dialogue  empathetic_dialogue       2424   \n",
       "4  att      7  empathetic_dialogue  empathetic_dialogue      10364   \n",
       "\n",
       "   Contribution                                        Explanation  \n",
       "0     9656475.0                       hyperlinks and web addresses  \n",
       "1     9325212.0   attends to specific significant tokens from s...  \n",
       "2     8175526.0   legal terms and phrases related to court case...  \n",
       "3     7996512.0   attends from tokens denoting an action or con...  \n",
       "4     7670500.0   attends to instances of the token followed by...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import csv\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "path = \"./datasets/afraid_vs_terrified.csv\"\n",
    "df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56222684-1c11-47cb-80f1-98ccf3693aaf",
   "metadata": {},
   "source": [
    "# Auto Interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca9a514-7bae-4a99-828b-beb7b9df33a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_feature(model_id, source, index):\n",
    "    try:\n",
    "        url = f\"https://www.neuronpedia.org/api/feature/{model_id}/{source}/{index}\"\n",
    "        resp = requests.get(url)\n",
    "        resp.raise_for_status()            # throws if not 200\n",
    "        feature = resp.json()\n",
    "        \n",
    "        # 2. Grab the list of explanations (might be empty!)\n",
    "        explanations = feature.get(\"explanations\", [])\n",
    "        \n",
    "        # 3. first description:\n",
    "        # if explanations:\n",
    "        return explanations[0][\"description\"]\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    \n",
    "for i in range(10):\n",
    "    model = \"gemma-2-2b\"\n",
    "    layer = 21\n",
    "    sae_type = \"mlp\"\n",
    "    source = f\"{layer}-gemmascope-{sae_type}-16k\"\n",
    "    feat = get_feature(model, source, i)\n",
    "    print(feat)\n",
    "\n",
    "\n",
    "\n",
    "model = \"gemma-2-2b\"\n",
    "\n",
    "explanations = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    sae_type = df[\"type\"]\n",
    "    layer = df[\"layer\"]\n",
    "    neuron_id = df[\"Neuron_ID\"]\n",
    "    source = f\"{layer}-gemmascope-{sae_type}-16k\"\n",
    "\n",
    "    feat = get_feature(model, source, neuron_id)\n",
    "    explanations.append(feat)\n",
    "\n",
    "df[\"Explanation\"] = explanations\n",
    "df.to_csv(path, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df5404-2843-486e-9db8-9b45b3235bb4",
   "metadata": {},
   "source": [
    "# Get sentences of a type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8529021e-ddc7-4408-8d06-f9b5a78c80e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>prompt</th>\n",
       "      <th>category</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-res-canonical-layer_2/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>...</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_22/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-token_feature_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-top_mean_ids</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-top_mean_vals</th>\n",
       "      <th>gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-token_feature_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>When I was a child I was in a tornado.</td>\n",
       "      <td>afraid</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 4194, 3706, 2296, 9570, 1...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 11522, 7322, 12054, 6999, ...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>...</td>\n",
       "      <td>[4723, 2531, 12567, 4723, 16067, 9940, 5002, 7...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 10184, 15497, 7466, 15196, 10...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 282, 9329, 10304, 282, 11515...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 4589, 13264, 8171, 4589,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>One time i heard someone outside my window.</td>\n",
       "      <td>afraid</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 9869, 2082, 2366, 15045, ...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 5343, 11492, 6631, 15045, ...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>...</td>\n",
       "      <td>[4723, 2531, 12567, 9666, 14947, 11983, 4723, ...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 15497, 10184, 7025, 15497, 23...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 282, 9329, 9807, 282, 9329, ...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 4589, 13264, 8171, 13264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>I keep hearing things in my kitchen. I think t...</td>\n",
       "      <td>afraid</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 9528, 12207, 8920, 9286, ...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 7318, 12054, 592, 4581, 53...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>...</td>\n",
       "      <td>[4723, 2531, 12567, 4029, 4723, 752, 11958, 32...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 14433, 16031, 10184, 10955, 9...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 282, 9063, 9329, 282, 9329, ...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 4589, 13266, 3848, 13264...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>I am cooking dinner for my boyfriend tomorrow ...</td>\n",
       "      <td>afraid</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 9528, 12207, 8920, 2221, ...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 7318, 12054, 592, 2653, 44...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>...</td>\n",
       "      <td>[4723, 2531, 12567, 4029, 4723, 752, 2094, 131...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 14433, 16031, 10184, 7687, 61...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 282, 9063, 9329, 282, 9329, ...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 4589, 13266, 3848, 4589,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>empathetic_dialogue</td>\n",
       "      <td>of dying</td>\n",
       "      <td>afraid</td>\n",
       "      <td>[[8920, 12838, 12950, 275, 15454, 10006, 1381,...</td>\n",
       "      <td>[[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...</td>\n",
       "      <td>[8920, 12838, 12950, 4725, 14733, 8920, 8920, ...</td>\n",
       "      <td>[[9770, 5146, 12054, 740, 13412, 10589, 12539,...</td>\n",
       "      <td>[[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...</td>\n",
       "      <td>[9770, 5146, 12054, 2915, 1892, 14600, 12054, ...</td>\n",
       "      <td>[[15089, 14059, 7132, 7361, 4885, 13977, 11527...</td>\n",
       "      <td>...</td>\n",
       "      <td>[4723, 2531, 12567, 15315, 74, 11983, 6307, 28...</td>\n",
       "      <td>[[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...</td>\n",
       "      <td>[[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...</td>\n",
       "      <td>[3567, 14957, 0, 10184, 15497, 15423, 10184, 1...</td>\n",
       "      <td>[[16058, 282, 102, 9478, 9835, 10304, 9243, 39...</td>\n",
       "      <td>[[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...</td>\n",
       "      <td>[16058, 282, 102, 9329, 282, 6437, 282, 9329, ...</td>\n",
       "      <td>[[15890, 12642, 10593, 8735, 6608, 11319, 1124...</td>\n",
       "      <td>[[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...</td>\n",
       "      <td>[15890, 12642, 10593, 10593, 8171, 8420, 13264...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 237 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  type                                             prompt  \\\n",
       "0  empathetic_dialogue             When I was a child I was in a tornado.   \n",
       "1  empathetic_dialogue       One time i heard someone outside my window.    \n",
       "2  empathetic_dialogue  I keep hearing things in my kitchen. I think t...   \n",
       "3  empathetic_dialogue  I am cooking dinner for my boyfriend tomorrow ...   \n",
       "4  empathetic_dialogue                                          of dying    \n",
       "\n",
       "  category  \\\n",
       "0   afraid   \n",
       "1   afraid   \n",
       "2   afraid   \n",
       "3   afraid   \n",
       "4   afraid   \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "1  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "2  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "3  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "4  [[8920, 12838, 12950, 275, 15454, 10006, 1381,...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "1  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "2  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "3  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "4  [[296.67, 121.99, 110.25, 41.58, 32.32, 27.85,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_0/width_16k/canonical-token_feature_ids  \\\n",
       "0  [8920, 12838, 12950, 4194, 3706, 2296, 9570, 1...                              \n",
       "1  [8920, 12838, 12950, 9869, 2082, 2366, 15045, ...                              \n",
       "2  [8920, 12838, 12950, 9528, 12207, 8920, 9286, ...                              \n",
       "3  [8920, 12838, 12950, 9528, 12207, 8920, 2221, ...                              \n",
       "4  [8920, 12838, 12950, 4725, 14733, 8920, 8920, ...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "1  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "2  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "3  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "4  [[9770, 5146, 12054, 740, 13412, 10589, 12539,...                         \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "1  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "2  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "3  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "4  [[371.29, 249.65, 216.23, 81.72, 76.63, 69.86,...                          \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_1/width_16k/canonical-token_feature_ids  \\\n",
       "0  [9770, 5146, 12054, 11522, 7322, 12054, 6999, ...                              \n",
       "1  [9770, 5146, 12054, 5343, 11492, 6631, 15045, ...                              \n",
       "2  [9770, 5146, 12054, 7318, 12054, 592, 4581, 53...                              \n",
       "3  [9770, 5146, 12054, 7318, 12054, 592, 2653, 44...                              \n",
       "4  [9770, 5146, 12054, 2915, 1892, 14600, 12054, ...                              \n",
       "\n",
       "  gemma-scope-2b-pt-res-canonical-layer_2/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "1  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "2  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "3  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "4  [[15089, 14059, 7132, 7361, 4885, 13977, 11527...                         \n",
       "\n",
       "   ...  \\\n",
       "0  ...   \n",
       "1  ...   \n",
       "2  ...   \n",
       "3  ...   \n",
       "4  ...   \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_22/width_16k/canonical-token_feature_ids  \\\n",
       "0  [4723, 2531, 12567, 4723, 16067, 9940, 5002, 7...                               \n",
       "1  [4723, 2531, 12567, 9666, 14947, 11983, 4723, ...                               \n",
       "2  [4723, 2531, 12567, 4029, 4723, 752, 11958, 32...                               \n",
       "3  [4723, 2531, 12567, 4029, 4723, 752, 2094, 131...                               \n",
       "4  [4723, 2531, 12567, 15315, 74, 11983, 6307, 28...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "1  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "2  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "3  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "4  [[3567, 14957, 0, 5805, 11472, 1000, 10184, 14...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "1  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "2  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "3  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "4  [[139.31, 70.22, 68.3, 59.77, 45.67, 33.31, 32...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_23/width_16k/canonical-token_feature_ids  \\\n",
       "0  [3567, 14957, 0, 10184, 15497, 7466, 15196, 10...                               \n",
       "1  [3567, 14957, 0, 15497, 10184, 7025, 15497, 23...                               \n",
       "2  [3567, 14957, 0, 14433, 16031, 10184, 10955, 9...                               \n",
       "3  [3567, 14957, 0, 14433, 16031, 10184, 7687, 61...                               \n",
       "4  [3567, 14957, 0, 10184, 15497, 15423, 10184, 1...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "1  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "2  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "3  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "4  [[16058, 282, 102, 9478, 9835, 10304, 9243, 39...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "1  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "2  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "3  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "4  [[306.12, 240.2, 73.45, 48.24, 40.77, 39.54, 3...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_24/width_16k/canonical-token_feature_ids  \\\n",
       "0  [16058, 282, 102, 282, 9329, 10304, 282, 11515...                               \n",
       "1  [16058, 282, 102, 282, 9329, 9807, 282, 9329, ...                               \n",
       "2  [16058, 282, 102, 282, 9063, 9329, 282, 9329, ...                               \n",
       "3  [16058, 282, 102, 282, 9063, 9329, 282, 9329, ...                               \n",
       "4  [16058, 282, 102, 9329, 282, 6437, 282, 9329, ...                               \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-top_mean_ids  \\\n",
       "0  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "1  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "2  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "3  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "4  [[15890, 12642, 10593, 8735, 6608, 11319, 1124...                          \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-top_mean_vals  \\\n",
       "0  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "1  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "2  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "3  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "4  [[203.72, 73.83, 46.11, 36.68, 34.49, 32.86, 2...                           \n",
       "\n",
       "  gemma-scope-2b-pt-mlp-canonical-layer_25/width_16k/canonical-token_feature_ids  \n",
       "0  [15890, 12642, 10593, 4589, 13264, 8171, 4589,...                              \n",
       "1  [15890, 12642, 10593, 4589, 13264, 8171, 13264...                              \n",
       "2  [15890, 12642, 10593, 4589, 13266, 3848, 13264...                              \n",
       "3  [15890, 12642, 10593, 4589, 13266, 3848, 4589,...                              \n",
       "4  [15890, 12642, 10593, 10593, 8171, 8420, 13264...                              \n",
       "\n",
       "[5 rows x 237 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"./datasets/emotion_processed.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6ac3dd2-27ca-4d0b-a4b4-e26d7c16a9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I felt sad the other day when my best friend left. She visited for several days and I got used to her being here, but then she left and I miss her.\n",
      "\n",
      "I recently changed jobs for a better opportunity with more pay. I'm very pleased with the new job, but I did feel bummed about leaving my former co-workers behind. We had a good time and I liked those kids.\n",
      "\n",
      "My cat died yesterday.\n",
      "\n",
      "I left my phone on the bus last night as I was coming home, I am still very upset,\n",
      "\n",
      "I was very depressed and upset when my partner left, we've been together for years and I feel like my time has been wasted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hopeful = df[df[\"category\"] == \"sad\"] \n",
    "# for idx, row in df_hopeful.head().iterrows():\n",
    "for idx, row in df_hopeful.sample(5).iterrows():\n",
    "    print(row[\"prompt\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a91ee75-9766-4fc1-be66-f6eb9639456f",
   "metadata": {},
   "source": [
    "// HOPING\n",
    "\n",
    "I'm waiting to hear back from my doctor about my test results.\n",
    "\n",
    "I am praying that I get the part\n",
    "\n",
    "I meeting with my boss tommorrow. I really am praying for a raise!\n",
    "\n",
    "I started my new job yesterday. Hoping for a promotion soon.\n",
    "\n",
    "My wife and I just put in a bid for a new house last weekend.  I pray we get our offer accepted!\n",
    "\n",
    "// CONTENT\n",
    "\n",
    "I had a great two weeks with work. I made enough to even get a few things I wanted and to save up! I love it when those things happen.\n",
    "\n",
    "It's friday. I'm going to go home and grill a steak and have a beer.\n",
    "\n",
    "It was a very busy week for me, but now that the weekend is here I'm looking forward to relaxing and watching some good movies.\n",
    "\n",
    "I am feeling this way now in my life. I am so happy.\n",
    "\n",
    "I went to Krispy Kreme the other day and got some donuts while the hot light was on.\n",
    "\n",
    "// SAD\n",
    "\n",
    "I felt sad the other day when my best friend left. She visited for several days and I got used to her being here, but then she left and I miss her.\n",
    "\n",
    "I recently changed jobs for a better opportunity with more pay. I'm very pleased with the new job, but I did feel bummed about leaving my former co-workers behind. We had a good time and I liked those kids.\n",
    "\n",
    "My cat died yesterday.\n",
    "\n",
    "I left my phone on the bus last night as I was coming home, I am still very upset,\n",
    "\n",
    "I was very depressed and upset when my partner left, we've been together for years and I feel like my time has been wasted.\n",
    "\n",
    "// "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fb64e8-abaf-4e8e-9f19-e8d7fa8a35ad",
   "metadata": {},
   "source": [
    "# LLM few shot prompting \n",
    "Evaluate if the explanation is relevant or not based on 2 skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e6d932-8a98-4c01-a899-e16332ef0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Azure credentials\n",
    "AZURE_OPENAI_ENDPOINT = \"https://vbm-resource.cognitiveservices.azure.com/\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = \"o4-mini\"\n",
    "AZURE_OPENAI_API_VERSION = \"2024-12-01-preview\"\n",
    "AZURE_OPENAI_API_KEY = \"4LdHqRgKwivk2hoYayfbFNzQt9HWR6cqYqlWYI4xMDfCNdaE3b5mJQQJ99BGACfhMk5XJ3w3AAAAACOGiEst\"\n",
    "\n",
    "# Set env var for LangChain to use\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "\n",
    "# Backgrounds\n",
    "DATASET_BACKGROUND = {\n",
    "    \"mmlu\": \"The MMLU dataset is designed to evaluate the general knowledge and reasoning abilities...\",\n",
    "    \"empathetic_dialogue\": \"The empathetic_dialogue dataset consists of open-domain conversations...\",\n",
    "    \"math\": \"The Math dataset assesses the mathematical reasoning capabilities...\",\n",
    "    \"programming\": \"The Programming dataset is used to evaluate a language model’s ability...\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0602c0-c10a-4d7f-87a1-e5e525769975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_response(response_content: str, print_output: bool = False) -> dict:\n",
    "    # print(response_content)\n",
    "    try:\n",
    "        # Remove Markdown-style code fences (```json ... ```)\n",
    "        cleaned = response_content.strip()\n",
    "        if cleaned.startswith(\"```json\"):\n",
    "            cleaned = cleaned[7:]  # remove the initial ```json\n",
    "        if cleaned.startswith(\"```\"):\n",
    "            cleaned = cleaned[3:]  # fallback if only triple backticks\n",
    "        if cleaned.endswith(\"```\"):\n",
    "            cleaned = cleaned[:-3]\n",
    "        cleaned = cleaned.strip()\n",
    "        \n",
    "        data = json.loads(cleaned)\n",
    "        if print_output:\n",
    "            print(f\"Rationale: {data.get('rationale')}\")\n",
    "            print(f\"decision_on_both: {data.get('decision_on_both')}\")\n",
    "            print(f\"decision_on_one: {data.get('decision_on_one')}\")\n",
    "        return data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON Decode Error:\", e)\n",
    "        print(\"Raw response:\", response_content)\n",
    "        return {}\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "def parse_llm_response(response):\n",
    "    # Extract string from response.content\n",
    "    raw_content = response.content.strip()\n",
    "\n",
    "    # Remove triple backticks and possible \"json\" label\n",
    "    if raw_content.startswith(\"```json\"):\n",
    "        raw_content = raw_content[7:]  # remove ```json\\n\n",
    "    if raw_content.endswith(\"```\"):\n",
    "        raw_content = raw_content[:-3]  # remove trailing ```\n",
    "\n",
    "    # Clean whitespace and load as JSON\n",
    "    return json.loads(raw_content.strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0b2ae28-e3be-493a-b9d5-c51cd69ecd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1774395/1879615065.py:4: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import AzureChatOpenAI``.\n",
      "  llm = AzureChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "# Initialize the LLM\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    openai_api_version=AZURE_OPENAI_API_VERSION,\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "def get_answer(skill_name: str, skill_examples: str, QUESTION: str, print_output: bool = False):\n",
    "\n",
    "\n",
    "    # System prompt with escaped braces for JSON formatting\n",
    "    system_template = f\"\"\"\n",
    "    SYSTEM:\n",
    "        You are an evaluator agent analyzing neuron activations on Sparse Autoencoders. You will receive an explanation from an Auto-Interpretability system. Your task is to judge whether the explanation expresses **negative emotion or negative sentiment**.\n",
    "        \n",
    "        Negative emotional concepts include any of these specific feelings:\n",
    "        afraid, angry, annoyed, anxious, apprehensive, ashamed, devastated, disappointed, disgusted, embarrassed, furious, guilty, jealous, lonely, sad, terrified.\n",
    "        \n",
    "        It also includes any general references to negative sentiment, negative feelings, distress, negativity, or emotional conflict/responses.\n",
    "        \n",
    "        INSTRUCTIONS:\n",
    "        1. Think step-by-step, identifying any cues of negative emotion or sentiment.\n",
    "        2. If there is any uncertainty, choose `\"no\"`.\n",
    "        3. **Output only** the following JSON (no extra text, no explanation outside your rationale field)\n",
    "\n",
    "    Provide your reasoning and final decision in this exact JSON format:\n",
    "    \n",
    "    ```json\n",
    "    {{\n",
    "      \"rationale\": \"Your step-by-step reasoning goes here.\",\n",
    "      \"decision\": \"yes|no\"\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    # User message prompt\n",
    "    user_prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"\n",
    "        Question:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    user_message = user_prompt.format(question=QUESTION)\n",
    "\n",
    "    # LLM call\n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_template.strip()},\n",
    "        {\"role\": \"user\", \"content\": user_message.strip()}\n",
    "    ])\n",
    "    return parse_llm_response(response)\n",
    "    # return parse_json_response(response.content, print_output=print_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69971fdb-4be3-4b6b-b1c6-3741abad032f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No text exposition provided to evaluate for fear or anxiety. Without any content expressing negative emotion, the decision is no.\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "skill_name = \"terrified\"\n",
    "skill_examples = \"\"\"\n",
    "        * Emotional expressions \n",
    "        * Mentions words or concepts tied to emotional states of fear, anxiety, panic, afraid or stress.\n",
    "        * Describes reactions or content commonly associated with being terrified (e.g., phrases evoking danger, emotional distress, intense fear).\n",
    "        * Suggests personal or emotional responses aligned with fear or negativity.\n",
    "        * Terms that can result in a terrified state\n",
    "\"\"\"\n",
    "\n",
    "question = \"expressions of personal sentiment and emotional responses\"\n",
    "question = \"I am so scared of that happening\"\n",
    "question = \"elements related to conflict and action\"\n",
    "# question = \"expressions of uncertainty and emotional reactions\"\n",
    "# question = \"negations and expressions implying uncertainty or disagreement\"\n",
    "# question = \"intensifiers related to feelings or emotions\"\n",
    "# question = \"expressions of emotional states and interpersonal connections\"\n",
    "# question = \"expressions of strong emotions or feelings\"\n",
    "# question = \"expressions of love and enjoyment of outdoor activities\"\n",
    "# question = \"emotions and introspective thoughts related to intense experiences\"\n",
    "# question = \"references to family relationships and their emotional connections\"\n",
    "# question = \"emotional expressions and states\"\n",
    "# question = \"phrases that convey experiences of distress or psychological states\"\n",
    "# question = \"references to negative thoughts\"\n",
    "# question = \"negative emotional states or feelings associated with difficult situations\"\n",
    "# question = \"expressions of fear and anxiety\"\n",
    "# question = \"expressions and sentiments related to love and affection\"\n",
    "question = \"phrases indicating personal struggle or emotional conflict\"\n",
    "question = \"expressions of fear and anxiety\"\n",
    "\n",
    "output = get_answer(skill_name, skill_examples, question)\n",
    "print(output[\"rationale\"])\n",
    "print(output[\"decision\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fe249-4e2e-4d11-bc51-f3ba8c4b8d2b",
   "metadata": {},
   "source": [
    "# MAKE DECEISION LLM IF USEFUL OR NOT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ab68056-d5f2-45a5-8125-58a55548f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Assuming df is already loaded\n",
    "results = []\n",
    "llm_explanation = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"LLM EVAL\"):\n",
    "    explanation = row[\"Explanation\"]\n",
    "    try:\n",
    "        response = get_answer(\n",
    "            skill_name=skill_name,\n",
    "            skill_examples=skill_examples,\n",
    "            QUESTION=explanation,\n",
    "            print_output=False\n",
    "        )\n",
    "        # llm_explanation.append(response[\"rationale\"])\n",
    "        results.append(response[\"decision\"])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {idx}: {e}\")\n",
    "        results.append(\"No\")\n",
    "\n",
    "# Add results to DataFrame\n",
    "df[\"llm_decision\"] = results\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41e12a-eb07-4803-b30b-472565d2a754",
   "metadata": {},
   "source": [
    "## Parallel computing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d92852-9996-4a45-a63a-ccecb23e1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def parallel_llm_fetch(args):\n",
    "    \"\"\"Helper function for parallel LLM processing\"\"\"\n",
    "    idx, row, skill_name, skill_examples = args\n",
    "    explanation = row[\"Explanation\"]\n",
    "    \n",
    "    try:\n",
    "        response = get_answer(\n",
    "            skill_name=skill_name,\n",
    "            skill_examples=skill_examples,\n",
    "            QUESTION=explanation,\n",
    "            print_output=False\n",
    "        )\n",
    "        return idx, response[\"decision\"]\n",
    "    except Exception as e:\n",
    "        print(f\"Error at index {idx}: {e}\")\n",
    "        return idx, \"No\"\n",
    "\n",
    "def parallel_llm_evaluation(df, path, skill_name, skill_examples, max_workers=4):\n",
    "    \"\"\"Parallel LLM evaluation with skipping for existing decisions\"\"\"\n",
    "    \n",
    "    # Initialize the column if it doesn't exist\n",
    "    if \"llm_decision\" not in df.columns:\n",
    "        df[\"llm_decision\"] = None\n",
    "    \n",
    "    # SKIP ROWS THAT ALREADY HAVE LLM DECISIONS\n",
    "    rows_to_process = []\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Skip if llm_decision already exists and is not empty/None\n",
    "        if pd.notna(row.get(\"llm_decision\")) and row.get(\"llm_decision\") not in [\"\", None]:\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Also skip if no explanation to process\n",
    "        if pd.isna(row.get(\"Explanation\")) or row.get(\"Explanation\") == \"\":\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "            \n",
    "        rows_to_process.append((idx, row, skill_name, skill_examples))\n",
    "    \n",
    "    print(f\"Skipping {skipped_count} rows that already have LLM decisions or no explanations\")\n",
    "    print(f\"Processing {len(rows_to_process)} rows\")\n",
    "    \n",
    "    if not rows_to_process:\n",
    "        print(\"All rows already have LLM decisions!\")\n",
    "        return df\n",
    "    \n",
    "    # THE PARALLEL PROCESSING MAGIC:\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # 1. Submit all LLM tasks to the thread pool\n",
    "        future_to_idx = {executor.submit(parallel_llm_fetch, args): args[0] \n",
    "                        for args in rows_to_process}\n",
    "        \n",
    "        # 2. Process completed tasks as they finish\n",
    "        for future in tqdm(as_completed(future_to_idx), total=len(rows_to_process), desc=\"LLM EVAL\"):\n",
    "            idx = future_to_idx[future]\n",
    "            try:\n",
    "                result_idx, decision = future.result()\n",
    "                df.at[result_idx, \"llm_decision\"] = decision\n",
    "            except Exception as exc:\n",
    "                print(f'Row {idx} generated an exception: {exc}')\n",
    "                df.at[idx, \"llm_decision\"] = \"No\"\n",
    "    \n",
    "    # Save the results\n",
    "    df.to_csv(path, index=False)\n",
    "    return df\n",
    "\n",
    "# Usage example:\n",
    "# df = parallel_llm_evaluation(\n",
    "#     df=your_dataframe,\n",
    "#     path=\"your_output_path.csv\", \n",
    "#     skill_name=\"your_skill_name\",\n",
    "#     skill_examples=\"your_skill_examples\",\n",
    "#     max_workers=4  # Adjust based on your LLM API rate limits\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bccee3-ecee-4030-9def-e00f6811ca2a",
   "metadata": {},
   "source": [
    "afraid terrifeid \n",
    "sad sad "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e796b8a-2ce5-459b-a0da-3e04d064fa9e",
   "metadata": {},
   "source": [
    "# Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03c740df-6ad7-4d15-94be-ebe182dcdc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"./datasets/sad_vs_sad.csv\"\n",
    "df = pd.read_csv(path)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66f24c06-971d-41bb-a527-2bec9f93c43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96, 8)\n",
      "type\n",
      "res    96\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>layer</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>llm_decision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>res</td>\n",
       "      <td>15</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>13368</td>\n",
       "      <td>11664.0</td>\n",
       "      <td>elements related to internal strength and emot...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>res</td>\n",
       "      <td>12</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>11281</td>\n",
       "      <td>5625.0</td>\n",
       "      <td>expressions of disappointment and sadness</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>res</td>\n",
       "      <td>19</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>9009</td>\n",
       "      <td>5041.0</td>\n",
       "      <td>emotions related to dissatisfaction or frustra...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>res</td>\n",
       "      <td>6</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>4948</td>\n",
       "      <td>4356.0</td>\n",
       "      <td>expressions and sentiments related to sadness...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>res</td>\n",
       "      <td>24</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>10826</td>\n",
       "      <td>3721.0</td>\n",
       "      <td>references to animals and their behaviors rela...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>res</td>\n",
       "      <td>16</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>5769</td>\n",
       "      <td>3364.0</td>\n",
       "      <td>emotional expressions related to feelings of s...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>res</td>\n",
       "      <td>15</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>6469</td>\n",
       "      <td>3025.0</td>\n",
       "      <td>emotions tied to feelings of regret, shame, a...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>res</td>\n",
       "      <td>22</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>5218</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>phrases related to emotional distress and con...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>res</td>\n",
       "      <td>8</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>3813</td>\n",
       "      <td>2304.0</td>\n",
       "      <td>expressions of sadness and negative emotions</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>res</td>\n",
       "      <td>8</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>7865</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>emotions related to loss and longing</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>res</td>\n",
       "      <td>1</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>5746</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>expressions of emotional states typically asso...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>res</td>\n",
       "      <td>25</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>8942</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>emotions and reactions related to surprise, di...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>res</td>\n",
       "      <td>22</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>5523</td>\n",
       "      <td>1936.0</td>\n",
       "      <td>references to emotional or familial distress,...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>res</td>\n",
       "      <td>5</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>3940</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>expressions of grief and loss</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>res</td>\n",
       "      <td>9</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>3562</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>expressions of longing and grief</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>res</td>\n",
       "      <td>23</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>1502</td>\n",
       "      <td>1764.0</td>\n",
       "      <td>emotional responses and expressions of grief</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>res</td>\n",
       "      <td>10</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>9071</td>\n",
       "      <td>1444.0</td>\n",
       "      <td>expressions and descriptions of sadness or neg...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>res</td>\n",
       "      <td>13</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>5327</td>\n",
       "      <td>1225.0</td>\n",
       "      <td>expressions of emotional responses, particular...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>res</td>\n",
       "      <td>18</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>11186</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>emotional expressions related to loss and sadness</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2308</th>\n",
       "      <td>res</td>\n",
       "      <td>11</td>\n",
       "      <td>sad</td>\n",
       "      <td>sad</td>\n",
       "      <td>9840</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>expressions of sadness and disappointment</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  layer class1 class2  Neuron_ID  Contribution  \\\n",
       "814   res     15    sad    sad      13368       11664.0   \n",
       "1075  res     12    sad    sad      11281        5625.0   \n",
       "1132  res     19    sad    sad       9009        5041.0   \n",
       "1204  res      6    sad    sad       4948        4356.0   \n",
       "1302  res     24    sad    sad      10826        3721.0   \n",
       "1361  res     16    sad    sad       5769        3364.0   \n",
       "1399  res     15    sad    sad       6469        3025.0   \n",
       "1556  res     22    sad    sad       5218        2401.0   \n",
       "1583  res      8    sad    sad       3813        2304.0   \n",
       "1640  res      8    sad    sad       7865        2116.0   \n",
       "1652  res      1    sad    sad       5746        2116.0   \n",
       "1698  res     25    sad    sad       8942        2025.0   \n",
       "1729  res     22    sad    sad       5523        1936.0   \n",
       "1751  res      5    sad    sad       3940        1849.0   \n",
       "1772  res      9    sad    sad       3562        1764.0   \n",
       "1787  res     23    sad    sad       1502        1764.0   \n",
       "1926  res     10    sad    sad       9071        1444.0   \n",
       "2089  res     13    sad    sad       5327        1225.0   \n",
       "2281  res     18    sad    sad      11186        1024.0   \n",
       "2308  res     11    sad    sad       9840        1024.0   \n",
       "\n",
       "                                            Explanation llm_decision  \n",
       "814   elements related to internal strength and emot...          yes  \n",
       "1075          expressions of disappointment and sadness          yes  \n",
       "1132  emotions related to dissatisfaction or frustra...          yes  \n",
       "1204   expressions and sentiments related to sadness...          yes  \n",
       "1302  references to animals and their behaviors rela...          yes  \n",
       "1361  emotional expressions related to feelings of s...          yes  \n",
       "1399   emotions tied to feelings of regret, shame, a...          yes  \n",
       "1556   phrases related to emotional distress and con...          yes  \n",
       "1583       expressions of sadness and negative emotions          yes  \n",
       "1640               emotions related to loss and longing          yes  \n",
       "1652  expressions of emotional states typically asso...          yes  \n",
       "1698  emotions and reactions related to surprise, di...          yes  \n",
       "1729   references to emotional or familial distress,...          yes  \n",
       "1751                      expressions of grief and loss          yes  \n",
       "1772                   expressions of longing and grief          yes  \n",
       "1787       emotional responses and expressions of grief          yes  \n",
       "1926  expressions and descriptions of sadness or neg...          yes  \n",
       "2089  expressions of emotional responses, particular...          yes  \n",
       "2281  emotional expressions related to loss and sadness          yes  \n",
       "2308          expressions of sadness and disappointment          yes  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df[df[\"llm_decision\"] == \"yes\"]\n",
    "df = df[(df[\"llm_decision\"] == \"yes\") & (df[\"type\"] == \"res\")]\n",
    "print(df.shape)\n",
    "print(df[\"type\"].value_counts())\n",
    "df.head(20)\n",
    "# for idx, row in df.iterrows():\n",
    "#     print(row[\"Explanation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47740da-63cc-499c-af46-cf9ae792ce06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
