{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0bda651-75aa-4c8b-b1b6-b0320462734e",
   "metadata": {},
   "source": [
    "# ENV VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a54a3a-885c-4635-ac42-0d54b18d14ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/dot_product/negative_feelings_with_explanations.csv\n"
     ]
    }
   ],
   "source": [
    "DEPLOYMENT_NAME = 0\n",
    "\n",
    "DATASET_NAMES = [\n",
    "    \"negative_feelings\",\n",
    "    \"law_and_policy\",\n",
    "    \"positive_feelings\",\n",
    "    \"philosophy_and_ethics\"\n",
    "]\n",
    "\n",
    "PATH = f\"./datasets/dot_product/{DATASET_NAMES[DEPLOYMENT_NAME]}_with_explanations.csv\"\n",
    "# PATH = f\"./datasets/dot_product/{}.csv\"\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b79dd-ecbc-43ef-b8dd-4b139aebaad2",
   "metadata": {},
   "source": [
    "# INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d4dd7b-075d-44e1-bb6e-422caa2c3792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import csv\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95d1c02c-9b15-4dbf-b2dd-07ccd7241782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>layer</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Explanations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>282</td>\n",
       "      <td>12699340.0</td>\n",
       "      <td>hyperlinks and web addresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>att</td>\n",
       "      <td>22</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>14953</td>\n",
       "      <td>12099597.0</td>\n",
       "      <td>attends to specific significant tokens from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>att</td>\n",
       "      <td>12</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>2424</td>\n",
       "      <td>10867400.0</td>\n",
       "      <td>attends from tokens denoting an action or con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>9329</td>\n",
       "      <td>10860906.0</td>\n",
       "      <td>legal terms and phrases related to court case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>att</td>\n",
       "      <td>7</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>10364</td>\n",
       "      <td>10214085.0</td>\n",
       "      <td>attends to instances of the token followed by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type  layer       class1       class2  Neuron_ID  Contribution  \\\n",
       "0  mlp     24   devastated  embarrassed        282    12699340.0   \n",
       "1  att     22   devastated  embarrassed      14953    12099597.0   \n",
       "2  att     12   devastated  embarrassed       2424    10867400.0   \n",
       "3  mlp     24  embarrassed      furious       9329    10860906.0   \n",
       "4  att      7      ashamed  embarrassed      10364    10214085.0   \n",
       "\n",
       "                                        Explanations  \n",
       "0                       hyperlinks and web addresses  \n",
       "1   attends to specific significant tokens from s...  \n",
       "2   attends from tokens denoting an action or con...  \n",
       "3   legal terms and phrases related to court case...  \n",
       "4   attends to instances of the token followed by...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11534093-2e79-46e4-b74f-37739b276481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from collections import defaultdict\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Azure credentials\n",
    "AZURE_OPENAI_ENDPOINT = \"https://interp.cognitiveservices.azure.com/\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = \"o4-mini\"\n",
    "AZURE_OPENAI_API_VERSION = \"2024-12-01-preview\"\n",
    "AZURE_OPENAI_API_KEY = \"BD3IG7AY4XibX8JjlehI5aKSXNVwtvsBopVPMDuRaoMHEdYSgGe6JQQJ99BGACYeBjFXJ3w3AAAAACOGxocP\"\n",
    "\n",
    "deployment_names = [\n",
    "    \"o4-mini\",\n",
    "    \"o4-mini-2\",\n",
    "    \"o4-mini-3\",\n",
    "    \"o4-mini-4\",\n",
    "]\n",
    "\n",
    "# Set env var for LangChain to use\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "# Initialize the LLM\n",
    "# llm = AzureChatOpenAI(\n",
    "#     azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "#     azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "#     openai_api_version=AZURE_OPENAI_API_VERSION,\n",
    "#     temperature=1.0,\n",
    "#     model=deployment_names[DEPLOYMENT_NAME]\n",
    "# )\n",
    "# llm = make_llm(deployment_names[DEPLOYMENT_NAME])  # uses \"o4-mini-X\"\n",
    "client = AzureOpenAI(\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "\n",
    "# Backgrounds\n",
    "# Backgrounds\n",
    "DATASET_BACKGROUND = {\n",
    "    \"mmlu\": \"\"\"\n",
    "SYSTEM:\n",
    "  You are an evaluator agent analyzing skills for neuron activations on Sparse Autoencoders. You will receive an explanation from an Auto-Interpretability system. Your task is to judge whether the explanation expresses academic or professional domain knowledge.\n",
    "  These concepts include any of these specific topics: abstract algebra, anatomy, astronomy, business ethics, clinical knowledge, college biology, college chemistry, college computer science, college mathematics, college medicine, computer security, conceptual physics, econometrics, electrical engineering, elementary mathematics, formal logic, global facts, high school biology, high school chemistry, high school computer science, high school European history, high school geography, high school government and politics, high school macroeconomics, high school mathematics, high school microeconomics, high school physics, high school psychology, high school statistics, high school US history, high school world history, human aging, human sexuality, international law, jurisprudence, logical fallacies, machine learning, management, marketing, medical genetics, miscellaneous, moral disputes, moral scenarios, nutrition, philosophy, prehistory, professional accounting, professional law, professional medicine, professional psychology, public relations, security studies, sociology, US foreign policy, virology, world religions.\n",
    "  It also includes any general references to domain-specific facts, academic reasoning, professional terminology, or subject-matter expertise.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Think step-by-step, identifying any cues of code structure, algorithmic reasoning, or programming terminology.\n",
    "2. EXCLUDE any explanations that talk only about low-level token patterns, lexical tokens, or sequence-level formatting (e.g., “attends to verbs…”, “counts tokens…”, “looks at underscores…”). Those are not evidence of domain knowledge.\n",
    "3. If there is any uncertainty, choose “no”.\n",
    "4. Output only in JSON (no extra text, no explanation outside your rationale field).\n",
    "\n",
    "Provide your reasoning and final decision in this exact JSON format:\n",
    "```json\n",
    "{\n",
    "  \"rationale\": \"Your step by step reasoning goes here.\",\n",
    "  \"decision\": \"yes | no\"\n",
    "}\n",
    "```\"\"\",\n",
    "\n",
    "    \"empathetic_dialogue\": \"\"\"\n",
    "SYSTEM:\n",
    "  You are an evaluator agent analyzing skills for neuron activations on Sparse Autoencoders. You will receive an explanation from an Auto-Interpretability system. Your task is to judge whether the explanation expresses emotional understanding, emotional reasoning, positive or negative emotion.\n",
    "  These concepts include any of these specific topics: afraid, angry, annoyed, anticipating, anxious, apprehensive, ashamed, caring, confident, content, devastated, disappointed, disgusted, embarrassed, excited, faithful, furious, grateful, guilty, hopeful, impressed, jealous, joyful, lonely, nostalgic, prepared, proud, sad, sentimental, surprised, terrified, trusting.\n",
    "  It also includes any general references to emotional distress, negative emotional states, psychological discomfort, or interpersonal sensitivity.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Think step-by-step, identifying any cues of code structure, algorithmic reasoning, or programming terminology.\n",
    "2. EXCLUDE any explanations that talk only about low-level token patterns, lexical tokens, or sequence-level formatting (e.g., “attends to verbs…”, “counts tokens…”, “looks at underscores…”). Those are not evidence of domain knowledge.\n",
    "3. If there is any uncertainty, choose “no”.\n",
    "4. Output only in JSON (no extra text, no explanation outside your rationale field).\n",
    "\n",
    "Provide your reasoning and final decision in this exact JSON format:\n",
    "```json\n",
    "{\n",
    "  \"rationale\": \"Your step by step reasoning goes here.\",\n",
    "  \"decision\": \"yes | no\"\n",
    "}\n",
    "```\"\"\",\n",
    "\n",
    "    \"math\": \"\"\"\n",
    "SYSTEM:\n",
    "  You are an evaluator agent analyzing skills for neuron activations on Sparse Autoencoders. You will receive an explanation from an Auto-Interpretability system. Your task is to judge whether the explanation expresses mathematical reasoning or problem-solving ability.\n",
    "  These topics include any of these specific areas: algebra, prealgebra, intermediate algebra, number theory, precalculus, geometry, counting and probability.\n",
    "  It also includes any general references to numerical reasoning, arithmetic operations, solving equations, geometric understanding, or probabilistic logic.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Think step-by-step, identifying any cues of code structure, algorithmic reasoning, or programming terminology.\n",
    "2. EXCLUDE any explanations that talk only about low-level token patterns, lexical tokens, or sequence-level formatting (e.g., “attends to verbs…”, “counts tokens…”, “looks at underscores…”). Those are not evidence of domain knowledge.\n",
    "3. If there is any uncertainty, choose “no”.\n",
    "4. Output only in JSON (no extra text, no explanation outside your rationale field).\n",
    "\n",
    "Provide your reasoning and final decision in this exact JSON format:\n",
    "```json\n",
    "{\n",
    "  \"rationale\": \"Your step by step reasoning goes here.\",\n",
    "  \"decision\": \"yes | no\"\n",
    "}\n",
    "```\"\"\",\n",
    "\n",
    "    \"programming\": \"\"\"\n",
    "SYSTEM:\n",
    "  You are an evaluator agent analyzing skills for neuron activations on Sparse Autoencoders. You will receive an explanation from an Auto-Interpretability system. Your task is to judge whether the explanation expresses programming knowledge or computational reasoning.\n",
    "  These concepts include any of these specific topics: programming syntax, programming languages (e.g., Python, C++, JavaScript), data structures (e.g., arrays, lists, trees, graphs), algorithms (e.g., sorting, searching, dynamic programming), code logic, function definitions, debugging steps, pseudocode, object-oriented programming, recursion, loops, conditions, and basic software engineering concepts.\n",
    "  It also includes any general references to code structure, implementation logic, computational flow, or language-specific behavior.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Think step-by-step, identifying any cues of code structure, algorithmic reasoning, or programming terminology.\n",
    "2. EXCLUDE any explanations that talk only about low-level token patterns, lexical tokens, or sequence-level formatting (e.g., “attends to verbs…”, “counts tokens…”, “looks at underscores…”). Those are not evidence of domain knowledge.\n",
    "3. If there is any uncertainty, choose “no”.\n",
    "4. Output only in JSON (no extra text, no explanation outside your rationale field).\n",
    "\n",
    "Provide your reasoning and final decision in this exact JSON format:\n",
    "```json\n",
    "{\n",
    "  \"rationale\": \"Your step by step reasoning goes here.\",\n",
    "  \"decision\": \"yes | no\"\n",
    "}\n",
    "```\"\"\",\n",
    "}\n",
    "\n",
    "\n",
    "WITHIN_SKILL_DATASET = {\n",
    "    \"negative_feelings\": \"\"\"\n",
    "SYSTEM:\n",
    "        You are an evaluator agent analyzing neuron activations on Sparse Autoencoders. You will receive an explanation from an Auto-Interpretability system. Your task is to judge whether the explanation expresses negative emotion or negative sentiment.\n",
    "        \n",
    "        Negative emotional concepts include any of these specific feelings:\n",
    "        afraid, angry, annoyed, anxious, apprehensive, ashamed, devastated, disappointed, disgusted, embarrassed, furious, guilty, jealous, lonely, sad, terrified.\n",
    "        \n",
    "        It also includes any general references to negative sentiment, negative feelings, distress, negativity, or emotional conflict/responses.\n",
    "        \n",
    "        INSTRUCTIONS:\n",
    "        1. Think step-by-step, identifying any cues of negative emotion or sentiment.\n",
    "        2. If there is any uncertainty, choose “no”.\n",
    "        3. Output only in JSON (no extra text, no explanation outside your rationale field)\n",
    "\n",
    "    Provide your reasoning and final decision in this exact JSON format:    \n",
    "    ```json\n",
    "    {{\n",
    "      \"rationale\": \"Your step by step reasoning goes here.\",\n",
    "      \"decision\": \"yes | no\"\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\",\n",
    "\n",
    "    \"positive_feelings\": \"\"\"\n",
    "    SYSTEM:\n",
    "You are an evaluator agent analyzing neuron activations on Sparse Autoencoders. You will receive an explanation from an Auto-Interpretability system. Your task is to judge whether the explanation expresses positive emotion or positive sentiment.\n",
    "\n",
    "Positive emotional concepts include any of these specific feelings:\n",
    "caring, confident, content, excited, faithful, grateful, hopeful, impressed, joyful, prepared, proud, surprised, trusting.\n",
    "\n",
    "It also includes any general references to positive sentiment, positive feelings, positivity, uplift, optimism, or emotional well-being.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Think step-by-step, identifying any cues of positive emotion or positive sentiment.\n",
    "2. EXCLUDE any explanations that talk only about low-level token patterns, lexical tokens, or sequence‑level formatting (e.g., “attends to verbs…”, “counts tokens…”, “looks at underscores…”). Those are not evidence of positive emotion.\n",
    "3. If there is any uncertainty, choose “no”.\n",
    "4. Output only in JSON (no extra text, no explanation outside your rationale field).\n",
    "\n",
    "Provide your reasoning and final decision in this exact JSON format:\n",
    "```json\n",
    "{\n",
    "  \"rationale\": \"Your step-by-step reasoning goes here.\",\n",
    "  \"decision\": \"yes | no\"\n",
    "}\n",
    "\"\"\",\n",
    "    \"law_and_policy\":\"\"\"\n",
    "    SYSTEM:\n",
    "You are an evaluator agent analyzing neuron activations on Sparse Autoencoders. You will receive an explanation from an Auto‑Interpretability system. Your task is to judge whether the explanation expresses legal expertise or knowledge.\n",
    "\n",
    "Legal‐expertise concepts include any of these specific topics:\n",
    "jurisprudence, professional law, international law, U.S. foreign policy, security studies.\n",
    "\n",
    "It also includes any general references to legal reasoning, statutory interpretation, case law analysis, treaties, regulatory frameworks, or national/international security policy.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Think step‑by‑step, identifying any cues of legal expertise or knowledge.\n",
    "2. EXCLUDE any explanations that talk only about low‑level token patterns, lexical tokens, or sequence‑level formatting (e.g., “attends to verbs…”, “counts tokens…”, “looks at underscores…”). Those are not evidence of legal understanding.\n",
    "3. If there is any uncertainty, choose “no”.\n",
    "4. Output only in JSON (no extra text, no explanation outside your rationale field).\n",
    "\n",
    "Provide your reasoning and final decision in this exact JSON format:\n",
    "```json\n",
    "{\n",
    "  \"rationale\": \"Your step‑by‑step reasoning goes here.\",\n",
    "  \"decision\": \"yes | no\"\n",
    "}\n",
    "\"\"\",\n",
    "    \"philosophy_and_ethics\": \"\"\"\n",
    "    SYSTEM:\n",
    "You are an evaluator agent analyzing neuron activations on Sparse Autoencoders. You will receive an explanation from an Auto‑Interpretability system. Your task is to judge whether the explanation expresses **philosophical or ethical reasoning**.\n",
    "\n",
    "Philosophy‑and‑ethics concepts include any of these specific topics:\n",
    "philosophy, moral disputes, moral scenarios, world religions.\n",
    "\n",
    "It also includes any general references to ethical principles, normative theories, values-based reasoning, metaphysical inquiry, theological perspectives, or moral judgment.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Think step‑by‑step, identifying any cues of philosophical or ethical reasoning.\n",
    "2. EXCLUDE any explanations that talk only about low‑level token patterns, lexical tokens, or sequence‑level formatting (e.g., “attends to verbs…”, “counts tokens…”, “looks at underscores…”). Those are not evidence of philosophical or ethical understanding.\n",
    "3. If there is any uncertainty, choose “no”.\n",
    "4. Output only in JSON (no extra text, no explanation outside your rationale field).\n",
    "\n",
    "Provide your reasoning and final decision in this exact JSON format:\n",
    "```json\n",
    "{\n",
    "  \"rationale\": \"Your step‑by‑step reasoning goes here.\",\n",
    "  \"decision\": \"yes | no\"\n",
    "}\n",
    "\n",
    "\"\"\" \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eaaa95a-9612-4c35-90b5-02973faeb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# def parse_llm_response(response):\n",
    "#     # Extract string from response.content\n",
    "#     raw_content = response.content.strip()\n",
    "\n",
    "#     # Remove triple backticks and possible \"json\" label\n",
    "#     if raw_content.startswith(\"```json\"):\n",
    "#         raw_content = raw_content[7:]  # remove ```json\\n\n",
    "#     if raw_content.endswith(\"```\"):\n",
    "#         raw_content = raw_content[:-3]  # remove trailing ```\n",
    "\n",
    "#     # Clean whitespace and load as JSON\n",
    "#     return json.loads(raw_content.strip())\n",
    "\n",
    "# def parse_llm_response(response) -> dict:\n",
    "#     # Azure returns a ChatCompletions model with .choices,\n",
    "#     # each having .message.content\n",
    "#     raw_content = response.choices[0].message.content.strip()\n",
    "\n",
    "#     # strip triple-backticks if present\n",
    "#     if raw_content.startswith(\"```\"):\n",
    "#         # drop ```json or ```\n",
    "#         raw_content = raw_content.split(\"```\", 1)[1].rsplit(\"```\", 1)[0].strip()\n",
    "\n",
    "#     # now load JSON\n",
    "#     return json.loads(raw_content)\n",
    "\n",
    "def parse_llm_response(response) -> dict:\n",
    "    # 1) Extract the content field (guarding against None or missing)\n",
    "    try:\n",
    "        choice = response.choices[0]\n",
    "        content = getattr(choice.message, \"content\", None)\n",
    "        if not content:\n",
    "            raise ValueError(\"No content returned by LLM\")\n",
    "        raw = content.strip()\n",
    "    except (IndexError, AttributeError, ValueError) as e:\n",
    "        # Something went wrong extracting the text\n",
    "        raise RuntimeError(f\"Failed to extract LLM content: {e}\")\n",
    "\n",
    "    # 2) Remove ``` fences if present\n",
    "    if raw.startswith(\"```\"):\n",
    "        # split out the fenced block\n",
    "        parts = raw.split(\"```\")\n",
    "        # parts[0] is before the first fence (likely empty), parts[1] is language (maybe \"json\") or content\n",
    "        # parts[2] is the inner content if fenced\n",
    "        raw = parts[2] if len(parts) >= 3 else parts[1]\n",
    "\n",
    "    raw = raw.strip()\n",
    "\n",
    "    # 3) JSON-parse, but catch decode errors\n",
    "    try:\n",
    "        return json.loads(raw)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # include the raw string in the exception for debugging\n",
    "        raise ValueError(\n",
    "            f\"Failed to parse JSON (char {e.pos}): {e.msg}\\n\"\n",
    "            f\"Raw content was:\\n{raw}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9384e02d-5bf0-487b-976b-969ebaa1ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_answer(QUESTION: str, print_output: bool = False):\n",
    "    # System prompt with escaped braces for JSON formatting\n",
    "    system_template = WITHIN_SKILL_DATASET[DATASET_NAMES[DEPLOYMENT_NAME]]\n",
    "    # system_template = WITHIN_SKILL_DATASET[DATASET_NAMES[DEPLOYMENT_NAME]]\n",
    "\n",
    "    # User message prompt\n",
    "    user_prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"\n",
    "        Question:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    user_message = user_prompt.format(question=QUESTION)\n",
    "\n",
    "    # LLM call\n",
    "    # response = llm.invoke([\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_template},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        model= deployment_names[DEPLOYMENT_NAME]                                        \n",
    "    )\n",
    "    # print(system_template)\n",
    "    return parse_llm_response(response)\n",
    "    # return parse_json_response(response.content, print_output=print_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39f9cc7d-8855-454d-af8f-66a90934ccdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given text is a description of a system component attending to descriptive or evaluative adjectives and phrases. It contains no expression of negative emotion or sentiment, nor any of the listed negative emotional concepts.\n",
      "no\n"
     ]
    }
   ],
   "source": [
    "# skill_name = \"terrified\"\n",
    "# skill_examples = \"\"\"\n",
    "#         * Emotional expressions \n",
    "#         * Mentions words or concepts tied to emotional states of fear, anxiety, panic, afraid or stress.\n",
    "#         * Describes reactions or content commonly associated with being terrified (e.g., phrases evoking danger, emotional distress, intense fear).\n",
    "#         * Suggests personal or emotional responses aligned with fear or negativity.\n",
    "#         * Terms that can result in a terrified state\n",
    "# \"\"\"\n",
    "# ============================================================================\n",
    "\n",
    "# question = \"expressions of personal sentiment and emotional responses\"\n",
    "# question = \"I am so scared of that happening\"\n",
    "# question = \"elements related to conflict and action\"\n",
    "# question = \"expressions of uncertainty and emotional reactions\"\n",
    "# question = \"negations and expressions implying uncertainty or disagreement\"\n",
    "# question = \"intensifiers related to feelings or emotions\"\n",
    "# question = \"expressions of emotional states and interpersonal connections\"\n",
    "# question = \"expressions of strong emotions or feelings\"\n",
    "# question = \"expressions of love and enjoyment of outdoor activities\"\n",
    "# question = \"emotions and introspective thoughts related to intense experiences\"\n",
    "# question = \"references to family relationships and their emotional connections\"\n",
    "# question = \"emotional expressions and states\"\n",
    "# question = \"phrases that convey experiences of distress or psychological states\"\n",
    "# question = \"references to negative thoughts\"\n",
    "# question = \"negative emotional states or feelings associated with difficult situations\"\n",
    "# question = \"expressions of fear and anxiety\"\n",
    "# question = \"expressions and sentiments related to love and affection\"\n",
    "# question = \"phrases indicating personal struggle or emotional conflict\"\n",
    "# question = \"expressions of fear and anxiety\"\n",
    "question = \"attends to descriptive or evaluative adjectives and phrases indicating qualities or states from subjective expressions or comments\t\"\n",
    "\n",
    "output = get_answer(question)\n",
    "\n",
    "# print(output)\n",
    "print(output[\"rationale\"])\n",
    "print(output[\"decision\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e860dd-d93c-4eff-bb0e-99216f539a0c",
   "metadata": {},
   "source": [
    "# DECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "512c1d5f-f571-4298-b8f4-f40a68350cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # make sure the column exists\n",
    "# if \"llm_decision\" not in df.columns:\n",
    "#     df[\"llm_decision\"] = None\n",
    "\n",
    "# for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"LLM EVAL\"):\n",
    "#     explanation = row[\"Explanation\"]\n",
    "#     try:\n",
    "#         response = get_answer(\n",
    "#             QUESTION=explanation,\n",
    "#             print_output=False\n",
    "#         )\n",
    "#         df.at[idx, \"llm_decision\"] = response[\"decision\"]\n",
    "#         # df.at[idx, \"llm_rationale\"] = response[\"rationale\"]\n",
    "#     except Exception as e:\n",
    "#         df.at[idx, \"llm_decision\"] = \"ERROR\"\n",
    "\n",
    "# df.to_csv(path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b676051-e28a-4d7f-9c10-4dd4ff01106d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative_feelings'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COL_NAME = DATASET_NAMES[DEPLOYMENT_NAME]\n",
    "COL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "904a8d93-97b6-483a-aa66-af1e8f1c7b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220210"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "38aedf10-8c09-431d-9e26-cac800c0281e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>layer</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Explanations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>282</td>\n",
       "      <td>12699340.0</td>\n",
       "      <td>hyperlinks and web addresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>att</td>\n",
       "      <td>22</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>14953</td>\n",
       "      <td>12099597.0</td>\n",
       "      <td>attends to specific significant tokens from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>att</td>\n",
       "      <td>12</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>2424</td>\n",
       "      <td>10867400.0</td>\n",
       "      <td>attends from tokens denoting an action or con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>9329</td>\n",
       "      <td>10860906.0</td>\n",
       "      <td>legal terms and phrases related to court case...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>att</td>\n",
       "      <td>7</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>10364</td>\n",
       "      <td>10214085.0</td>\n",
       "      <td>attends to instances of the token followed by...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type  layer       class1       class2  Neuron_ID  Contribution  \\\n",
       "0  mlp     24   devastated  embarrassed        282    12699340.0   \n",
       "1  att     22   devastated  embarrassed      14953    12099597.0   \n",
       "2  att     12   devastated  embarrassed       2424    10867400.0   \n",
       "3  mlp     24  embarrassed      furious       9329    10860906.0   \n",
       "4  att      7      ashamed  embarrassed      10364    10214085.0   \n",
       "\n",
       "                                        Explanations  \n",
       "0                       hyperlinks and web addresses  \n",
       "1   attends to specific significant tokens from s...  \n",
       "2   attends from tokens denoting an action or con...  \n",
       "3   legal terms and phrases related to court case...  \n",
       "4   attends to instances of the token followed by...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a7e7351-42ab-42b4-b1b0-48eac29957e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming: 5 rows to go (up to 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resuming LLM EVAL: 100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done! Final CSV written to ./datasets/explanations_negative_feelings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "\n",
    "# --- setup (as before) ---\n",
    "# df is already loaded\n",
    "# COL_NAME, DATASET_NAMES, DEPLOYMENT_NAME, get_answer are defined\n",
    "\n",
    "if COL_NAME not in df.columns:\n",
    "    df[COL_NAME] = None\n",
    "\n",
    "def process_row(idx, explanation, max_retries=2, backoff_s=1):\n",
    "    for attempt in range(max_retries + 1):\n",
    "        try:\n",
    "            resp = get_answer(QUESTION=explanation, print_output=False)\n",
    "            return idx, resp[\"decision\"]\n",
    "        except Exception:\n",
    "            if attempt < max_retries:\n",
    "                time.sleep(backoff_s)\n",
    "            else:\n",
    "                return idx, \"ERROR\"\n",
    "\n",
    "# how far we want to go\n",
    "new_max = df.shape[0]\n",
    "# new_max = 5\n",
    "\n",
    "# pick only those in [0, new_max) still unfilled\n",
    "to_process = (\n",
    "    df\n",
    "    .iloc[:new_max]\n",
    "    .loc[df[COL_NAME].isna()]\n",
    "    .iterrows()\n",
    ")\n",
    "total = len(df.iloc[:new_max]) - df[COL_NAME].notna().sum()\n",
    "print(f\"Resuming: {total} rows to go (up to {new_max})\")\n",
    "\n",
    "output_name = DATASET_NAMES[DEPLOYMENT_NAME]\n",
    "output_path = f\"./datasets/dot_product/explanations_{output_name}.csv\"\n",
    "\n",
    "# counter for checkpointing\n",
    "processed_since_start = 0\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    futures = {\n",
    "        executor.submit(process_row, idx, row[\"Explanations\"]): idx\n",
    "        for idx, row in to_process\n",
    "    }\n",
    "\n",
    "    for future in tqdm(as_completed(futures), total=total, desc=\"Resuming LLM EVAL\"):\n",
    "        idx, decision = future.result()\n",
    "        # write back immediately\n",
    "        df.at[idx, COL_NAME] = decision\n",
    "\n",
    "        processed_since_start += 1\n",
    "        # every 10k, flush to disk\n",
    "        if processed_since_start % 10_000 == 0:\n",
    "            print(f\"[{processed_since_start}/{total}] rows done — saving checkpoint...\")\n",
    "            df.to_csv(output_path, index=False)\n",
    "\n",
    "# final save\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"All done! Final CSV written to\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5278975f-85c3-47c1-85fb-5261bac1d553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>layer</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Explanation</th>\n",
       "      <th>negative_feelings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>282</td>\n",
       "      <td>12699340.0</td>\n",
       "      <td>hyperlinks and web addresses</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>att</td>\n",
       "      <td>22</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>14953</td>\n",
       "      <td>12099597.0</td>\n",
       "      <td>attends to specific significant tokens from s...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>att</td>\n",
       "      <td>12</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>2424</td>\n",
       "      <td>10867400.0</td>\n",
       "      <td>attends from tokens denoting an action or con...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>9329</td>\n",
       "      <td>10860906.0</td>\n",
       "      <td>legal terms and phrases related to court case...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>att</td>\n",
       "      <td>7</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>10364</td>\n",
       "      <td>10214085.0</td>\n",
       "      <td>attends to instances of the token followed by...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>res</td>\n",
       "      <td>1</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>12054</td>\n",
       "      <td>9616475.0</td>\n",
       "      <td>content related to medical conditions and trea...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>att</td>\n",
       "      <td>23</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>5279</td>\n",
       "      <td>9500750.0</td>\n",
       "      <td>attends to the token \"by\" from the surroundin...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mlp</td>\n",
       "      <td>7</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>6117</td>\n",
       "      <td>9141438.0</td>\n",
       "      <td>topics related to nutrition and health measur...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>att</td>\n",
       "      <td>5</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>9670</td>\n",
       "      <td>9120768.0</td>\n",
       "      <td>attends to specific tokens lacking any conten...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>res</td>\n",
       "      <td>12</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>2620</td>\n",
       "      <td>8510100.0</td>\n",
       "      <td>words associated with authority, control, and ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>att</td>\n",
       "      <td>17</td>\n",
       "      <td>anxious</td>\n",
       "      <td>lonely</td>\n",
       "      <td>14463</td>\n",
       "      <td>8229474.0</td>\n",
       "      <td>attends to tokens like \"kg\" and \"kJ\" from oth...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>att</td>\n",
       "      <td>10</td>\n",
       "      <td>devastated</td>\n",
       "      <td>lonely</td>\n",
       "      <td>3101</td>\n",
       "      <td>8208000.0</td>\n",
       "      <td>attends to the token \"ern\" from the adjacent ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mlp</td>\n",
       "      <td>25</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>13264</td>\n",
       "      <td>7896258.0</td>\n",
       "      <td>elements related to conflict and action</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>att</td>\n",
       "      <td>17</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>12484</td>\n",
       "      <td>7638678.0</td>\n",
       "      <td>attends to alphanumeric tokens from the secon...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>att</td>\n",
       "      <td>10</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>7009</td>\n",
       "      <td>7569420.0</td>\n",
       "      <td>attends to terms related to a specific token ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>res</td>\n",
       "      <td>13</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>11256</td>\n",
       "      <td>7154722.0</td>\n",
       "      <td>phrases related to product features and specif...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mlp</td>\n",
       "      <td>4</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>14164</td>\n",
       "      <td>7083744.0</td>\n",
       "      <td>structured programming elements and documentat...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mlp</td>\n",
       "      <td>12</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>9338</td>\n",
       "      <td>6980043.0</td>\n",
       "      <td>phrases related to assistance and support ser...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>att</td>\n",
       "      <td>6</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>3484</td>\n",
       "      <td>6772500.0</td>\n",
       "      <td>attends to pivotal tokens marked by commas fr...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>att</td>\n",
       "      <td>11</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>11572</td>\n",
       "      <td>6747006.0</td>\n",
       "      <td>attends to regulatory or function-determining...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>mlp</td>\n",
       "      <td>4</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>2793</td>\n",
       "      <td>6423824.0</td>\n",
       "      <td>terms related to legal and regulatory document...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mlp</td>\n",
       "      <td>7</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>12096</td>\n",
       "      <td>6367780.0</td>\n",
       "      <td>terms related to healthcare and medical advice</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>res</td>\n",
       "      <td>15</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>1695</td>\n",
       "      <td>6336724.0</td>\n",
       "      <td>phrases related to accountability and responsi...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>res</td>\n",
       "      <td>10</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>3986</td>\n",
       "      <td>6336362.0</td>\n",
       "      <td>terms related to film awards and achievements</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>att</td>\n",
       "      <td>9</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>4597</td>\n",
       "      <td>6317171.0</td>\n",
       "      <td>attends to terminal punctuation marks from br...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>res</td>\n",
       "      <td>11</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>3151</td>\n",
       "      <td>6309126.0</td>\n",
       "      <td>concepts related to human emotions and needs f...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>att</td>\n",
       "      <td>1</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>11003</td>\n",
       "      <td>6152872.0</td>\n",
       "      <td>attends to the right parenthesis in mathemati...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>att</td>\n",
       "      <td>18</td>\n",
       "      <td>devastated</td>\n",
       "      <td>lonely</td>\n",
       "      <td>7096</td>\n",
       "      <td>5799312.0</td>\n",
       "      <td>attends to an unspecified context from previo...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>att</td>\n",
       "      <td>20</td>\n",
       "      <td>devastated</td>\n",
       "      <td>lonely</td>\n",
       "      <td>9566</td>\n",
       "      <td>5683447.0</td>\n",
       "      <td>attends to the \"to\" token from occurrences of...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>att</td>\n",
       "      <td>4</td>\n",
       "      <td>anxious</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>5518</td>\n",
       "      <td>5174601.0</td>\n",
       "      <td>attends to mathematical notation and symbols ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>att</td>\n",
       "      <td>8</td>\n",
       "      <td>jealous</td>\n",
       "      <td>lonely</td>\n",
       "      <td>9940</td>\n",
       "      <td>5168800.0</td>\n",
       "      <td>attends to closing braces and nested structur...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>res</td>\n",
       "      <td>14</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>12319</td>\n",
       "      <td>4966505.0</td>\n",
       "      <td>statements about failure or lack of success in...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>res</td>\n",
       "      <td>9</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>54</td>\n",
       "      <td>4952636.0</td>\n",
       "      <td>words associated with awards and recognitions ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mlp</td>\n",
       "      <td>10</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>7495</td>\n",
       "      <td>4842018.0</td>\n",
       "      <td>structures related to mathematical or technica...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>mlp</td>\n",
       "      <td>11</td>\n",
       "      <td>devastated</td>\n",
       "      <td>furious</td>\n",
       "      <td>6316</td>\n",
       "      <td>4753458.0</td>\n",
       "      <td>references to scientific concepts and methodol...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>att</td>\n",
       "      <td>9</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>4526</td>\n",
       "      <td>4670523.0</td>\n",
       "      <td>attends to the dollar sign token from Q-relat...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>att</td>\n",
       "      <td>24</td>\n",
       "      <td>angry</td>\n",
       "      <td>furious</td>\n",
       "      <td>10565</td>\n",
       "      <td>4507555.0</td>\n",
       "      <td>attends to individual tokens that relate to a...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>att</td>\n",
       "      <td>4</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>4742</td>\n",
       "      <td>4490175.0</td>\n",
       "      <td>attends to specific keywords marked with doub...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>res</td>\n",
       "      <td>7</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>furious</td>\n",
       "      <td>12287</td>\n",
       "      <td>4466070.0</td>\n",
       "      <td>specific nouns and related actions or concepts...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>att</td>\n",
       "      <td>16</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>lonely</td>\n",
       "      <td>11259</td>\n",
       "      <td>4440656.0</td>\n",
       "      <td>attends to mathematical or programming-relate...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>mlp</td>\n",
       "      <td>8</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>1367</td>\n",
       "      <td>4400379.0</td>\n",
       "      <td>specific scientific or technical terms related...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>mlp</td>\n",
       "      <td>9</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>11525</td>\n",
       "      <td>4300992.0</td>\n",
       "      <td>elements related to decision-making and choices</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>mlp</td>\n",
       "      <td>15</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>75</td>\n",
       "      <td>4261348.0</td>\n",
       "      <td>technical and programming terminology</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>att</td>\n",
       "      <td>12</td>\n",
       "      <td>anxious</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>14886</td>\n",
       "      <td>4087460.0</td>\n",
       "      <td>attends to the presence of double markers fro...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>mlp</td>\n",
       "      <td>5</td>\n",
       "      <td>devastated</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>15592</td>\n",
       "      <td>3908465.0</td>\n",
       "      <td>the presence of specific identifiers or names...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>mlp</td>\n",
       "      <td>11</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>4397</td>\n",
       "      <td>3702770.0</td>\n",
       "      <td>words related to various scientific or technic...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>att</td>\n",
       "      <td>19</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>lonely</td>\n",
       "      <td>2528</td>\n",
       "      <td>3672816.0</td>\n",
       "      <td>attends to personal pronouns from themselves ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>res</td>\n",
       "      <td>8</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>furious</td>\n",
       "      <td>9213</td>\n",
       "      <td>3651940.0</td>\n",
       "      <td>specific terms related to structure, classific...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>att</td>\n",
       "      <td>14</td>\n",
       "      <td>jealous</td>\n",
       "      <td>lonely</td>\n",
       "      <td>10020</td>\n",
       "      <td>3640890.0</td>\n",
       "      <td>attends to references to female family member...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>att</td>\n",
       "      <td>24</td>\n",
       "      <td>devastated</td>\n",
       "      <td>lonely</td>\n",
       "      <td>12402</td>\n",
       "      <td>3563982.0</td>\n",
       "      <td>attends to tokens related to musical or artis...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>att</td>\n",
       "      <td>0</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>9944</td>\n",
       "      <td>3534210.0</td>\n",
       "      <td>attends to the period token from various othe...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>att</td>\n",
       "      <td>19</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>jealous</td>\n",
       "      <td>13363</td>\n",
       "      <td>3434525.0</td>\n",
       "      <td>attends to informal or conversational phrase ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>mlp</td>\n",
       "      <td>23</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>guilty</td>\n",
       "      <td>10184</td>\n",
       "      <td>3244646.0</td>\n",
       "      <td>mathematical or analytical expressions related...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>att</td>\n",
       "      <td>11</td>\n",
       "      <td>anxious</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>2311</td>\n",
       "      <td>3218075.0</td>\n",
       "      <td>attends to specific programming language toke...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>res</td>\n",
       "      <td>8</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>2024</td>\n",
       "      <td>3129724.0</td>\n",
       "      <td>names of notable performance venues and cultur...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>res</td>\n",
       "      <td>11</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>furious</td>\n",
       "      <td>12945</td>\n",
       "      <td>3126992.0</td>\n",
       "      <td>specific references to medical and scientific ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>mlp</td>\n",
       "      <td>6</td>\n",
       "      <td>anxious</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>7589</td>\n",
       "      <td>3116880.0</td>\n",
       "      <td>content related to neural crest cells and thei...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>att</td>\n",
       "      <td>8</td>\n",
       "      <td>anxious</td>\n",
       "      <td>lonely</td>\n",
       "      <td>11894</td>\n",
       "      <td>3070386.0</td>\n",
       "      <td>attends to code or symbol tokens from a range...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>mlp</td>\n",
       "      <td>13</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>13617</td>\n",
       "      <td>2968648.0</td>\n",
       "      <td>references to political and legal matters in ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>mlp</td>\n",
       "      <td>14</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>jealous</td>\n",
       "      <td>14672</td>\n",
       "      <td>2899053.0</td>\n",
       "      <td>references to geographic locations and scienti...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>att</td>\n",
       "      <td>15</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>furious</td>\n",
       "      <td>7464</td>\n",
       "      <td>2890485.0</td>\n",
       "      <td>attends to a variety of expressions or sentim...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>res</td>\n",
       "      <td>7</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>embarrassed</td>\n",
       "      <td>3704</td>\n",
       "      <td>2782220.0</td>\n",
       "      <td>discussions around authoritarianism and its ef...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>att</td>\n",
       "      <td>15</td>\n",
       "      <td>anxious</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>2522</td>\n",
       "      <td>2780288.0</td>\n",
       "      <td>attends to punctuation marks from various tok...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>att</td>\n",
       "      <td>6</td>\n",
       "      <td>anxious</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>1231</td>\n",
       "      <td>2601513.0</td>\n",
       "      <td>attends to tokens indicating programming or t...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>res</td>\n",
       "      <td>10</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>furious</td>\n",
       "      <td>4392</td>\n",
       "      <td>2566403.0</td>\n",
       "      <td>words related to magic or illusion</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>res</td>\n",
       "      <td>9</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>furious</td>\n",
       "      <td>12102</td>\n",
       "      <td>2501428.0</td>\n",
       "      <td>structural elements and syntax within code or ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>att</td>\n",
       "      <td>13</td>\n",
       "      <td>afraid</td>\n",
       "      <td>anxious</td>\n",
       "      <td>1654</td>\n",
       "      <td>2485196.0</td>\n",
       "      <td>attends to the closing parenthesis or specifi...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>att</td>\n",
       "      <td>14</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>jealous</td>\n",
       "      <td>3431</td>\n",
       "      <td>2382336.0</td>\n",
       "      <td>attends to punctuation marks from tokens that...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>res</td>\n",
       "      <td>15</td>\n",
       "      <td>disgusted</td>\n",
       "      <td>furious</td>\n",
       "      <td>10716</td>\n",
       "      <td>2380120.0</td>\n",
       "      <td>specific structural elements and formatting in...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>res</td>\n",
       "      <td>16</td>\n",
       "      <td>ashamed</td>\n",
       "      <td>guilty</td>\n",
       "      <td>3847</td>\n",
       "      <td>2354618.0</td>\n",
       "      <td>specific programming or computational element...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  layer        class1        class2  Neuron_ID  Contribution  \\\n",
       "0   mlp     24    devastated   embarrassed        282    12699340.0   \n",
       "1   att     22    devastated   embarrassed      14953    12099597.0   \n",
       "2   att     12    devastated   embarrassed       2424    10867400.0   \n",
       "3   mlp     24   embarrassed       furious       9329    10860906.0   \n",
       "4   att      7       ashamed   embarrassed      10364    10214085.0   \n",
       "5   res      1       ashamed   embarrassed      12054     9616475.0   \n",
       "6   att     23    devastated   embarrassed       5279     9500750.0   \n",
       "7   mlp      7   embarrassed       furious       6117     9141438.0   \n",
       "8   att      5   embarrassed       furious       9670     9120768.0   \n",
       "9   res     12   embarrassed       furious       2620     8510100.0   \n",
       "10  att     17       anxious        lonely      14463     8229474.0   \n",
       "11  att     10    devastated        lonely       3101     8208000.0   \n",
       "12  mlp     25       ashamed   embarrassed      13264     7896258.0   \n",
       "13  att     17   embarrassed       furious      12484     7638678.0   \n",
       "14  att     10    devastated   embarrassed       7009     7569420.0   \n",
       "15  res     13   embarrassed       furious      11256     7154722.0   \n",
       "16  mlp      4    devastated   embarrassed      14164     7083744.0   \n",
       "17  mlp     12     disgusted   embarrassed       9338     6980043.0   \n",
       "18  att      6   embarrassed       furious       3484     6772500.0   \n",
       "19  att     11       ashamed  disappointed      11572     6747006.0   \n",
       "20  mlp      4    devastated   embarrassed       2793     6423824.0   \n",
       "21  mlp      7   embarrassed       furious      12096     6367780.0   \n",
       "22  res     15  disappointed   embarrassed       1695     6336724.0   \n",
       "23  res     10   embarrassed       furious       3986     6336362.0   \n",
       "24  att      9   embarrassed       furious       4597     6317171.0   \n",
       "25  res     11   embarrassed       furious       3151     6309126.0   \n",
       "26  att      1     disgusted   embarrassed      11003     6152872.0   \n",
       "27  att     18    devastated        lonely       7096     5799312.0   \n",
       "28  att     20    devastated        lonely       9566     5683447.0   \n",
       "29  att      4       anxious  disappointed       5518     5174601.0   \n",
       "30  att      8       jealous        lonely       9940     5168800.0   \n",
       "31  res     14   embarrassed       furious      12319     4966505.0   \n",
       "32  res      9       ashamed   embarrassed         54     4952636.0   \n",
       "33  mlp     10     disgusted   embarrassed       7495     4842018.0   \n",
       "34  mlp     11    devastated       furious       6316     4753458.0   \n",
       "35  att      9       ashamed   embarrassed       4526     4670523.0   \n",
       "36  att     24         angry       furious      10565     4507555.0   \n",
       "37  att      4    devastated   embarrassed       4742     4490175.0   \n",
       "38  res      7     disgusted       furious      12287     4466070.0   \n",
       "39  att     16   embarrassed        lonely      11259     4440656.0   \n",
       "40  mlp      8     disgusted   embarrassed       1367     4400379.0   \n",
       "41  mlp      9  disappointed     disgusted      11525     4300992.0   \n",
       "42  mlp     15     disgusted   embarrassed         75     4261348.0   \n",
       "43  att     12       anxious   embarrassed      14886     4087460.0   \n",
       "44  mlp      5    devastated   embarrassed      15592     3908465.0   \n",
       "45  mlp     11     disgusted   embarrassed       4397     3702770.0   \n",
       "46  att     19   embarrassed        lonely       2528     3672816.0   \n",
       "47  res      8     disgusted       furious       9213     3651940.0   \n",
       "48  att     14       jealous        lonely      10020     3640890.0   \n",
       "49  att     24    devastated        lonely      12402     3563982.0   \n",
       "50  att      0     disgusted   embarrassed       9944     3534210.0   \n",
       "51  att     19   embarrassed       jealous      13363     3434525.0   \n",
       "52  mlp     23   embarrassed        guilty      10184     3244646.0   \n",
       "53  att     11       anxious       ashamed       2311     3218075.0   \n",
       "54  res      8  disappointed   embarrassed       2024     3129724.0   \n",
       "55  res     11     disgusted       furious      12945     3126992.0   \n",
       "56  mlp      6       anxious  disappointed       7589     3116880.0   \n",
       "57  att      8       anxious        lonely      11894     3070386.0   \n",
       "58  mlp     13     disgusted   embarrassed      13617     2968648.0   \n",
       "59  mlp     14  disappointed       jealous      14672     2899053.0   \n",
       "60  att     15   embarrassed       furious       7464     2890485.0   \n",
       "61  res      7       ashamed   embarrassed       3704     2782220.0   \n",
       "62  att     15       anxious  disappointed       2522     2780288.0   \n",
       "63  att      6       anxious  disappointed       1231     2601513.0   \n",
       "64  res     10     disgusted       furious       4392     2566403.0   \n",
       "65  res      9     disgusted       furious      12102     2501428.0   \n",
       "66  att     13        afraid       anxious       1654     2485196.0   \n",
       "67  att     14  disappointed       jealous       3431     2382336.0   \n",
       "68  res     15     disgusted       furious      10716     2380120.0   \n",
       "69  res     16       ashamed        guilty       3847     2354618.0   \n",
       "\n",
       "                                          Explanation negative_feelings  \n",
       "0                        hyperlinks and web addresses                no  \n",
       "1    attends to specific significant tokens from s...                no  \n",
       "2    attends from tokens denoting an action or con...                no  \n",
       "3    legal terms and phrases related to court case...                no  \n",
       "4    attends to instances of the token followed by...                no  \n",
       "5   content related to medical conditions and trea...              None  \n",
       "6    attends to the token \"by\" from the surroundin...              None  \n",
       "7    topics related to nutrition and health measur...              None  \n",
       "8    attends to specific tokens lacking any conten...              None  \n",
       "9   words associated with authority, control, and ...              None  \n",
       "10   attends to tokens like \"kg\" and \"kJ\" from oth...              None  \n",
       "11   attends to the token \"ern\" from the adjacent ...              None  \n",
       "12            elements related to conflict and action              None  \n",
       "13   attends to alphanumeric tokens from the secon...              None  \n",
       "14   attends to terms related to a specific token ...              None  \n",
       "15  phrases related to product features and specif...              None  \n",
       "16  structured programming elements and documentat...              None  \n",
       "17   phrases related to assistance and support ser...              None  \n",
       "18   attends to pivotal tokens marked by commas fr...              None  \n",
       "19   attends to regulatory or function-determining...              None  \n",
       "20  terms related to legal and regulatory document...              None  \n",
       "21     terms related to healthcare and medical advice              None  \n",
       "22  phrases related to accountability and responsi...              None  \n",
       "23      terms related to film awards and achievements              None  \n",
       "24   attends to terminal punctuation marks from br...              None  \n",
       "25  concepts related to human emotions and needs f...              None  \n",
       "26   attends to the right parenthesis in mathemati...              None  \n",
       "27   attends to an unspecified context from previo...              None  \n",
       "28   attends to the \"to\" token from occurrences of...              None  \n",
       "29   attends to mathematical notation and symbols ...              None  \n",
       "30   attends to closing braces and nested structur...              None  \n",
       "31  statements about failure or lack of success in...              None  \n",
       "32  words associated with awards and recognitions ...              None  \n",
       "33  structures related to mathematical or technica...              None  \n",
       "34  references to scientific concepts and methodol...              None  \n",
       "35   attends to the dollar sign token from Q-relat...              None  \n",
       "36   attends to individual tokens that relate to a...              None  \n",
       "37   attends to specific keywords marked with doub...              None  \n",
       "38  specific nouns and related actions or concepts...              None  \n",
       "39   attends to mathematical or programming-relate...              None  \n",
       "40  specific scientific or technical terms related...              None  \n",
       "41    elements related to decision-making and choices              None  \n",
       "42              technical and programming terminology              None  \n",
       "43   attends to the presence of double markers fro...              None  \n",
       "44   the presence of specific identifiers or names...              None  \n",
       "45  words related to various scientific or technic...              None  \n",
       "46   attends to personal pronouns from themselves ...              None  \n",
       "47  specific terms related to structure, classific...              None  \n",
       "48   attends to references to female family member...              None  \n",
       "49   attends to tokens related to musical or artis...              None  \n",
       "50   attends to the period token from various othe...              None  \n",
       "51   attends to informal or conversational phrase ...              None  \n",
       "52  mathematical or analytical expressions related...              None  \n",
       "53   attends to specific programming language toke...              None  \n",
       "54  names of notable performance venues and cultur...              None  \n",
       "55  specific references to medical and scientific ...              None  \n",
       "56  content related to neural crest cells and thei...              None  \n",
       "57   attends to code or symbol tokens from a range...              None  \n",
       "58   references to political and legal matters in ...              None  \n",
       "59  references to geographic locations and scienti...              None  \n",
       "60   attends to a variety of expressions or sentim...              None  \n",
       "61  discussions around authoritarianism and its ef...              None  \n",
       "62   attends to punctuation marks from various tok...              None  \n",
       "63   attends to tokens indicating programming or t...              None  \n",
       "64                 words related to magic or illusion              None  \n",
       "65  structural elements and syntax within code or ...              None  \n",
       "66   attends to the closing parenthesis or specifi...              None  \n",
       "67   attends to punctuation marks from tokens that...              None  \n",
       "68  specific structural elements and formatting in...              None  \n",
       "69   specific programming or computational element...              None  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a8f1ad-f697-4318-ba5e-55037f445816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
