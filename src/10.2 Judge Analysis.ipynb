{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e248cd-a6b7-417d-9c16-c4f23447bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [\n",
    "    # \"afraid_vs_terrified\",\n",
    "    # \"content_vs_hopeful\",\n",
    "    # \"hopeful_vs_terrified\",\n",
    "    # \"sad_vs_anxious\",\n",
    "    \"sad_vs_sad\"\n",
    "]\n",
    "\n",
    "\n",
    "for file_name in file_names:\n",
    "  # Specify the file path\n",
    "  file_path = f'/content/drive/MyDrive/LLM Interpretability/datasets/{file_name}.csv' # Replace with your actual file path\n",
    "\n",
    "  # print(file_name)\n",
    "  df = pd.read_csv(file_path)  # Assuming a CSV file, change function for other formats\n",
    "  df = df[df[\"llm_decision\"] == \"yes\"]\n",
    "  df.shape\n",
    "\n",
    "  type_frequencies = df['type'].value_counts()\n",
    "  # print(\"Frequency of each type:\")\n",
    "  # print(type_frequencies)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429c88e-f41f-4778-9bc6-3d09619c3396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_names = [\n",
    "    \"afraid_vs_terrified\",\n",
    "    \"content_vs_hopeful\",\n",
    "    \"hopeful_vs_terrified\",\n",
    "    \"sad_vs_anxious\",\n",
    "    \"sad_vs_sad\"\n",
    "]\n",
    "\n",
    "# Initialize counter\n",
    "total_counts = pd.Series({'mlp': 0, 'res': 0, 'att': 0}, dtype=int)\n",
    "\n",
    "# Process each file and accumulate type frequencies\n",
    "for file_name in file_names:\n",
    "    file_path = f'/content/drive/MyDrive/LLM Interpretability/datasets/{file_name}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df[\"llm_decision\"] == \"yes\"]\n",
    "\n",
    "    counts = df['type'].value_counts().reindex(['mlp', 'res', 'att'], fill_value=0)\n",
    "    total_counts += counts\n",
    "\n",
    "# Compute average\n",
    "average_counts = total_counts / len(file_names)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "average_counts.plot(kind='bar', color=['skyblue', 'lightcoral', 'mediumseagreen'])\n",
    "plt.title('Average Type Frequency Across Samples')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Average Frequency')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd44766-06ec-4830-b3af-e9ebf41060c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_names = [\n",
    "    \"afraid_vs_terrified\",\n",
    "    \"content_vs_hopeful\",\n",
    "    \"hopeful_vs_terrified\",\n",
    "    \"sad_vs_anxious\",\n",
    "    \"sad_vs_sad\"\n",
    "]\n",
    "\n",
    "# Initialize counter\n",
    "total_counts = pd.Series({'mlp': 0, 'res': 0, 'att': 0}, dtype=int)\n",
    "\n",
    "# Process each file and accumulate type frequencies\n",
    "for file_name in file_names:\n",
    "    file_path = f'/content/drive/MyDrive/LLM Interpretability/datasets/{file_name}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df[df[\"llm_decision\"] == \"yes\"]\n",
    "\n",
    "    counts = df['type'].value_counts().reindex(['mlp', 'res', 'att'], fill_value=0)\n",
    "    total_counts += counts\n",
    "\n",
    "# Plot the total frequencies\n",
    "plt.figure(figsize=(6, 4))\n",
    "total_counts.plot(kind='bar', color=['skyblue', 'lightcoral', 'mediumseagreen'])\n",
    "plt.title('Total Type Frequency Across All Files')\n",
    "plt.xlabel('Type')\n",
    "plt.ylabel('Total Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1fe13-e445-4055-bd08-5b4621554d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_frequencies = df['type'].value_counts()\n",
    "print(\"Frequency of each type:\")\n",
    "print(type_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9e0778-43b2-43a4-b22c-a66011c7481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_names = [\n",
    "    \"afraid_vs_terrified\",\n",
    "    \"content_vs_hopeful\",\n",
    "    \"hopeful_vs_terrified\",\n",
    "    \"sad_vs_anxious\",\n",
    "    \"sad_vs_sad\"\n",
    "]\n",
    "\n",
    "type_rows = []\n",
    "layer_rows = []\n",
    "sizes = []\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = f'/content/drive/MyDrive/LLM Interpretability/datasets/{file_name}.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    sizes.append(len(df))\n",
    "    df = df[df[\"llm_decision\"] == \"yes\"]\n",
    "\n",
    "    # --- Type counts ---\n",
    "    type_counts = df['type'].value_counts().reindex(['mlp', 'res', 'att'], fill_value=0)\n",
    "    type_rows.append(type_counts)\n",
    "\n",
    "    # --- Layer counts ---\n",
    "    layer_counts = df['layer'].value_counts().reindex(range(26), fill_value=0)\n",
    "    layer_counts.index = [f'l{i}' for i in range(26)]\n",
    "    layer_rows.append(layer_counts)\n",
    "\n",
    "# Create type summary table\n",
    "type_df = pd.DataFrame(type_rows, index=file_names)\n",
    "type_df[\"total_rows\"] = sizes\n",
    "type_df.index.name = \"File\"\n",
    "\n",
    "# Create layer summary table\n",
    "layer_df = pd.DataFrame(layer_rows, index=file_names)\n",
    "layer_df.index.name = \"File\"\n",
    "\n",
    "# Save or display\n",
    "type_df.to_csv(\"type_summary.csv\")\n",
    "layer_df.to_csv(\"layer_summary.csv\")\n",
    "\n",
    "# Or view in notebook\n",
    "print(\"== Type Summary ==\")\n",
    "print(type_df)\n",
    "\n",
    "print(\"\\n== Layer Summary ==\")\n",
    "print(layer_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1789b8-e7a5-4a61-98ff-facc295b76f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `summary_df` is already created as in the previous step\n",
    "\n",
    "# Sum layer counts across all files\n",
    "layer_cols = [f'layer_{i}' for i in range(26)]\n",
    "layer_totals = summary_df[layer_cols].sum()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(26), layer_totals.values, marker='o')\n",
    "plt.xticks(range(26))\n",
    "plt.title(\"Total Neuron Count per Layer (0â€“25)\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
