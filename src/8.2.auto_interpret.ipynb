{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42cc87da-33e9-44a6-8e1a-b728be972638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in ./jvenv/lib/python3.11/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in ./jvenv/lib/python3.11/site-packages (from langchain-openai) (0.3.68)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in ./jvenv/lib/python3.11/site-packages (from langchain-openai) (1.93.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./jvenv/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in ./jvenv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.4.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./jvenv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./jvenv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./jvenv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./jvenv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./jvenv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (4.14.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./jvenv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-openai) (2.11.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./jvenv/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./jvenv/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./jvenv/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./jvenv/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in ./jvenv/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./jvenv/lib/python3.11/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./jvenv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./jvenv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./jvenv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.86.0->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./jvenv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in ./jvenv/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./jvenv/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./jvenv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./jvenv/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-openai) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./jvenv/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./jvenv/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./jvenv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in ./jvenv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.66->langchain-openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./jvenv/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.66->langchain-openai) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./jvenv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./jvenv/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8253fe-5097-4309-9e00-4a8073b8e7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import torch\n",
    "GEMMA2B_KEY = \"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\"\n",
    "login(token=GEMMA2B_KEY)\n",
    "torch.set_grad_enabled(False)\n",
    "from sae_lens.analysis.neuronpedia_integration import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a59d08bb-45e5-4992-90fb-0d6c9632f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_feature_ids = [i for i in range(1000)]\n",
    "from sae_lens import SAE\n",
    "\n",
    "release = \"gemma-scope-2b-pt-mlp-canonical\"\n",
    "sae_id = \"layer_22/width_16k/canonical\"\n",
    "sae = SAE.from_pretrained(release, sae_id)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b6233-3b24-41a6-b510-0aebb2591f3c",
   "metadata": {},
   "source": [
    "# get explanation given the list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e12277b2-7116-4352-b925-14a6e8b9b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://neuronpedia.org/quick-list/?name=temporary_list&features=%5B%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%220%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%221%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%222%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%223%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%224%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%225%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%226%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%227%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%228%22%7D%2C%20%7B%22modelId%22%3A%20%22gemma-2-2b%22%2C%20%22layer%22%3A%20%2222-gemmascope-mlp-16k%22%2C%20%22index%22%3A%20%229%22%7D%5D\n"
     ]
    }
   ],
   "source": [
    "REQUEST_LIMIT = 150 # maximum neurons can analyze \n",
    "REQUEST_LIMIT = 10 # maximum neurons can analyze \n",
    "\n",
    "print(get_neuronpedia_quick_list(sae=sae, features=token_feature_ids[:REQUEST_LIMIT]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ba928e-e524-4ce2-91ff-448bcd3f8a52",
   "metadata": {},
   "source": [
    "# Analyze single neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7869485-aa3b-4a4a-a224-a5f1b93c1924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/0\n",
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/1\n",
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/2\n",
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/3\n",
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/4\n",
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/5\n",
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/6\n",
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/7\n",
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/8\n",
      "https://neuronpedia.org/gemma-2-2b/22-gemmascope-mlp-16k/9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sae_id = sae.cfg.neuronpedia_id\n",
    "    url = f\"{NEURONPEDIA_DOMAIN}/{sae_id}/{i}\"\n",
    "    print(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14889ed2-b80c-473f-bd6a-5d5b731d1359",
   "metadata": {},
   "source": [
    "# Get feature - Returns a feature, including its activations and explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91f6dde0-4521-409f-8bd9-4114897d57c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " instances of parentheses and expressions of the concept of \"status quo.\"\n",
      "elements of HTML and programming language syntax\n",
      " references to programming methods and serialization processes\n",
      " programming loops and function definitions\n",
      "references to SEO practices and related features in marketing contexts\n",
      " phrases expressing possession or ownership\n",
      "aspirations related to careers in design and cuisine\n",
      "references to specific individuals and their roles in a legal context\n",
      " references to specific objects or tools in a narrative context\n",
      " phrases indicating duration or quantity of time\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_feature(model_id, source, index):\n",
    "    url = f\"https://www.neuronpedia.org/api/feature/{model_id}/{source}/{index}\"\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()            # throws if not 200\n",
    "    feature = resp.json()\n",
    "    \n",
    "    # 2. Grab the list of explanations (might be empty!)\n",
    "    explanations = feature.get(\"explanations\", [])\n",
    "    \n",
    "    # 3. first description:\n",
    "    # if explanations:\n",
    "    return explanations[0][\"description\"]\n",
    "    \n",
    "for i in range(10):\n",
    "    model = \"gemma-2-2b\"\n",
    "    layer = 21\n",
    "    sae_type = \"mlp\"\n",
    "    source = f\"{layer}-gemmascope-{sae_type}-16k\"\n",
    "    feat = get_feature(model, source, i)\n",
    "    print(feat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d92fa-0c5b-4c71-9696-e2ba684c5147",
   "metadata": {},
   "source": [
    "# Get top neurons from a sentnece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a4c8d83-e9c0-4fc6-b5ab-bdbecbe80ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search by SAEs/Sources​#Copy link\n",
    "# Search for explanations in the features of one or more SAEs/Sources in a model. Takes a query and returns up to 20 results at a time.\n",
    "\n",
    "requests.post(\n",
    "    \"https://www.neuronpedia.org/api/explanation/search\",\n",
    "    headers={\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "      \"modelId\": \"gemma-2-2b\",\n",
    "      \"layers\": [\n",
    "        \"0-gemmascope-res-16k\",\n",
    "        \"20-gemmascope-res-16k\",\n",
    "        \"21-gemmascope-res-16k\"\n",
    "      ],\n",
    "      \"query\": \"Find the number of solutions to the equation [tan (5 pi cos theta) = cot (5 pi sin theta)]where $theta in (0, 2 pi).$\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc296c0-ff57-4cf8-b018-d44af0e71777",
   "metadata": {},
   "source": [
    "# Neuron steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4257dc3-c058-48e3-8df6-f946ad583fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.post(\n",
    "    \"https://www.neuronpedia.org/api/steer-chat\",\n",
    "    headers={\n",
    "      \"Content-Type\": \"application/json\"\n",
    "    },\n",
    "    json={\n",
    "      \"defaultChatMessages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"hello who are you\"\n",
    "        }\n",
    "      ],\n",
    "      \"steeredChatMessages\": [\n",
    "        {\n",
    "          \"role\": \"user\",\n",
    "          \"content\": \"hello who are you\"\n",
    "        }\n",
    "      ],\n",
    "      \"modelId\": \"gemma-2-9b-it\",\n",
    "      \"features\": [\n",
    "        {\n",
    "          \"modelId\": \"gemma-2-9b-it\",\n",
    "          \"layer\": \"9-gemmascope-res-131k\",\n",
    "          \"index\": 62610,\n",
    "          \"strength\": 200\n",
    "        }\n",
    "      ],\n",
    "      \"temperature\": 0.5,\n",
    "      \"n_tokens\": 48,\n",
    "      \"freq_penalty\": 2,\n",
    "      \"seed\": 16,\n",
    "      \"strength_multiplier\": 4,\n",
    "      \"steer_special_tokens\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94abf7ab-1d70-475e-855a-a368c88a39f2",
   "metadata": {},
   "source": [
    "# 1. get the explanations for each neuron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eca405b-025a-4d69-a27c-6f3ae22877d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = \"./find_similarity\" # Assuming you saved them in this folder\n",
    "\n",
    "\n",
    "# for file_name in os.listdir(folder_path):  \n",
    "file_name = \"type-res_layer-24_C1-empathetic_dialogue_C2-mmlu.csv\"\n",
    "match = re.match(r\"contributing_neurons_type-(.*)_layer-(\\d+)_C1-(.*)_C2-(.*)\\.csv\", file_name)\n",
    "file_name = folder_path + \"/\" + file_name\n",
    "if match:\n",
    "    typ_loaded = match.group(1)\n",
    "    layer_loaded = int(match.group(2))\n",
    "    class1_loaded = match.group(3)\n",
    "    class2_loaded = match.group(4)\n",
    "    print(f\"Loaded Metadata: Type={typ_loaded}, Layer={layer_loaded}, C1={class1_loaded}, C2={class2_loaded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c5c720c-8104-48e2-8f46-6d0aac804333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Neuron_ID     1000 non-null   int64  \n",
      " 1   Contribution  1000 non-null   float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 15.8 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>261</td>\n",
       "      <td>855963642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3848</td>\n",
       "      <td>768038052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14870</td>\n",
       "      <td>206918192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14448</td>\n",
       "      <td>200768391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4182</td>\n",
       "      <td>121216578.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neuron_ID  Contribution\n",
       "0        261   855963642.0\n",
       "1       3848   768038052.0\n",
       "2      14870   206918192.0\n",
       "3      14448   200768391.0\n",
       "4       4182   121216578.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name\n",
    "df = pd.read_csv(file_name)\n",
    "df.describe()\n",
    "df.info()\n",
    "# print(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb38e90-f82b-4fc9-8570-c44ca2f6b9b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer_loaded' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# def get_feature(model_id, source, index):\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#     url = f\"https://www.neuronpedia.org/api/feature/{model_id}/{source}/{index}\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m#     resp = requests.get(url)\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# class1_loaded = match.group(3)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# class2_loaded = match.group(4)\u001b[39;00m\n\u001b[32m     22\u001b[39m model = \u001b[33m\"\u001b[39m\u001b[33mgemma-2-2b\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m source = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mlayer_loaded\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-gemmascope-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp_loaded\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-16k\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     25\u001b[39m skills = []\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n",
      "\u001b[31mNameError\u001b[39m: name 'layer_loaded' is not defined"
     ]
    }
   ],
   "source": [
    "# go one by one call API \n",
    "import requests\n",
    "\n",
    "# def get_feature(model_id, source, index):\n",
    "#     url = f\"https://www.neuronpedia.org/api/feature/{model_id}/{source}/{index}\"\n",
    "#     resp = requests.get(url)\n",
    "#     resp.raise_for_status()            # throws if not 200\n",
    "#     feature = resp.json()\n",
    "    \n",
    "#     # 2. Grab the list of explanations (might be empty!)\n",
    "#     explanations = feature.get(\"explanations\", [])\n",
    "\n",
    "#     # 3. first description:\n",
    "#     if explanations:\n",
    "#         return explanations[0][\"description\"]\n",
    "\n",
    "\n",
    "# typ_loaded = match.group(1)           res\n",
    "# layer_loaded = int(match.group(2))    0-25\n",
    "# class1_loaded = match.group(3)\n",
    "# class2_loaded = match.group(4)\n",
    "model = \"gemma-2-2b\"\n",
    "source = f\"{layer_loaded}-gemmascope-{typ_loaded}-16k\"\n",
    "\n",
    "skills = []\n",
    "for index, row in df.iterrows():\n",
    "    neuron_id = row['Neuron_ID']\n",
    "    contribution = row['Contribution']\n",
    "    feat = get_feature(model, source, neuron_id)\n",
    "    skills.append(feat)\n",
    "\n",
    "df[\"explanation\"] = skills\n",
    "df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d25324-d647-476c-aa1a-efddd397f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use OPENAI API chatgpt to evaluate if it is or not \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de227117-837e-44b9-ad5e-3db373f5343c",
   "metadata": {},
   "source": [
    "# Evaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406d23b0-19f8-4cbc-9556-b0c1e680ae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"contributing_neurons/type-res_layer-24_C1-empathetic_dialogue_C2-mmlu.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9bc3b8-74e3-43f7-9acb-af28deb98ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Metadata: Type=res, Layer=24, C1=empathetic_dialogue, C2=mmlu\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Neuron_ID     1000 non-null   int64  \n",
      " 1   Contribution  1000 non-null   float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 15.8 KB\n",
      "None\n",
      "./find_similarity/type-res_layer-24_C1-empathetic_dialogue_C2-mmlu.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = \"./find_similarity\" # Assuming you saved them in this folder\n",
    "\n",
    "# for file_name in os.listdir(folder_path):  \n",
    "file_name = \"type-res_layer-24_C1-empathetic_dialogue_C2-mmlu.csv\"\n",
    "match = re.match(r\"type-(.*)_layer-(\\d+)_C1-(.*)_C2-(.*)\\.csv\", file_name)\n",
    "file_name = folder_path + \"/\" + file_name\n",
    "if match:\n",
    "    typ_loaded = match.group(1)\n",
    "    layer_loaded = int(match.group(2))\n",
    "    class1_loaded = match.group(3)\n",
    "    class2_loaded = match.group(4)\n",
    "    print(f\"Loaded Metadata: Type={typ_loaded}, Layer={layer_loaded}, C1={class1_loaded}, C2={class2_loaded}\")\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "print(df.info())\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf1d2fe8-4ac6-4bc7-8a87-400484438185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "# Azure credentials\n",
    "AZURE_OPENAI_ENDPOINT = \"https://vbm-resource.cognitiveservices.azure.com/\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = \"o4-mini\"\n",
    "AZURE_OPENAI_API_VERSION = \"2024-12-01-preview\"\n",
    "AZURE_OPENAI_API_KEY = \"4LdHqRgKwivk2hoYayfbFNzQt9HWR6cqYqlWYI4xMDfCNdaE3b5mJQQJ99BGACfhMk5XJ3w3AAAAACOGiEst\"\n",
    "\n",
    "# Set env var for LangChain to use\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "\n",
    "# Backgrounds\n",
    "DATASET_BACKGROUND = {\n",
    "    \"mmlu\": \"The MMLU dataset is designed to evaluate the general knowledge and reasoning abilities...\",\n",
    "    \"empathetic_dialogue\": \"The empathetic_dialogue dataset consists of open-domain conversations...\",\n",
    "    \"math\": \"The Math dataset assesses the mathematical reasoning capabilities...\",\n",
    "    \"programming\": \"The Programming dataset is used to evaluate a language model’s ability...\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2521b8-71db-4cf4-8f49-8f0ffed03ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_response(response_content: str, print_output: bool = False) -> dict:\n",
    "    # print(response_content)\n",
    "    try:\n",
    "        # Remove Markdown-style code fences (```json ... ```)\n",
    "        cleaned = response_content.strip()\n",
    "        if cleaned.startswith(\"```json\"):\n",
    "            cleaned = cleaned[7:]  # remove the initial ```json\n",
    "        if cleaned.startswith(\"```\"):\n",
    "            cleaned = cleaned[3:]  # fallback if only triple backticks\n",
    "        if cleaned.endswith(\"```\"):\n",
    "            cleaned = cleaned[:-3]\n",
    "        cleaned = cleaned.strip()\n",
    "        \n",
    "        data = json.loads(cleaned)\n",
    "        if print_output:\n",
    "            print(f\"Rationale: {data.get('rationale')}\")\n",
    "            print(f\"decision_on_both: {data.get('decision_on_both')}\")\n",
    "            print(f\"decision_on_one: {data.get('decision_on_one')}\")\n",
    "        return data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON Decode Error:\", e)\n",
    "        print(\"Raw response:\", response_content)\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8d7718-5ffc-41d0-a12f-ab7dd136eb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(QUESTION: str, print_output: bool = False, class1=\"mmlu\", class2=\"math\", context=\"Neuron X activates when...\"):\n",
    "    # Correct LLM init\n",
    "    llm = AzureChatOpenAI(\n",
    "        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "        openai_api_version=AZURE_OPENAI_API_VERSION,\n",
    "    )\n",
    "\n",
    "    system_template = f\"\"\"\n",
    "    SYSTEM:\n",
    "    You are an evaluator agent analyzing neuron activation on Sparse Autoencoders. You will receive an explanation from an Auto-Interpretability system. Your goal is to determine whether the explanation reflects activation of skills related to:\n",
    "    \n",
    "    1. **Both** class1 **AND** class2 (i.e., the neuron appears to represent a combination on both skill sets).\n",
    "    2. **At least one** of class1 **OR** class2 (i.e., the neuron might be relevant to only one of the skills, not necessarily both).\n",
    "    \n",
    "    Background on class1 ({class1}):\n",
    "    {DATASET_BACKGROUND[class1]}\n",
    "    \n",
    "    Background on class2 ({class2}):\n",
    "    {DATASET_BACKGROUND[class2]}\n",
    "    \n",
    "    INSTRUCTIONS:\n",
    "    Based on the explanation provided, analyze whether the neuron activation corresponds to:\n",
    "    - A combined skill from both class1 and class2\n",
    "    - A partial skill from either class1 or class2\n",
    "    \n",
    "    Output your reasoning and decision in the following JSON format:\n",
    "    ratinole: text\n",
    "    decision_on_both: YES, NO, UNSURE\n",
    "    decision_on_one: YES, NO, UNSURE\n",
    "    ```json\n",
    "    {{\n",
    "      \"rationale\": \"...\",\n",
    "      \"decision_on_both\": \"yes|no|unsure\",\n",
    "      \"decision_on_one\": \"yes|no|unsure\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    user_prompt = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    user_message = user_prompt.format(context=context, question=QUESTION)\n",
    "\n",
    "    # LLM call\n",
    "    response = llm.invoke([\n",
    "        {\"role\": \"system\", \"content\": system_template.strip()},\n",
    "        {\"role\": \"user\", \"content\": user_message.strip()}\n",
    "    ])\n",
    "\n",
    "    return parse_json_response(response.content, print_output=print_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83f192da-ff9e-4314-847b-26c487c7349b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rationale: The neuron response pertains specifically to understanding punctuation usage and its contextual significance in documentation or testimonies, which aligns with general knowledge and writing skills tested in MMLU rather than empathetic dialogue. Thus it represents only one of the skill classes (MMLU).\n",
      "decision_on_both: no\n",
      "decision_on_one: yes\n"
     ]
    }
   ],
   "source": [
    "QUESTION = \"terms related to organizational structure and maintenance tasks\"\n",
    "QUESTION = \"words related to profession or work responsibilities\"\n",
    "# QUESTION = \"punctuations and sentence endings\"\n",
    "QUESTION = \"diverse punctuation and their contextual significance in documenting conversations or testimonies\"\n",
    "llm_output = get_answer(QUESTION, print_output=True, class1=\"empathetic_dialogue\", class2=\"mmlu\")\n",
    "# # Safe unpacking\n",
    "# print(f\"Rationale: {llm_output.get('rationale')}\")\n",
    "# print(f\"decision_on_both: {llm_output.get('decision_on_both')}\")\n",
    "# print(f\"decision_on_one: {llm_output.get('decision_on_one')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "965cd56a-de6f-4574-b9ca-a2fa8ff124ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rationale': 'The neuron response pertains specifically to understanding punctuation usage and its contextual significance in documentation or testimonies, which aligns with general knowledge and writing skills tested in MMLU rather than empathetic dialogue. Thus it represents only one of the skill classes (MMLU).',\n",
       " 'decision_on_both': 'no',\n",
       " 'decision_on_one': 'yes'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e126160f-6fdc-4846-afb4-7f429851e4a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'explanation'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/cephfs/volumes/hpc_data_prj/inf_narrative_msc/e8efa787-4d41-448d-a7aa-814b8f0fac1e/k24086575/jvenv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'explanation'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m neuron_id = row[\u001b[33m\"\u001b[39m\u001b[33mNeuron_ID\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     10\u001b[39m contribution = row[\u001b[33m\"\u001b[39m\u001b[33mContribution\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m explanation = \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexplanation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     13\u001b[39m llm_output = get_answer(explanation, print_output=\u001b[38;5;28;01mFalse\u001b[39;00m, class1=CLASS1, class2=CLASS2)\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(idx)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cephfs/volumes/hpc_data_prj/inf_narrative_msc/e8efa787-4d41-448d-a7aa-814b8f0fac1e/k24086575/jvenv/lib/python3.11/site-packages/pandas/core/series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cephfs/volumes/hpc_data_prj/inf_narrative_msc/e8efa787-4d41-448d-a7aa-814b8f0fac1e/k24086575/jvenv/lib/python3.11/site-packages/pandas/core/series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/cephfs/volumes/hpc_data_prj/inf_narrative_msc/e8efa787-4d41-448d-a7aa-814b8f0fac1e/k24086575/jvenv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'explanation'"
     ]
    }
   ],
   "source": [
    "CLASS1 = \"empathetic_dialogue\"\n",
    "CLASS2 = \"mmlu\"\n",
    "\n",
    "output_rationale = []\n",
    "output_decision_both = []\n",
    "output_decision_one = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    neuron_id = row[\"Neuron_ID\"]\n",
    "    contribution = row[\"Contribution\"]\n",
    "    explanation = row[\"explanation\"]\n",
    "\n",
    "    llm_output = get_answer(explanation, print_output=False, class1=CLASS1, class2=CLASS2)\n",
    "    print(idx)\n",
    "    rationale = llm_output.get(\"rationale\")\n",
    "    decision_on_both = llm_output.get(\"decision_on_both\")\n",
    "    decision_on_one = llm_output.get(\"decision_on_one\")\n",
    "\n",
    "    output_rationale.append(rationale)\n",
    "    output_decision_both.append(decision_on_both)\n",
    "    output_decision_one.append(decision_on_one)\n",
    "\n",
    "# Add results to the DataFrame\n",
    "df[\"Rationale\"] = output_rationale\n",
    "df[\"Decision_BOTH\"] = output_decision_both\n",
    "df[\"Decision_ONE\"] = output_decision_one\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(file_name, index=False)\n",
    "print(f\"Saved results to {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b69c1b8b-190d-4625-bcf8-e92c3bd87f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>explanation</th>\n",
       "      <th>Rationale</th>\n",
       "      <th>Decision</th>\n",
       "      <th>Decision_BOTH</th>\n",
       "      <th>Decision_ONE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>261</td>\n",
       "      <td>855963642.0</td>\n",
       "      <td>technical terms related to software or program...</td>\n",
       "      <td>The neuron activates specifically for technica...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3848</td>\n",
       "      <td>768038052.0</td>\n",
       "      <td>terms related to scientific and medical topics</td>\n",
       "      <td>The neuron fires on terms related to scientifi...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14870</td>\n",
       "      <td>206918192.0</td>\n",
       "      <td>content related to healthcare policies and pra...</td>\n",
       "      <td>No explanation of neuron activation behavior w...</td>\n",
       "      <td>no</td>\n",
       "      <td>unsure</td>\n",
       "      <td>unsure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14448</td>\n",
       "      <td>200768391.0</td>\n",
       "      <td>code snippets and programming-related terminology</td>\n",
       "      <td>Neuron X responds specifically to code snippet...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4182</td>\n",
       "      <td>121216578.0</td>\n",
       "      <td>programming-related constructs and structures</td>\n",
       "      <td>The neuron activates for programming-related c...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Neuron_ID  Contribution                                        explanation  \\\n",
       "0        261   855963642.0  technical terms related to software or program...   \n",
       "1       3848   768038052.0     terms related to scientific and medical topics   \n",
       "2      14870   206918192.0  content related to healthcare policies and pra...   \n",
       "3      14448   200768391.0  code snippets and programming-related terminology   \n",
       "4       4182   121216578.0      programming-related constructs and structures   \n",
       "\n",
       "                                           Rationale Decision Decision_BOTH  \\\n",
       "0  The neuron activates specifically for technica...       no            no   \n",
       "1  The neuron fires on terms related to scientifi...       no            no   \n",
       "2  No explanation of neuron activation behavior w...       no        unsure   \n",
       "3  Neuron X responds specifically to code snippet...       no            no   \n",
       "4  The neuron activates for programming-related c...       no            no   \n",
       "\n",
       "  Decision_ONE  \n",
       "0          yes  \n",
       "1          yes  \n",
       "2       unsure  \n",
       "3          yes  \n",
       "4          yes  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d265d593-8595-447f-bdb2-858e35c878d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision_BOTH\n",
      "no        93\n",
      "unsure     5\n",
      "NO         1\n",
      "yes        1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"contributing_neurons/100type-res_layer-24_C1-empathetic_dialogue_C2-mmlu.csv\")\n",
    "rationale_counts = df[\"Decision_BOTH\"].value_counts()\n",
    "print(rationale_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a8ddc2-8194-4884-93ed-7f5933d9a210",
   "metadata": {},
   "source": [
    "# =============================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9966ab79-4212-4d4e-93af-21f1ebe752a1",
   "metadata": {},
   "source": [
    "# Auto interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4615194-aa54-4833-99aa-72c5ddb184fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul 19 21:24:07 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A40                     On  | 00000000:19:00.0 Off |                    0 |\n",
      "|  0%   29C    P8              21W / 300W |      0MiB / 46068MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf522b9-9d21-4c36-9b86-3cdd6cefe940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ast\n",
    "import csv\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44d8ac23-a645-40ae-95dd-8a79abef1126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>layer</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>Neuron_ID</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mlp</td>\n",
       "      <td>7</td>\n",
       "      <td>math</td>\n",
       "      <td>programming</td>\n",
       "      <td>6117</td>\n",
       "      <td>8.144039e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>math</td>\n",
       "      <td>programming</td>\n",
       "      <td>9329</td>\n",
       "      <td>7.782393e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mlp</td>\n",
       "      <td>23</td>\n",
       "      <td>math</td>\n",
       "      <td>programming</td>\n",
       "      <td>10184</td>\n",
       "      <td>7.565522e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>res</td>\n",
       "      <td>1</td>\n",
       "      <td>math</td>\n",
       "      <td>programming</td>\n",
       "      <td>12054</td>\n",
       "      <td>6.470184e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mlp</td>\n",
       "      <td>24</td>\n",
       "      <td>math</td>\n",
       "      <td>programming</td>\n",
       "      <td>282</td>\n",
       "      <td>5.486137e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type  layer class1       class2  Neuron_ID  Contribution\n",
       "0  mlp      7   math  programming       6117  8.144039e+11\n",
       "1  mlp     24   math  programming       9329  7.782393e+11\n",
       "2  mlp     23   math  programming      10184  7.565522e+11\n",
       "3  res      1   math  programming      12054  6.470184e+11\n",
       "4  mlp     24   math  programming        282  5.486137e+11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./dot_product/neuron_contribution_between_class.csv\"\n",
    "df = pd.read_csv(path, encoding=\"utf-8-sig\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39417fd5-f078-426c-817a-c5b68dc0c74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " instances of parentheses and expressions of the concept of \"status quo.\"\n",
      "elements of HTML and programming language syntax\n",
      " references to programming methods and serialization processes\n",
      " programming loops and function definitions\n",
      "references to SEO practices and related features in marketing contexts\n",
      " phrases expressing possession or ownership\n",
      "aspirations related to careers in design and cuisine\n",
      "references to specific individuals and their roles in a legal context\n",
      " references to specific objects or tools in a narrative context\n",
      " phrases indicating duration or quantity of time\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_feature(model_id, source, index):\n",
    "    try:\n",
    "        url = f\"https://www.neuronpedia.org/api/feature/{model_id}/{source}/{index}\"\n",
    "        resp = requests.get(url)\n",
    "        resp.raise_for_status()            # throws if not 200\n",
    "        feature = resp.json()\n",
    "        \n",
    "        # 2. Grab the list of explanations (might be empty!)\n",
    "        explanations = feature.get(\"explanations\", [])\n",
    "        \n",
    "        # 3. first description:\n",
    "        # if explanations:\n",
    "        return explanations[0][\"description\"]\n",
    "    except e:\n",
    "        return None\n",
    "    \n",
    "for i in range(10):\n",
    "    model = \"gemma-2-2b\"\n",
    "    layer = 21\n",
    "    sae_type = \"mlp\"\n",
    "    source = f\"{layer}-gemmascope-{sae_type}-16k\"\n",
    "    feat = get_feature(model, source, i)\n",
    "    print(feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce0365-a275-49b0-9073-6c546f505145",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gemma-2-2b\"\n",
    "\n",
    "explanations = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    sae_type = df[\"type\"]\n",
    "    layer = df[\"layer\"]\n",
    "    neuron_id = df[\"Neuron_ID\"]\n",
    "    source = f\"{layer}-gemmascope-{sae_type}-16k\"\n",
    "\n",
    "    feat = get_feature(model, source, neuron_id)\n",
    "    explanations.append(feat)\n",
    "\n",
    "df[\"Explanation\"] = explanations\n",
    "df.to_csv(path, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5098fa39-c04f-49c2-8ef5-ad660da7a353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e094aa5d-846b-437f-bc4c-5fb2af8f3064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
